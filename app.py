"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   FOOTBALL AI â€” COMPETITION GRADE v8.0                       â•‘
â•‘   v7b fixes + 3 clarity upgrades:                            â•‘
â•‘   ğŸ”¥ FIX 4: Ablation test â€” à¹€à¸à¸´à¹ˆà¸¡ context single-stage note â•‘
â•‘             â†’ xG negative contribution = architecture issue  â•‘
â•‘             â†’ à¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆà¸ªà¸±à¸à¸à¸²à¸“à¸§à¹ˆà¸² xG à¹„à¸¡à¹ˆà¸¡à¸µà¸›à¸£à¸°à¹‚à¸¢à¸Šà¸™à¹Œ             â•‘
â•‘   ğŸ”¥ FIX 5: Rolling CV â€” à¹€à¸à¸´à¹ˆà¸¡ explanation à¸§à¹ˆà¸²à¸—à¸³à¹„à¸¡à¸•à¹ˆà¸³à¸à¸§à¹ˆà¸²  â•‘
â•‘             â†’ single-stage + older data = lower bound        â•‘
â•‘             â†’ Walk-forward à¸„à¸·à¸­ primary metric à¸—à¸µà¹ˆà¹€à¸Šà¸·à¹ˆà¸­à¸–à¸·à¸­à¹„à¸”à¹‰â•‘
â•‘   ğŸ”¥ FIX 6: Phase 3 Summary â€” Walk-forward à¹€à¸›à¹‡à¸™ PRIMARY      â•‘
â•‘             â†’ Rolling CV à¸¥à¸”à¹€à¸›à¹‡à¸™ reference only              â•‘
â•‘             â†’ Weighted accuracy + pooled sample size          â•‘
â•‘   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â•‘
â•‘   Confirmed wins from v7b:                                   â•‘
â•‘     âœ… Draw Calibration: Brier SS = +0.2%, Bias = +0.1%      â•‘
â•‘     âœ… Walk-forward std = 0.036 (à¹€à¸ªà¸–à¸µà¸¢à¸£)                     â•‘
â•‘     âœ… Narrow threshold search à¸ªà¸³à¸«à¸£à¸±à¸š CV folds               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import pandas as pd
import numpy as np
import glob
import os
import pickle
import warnings
warnings.filterwarnings('ignore')

from sklearn.ensemble import (
    RandomForestClassifier, VotingClassifier,
    GradientBoostingClassifier, ExtraTreesClassifier,
    StackingClassifier
)
from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.calibration import CalibratedClassifierCV, calibration_curve
from sklearn.metrics import (
    accuracy_score, confusion_matrix, classification_report,
    brier_score_loss, log_loss
)
from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV
from scipy.stats import poisson

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIG FLAGS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# à¹à¸à¸™à¸«à¸¥à¸±à¸: Football model à¹„à¸¡à¹ˆà¸à¸¶à¹ˆà¸‡ market odds
USE_MARKET_FEATURES = False

# ğŸ”¥ LightGBM â€” core model v3.0
try:
    import lightgbm as lgb
    LGBM_AVAILABLE = True
    print("âœ… LightGBM available")
except ImportError:
    LGBM_AVAILABLE = False
    print("âš ï¸  LightGBM not found â€” pip install lightgbm  (falling back to GBT)")

# ğŸ”¥ SHAP â€” feature importance
try:
    import shap
    SHAP_AVAILABLE = True
except ImportError:
    SHAP_AVAILABLE = False

# ğŸ”¥ S3: Optuna â€” hyperparameter tuning
try:
    import optuna
    optuna.logging.set_verbosity(optuna.logging.WARNING)
    OPTUNA_AVAILABLE = True
    print("âœ… Optuna available")
except ImportError:
    OPTUNA_AVAILABLE = False
    print("âš ï¸  Optuna not found â€” pip install optuna  (skipping tuning)")

# ğŸ”¥ S5: imbalanced-learn â€” SMOTE for Draw class
try:
    from imblearn.over_sampling import SMOTE
    from imblearn.pipeline import Pipeline as ImbPipeline
    SMOTE_AVAILABLE = True
    print("âœ… imbalanced-learn available")
except ImportError:
    SMOTE_AVAILABLE = False
    print("âš ï¸  imbalanced-learn not found â€” pip install imbalanced-learn  (skipping SMOTE)")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1) LOAD ALL DATA
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("Current directory:", os.getcwd())
files = glob.glob("data_set/*.csv")
print("Loaded files:", files)

df_list = []
for file in files:
    df = pd.read_csv(file)
    df_list.append(df)

data = pd.concat(df_list, ignore_index=True).copy()
data['MatchID'] = data.index
data['Date'] = pd.to_datetime(data['Date'], dayfirst=True, errors='coerce')
data = data.sort_values('Date').reset_index(drop=True)

print("\n===== DATA INFO =====")
print("Total matches:", len(data))
print("Date range:", data['Date'].min(), "â†’", data['Date'].max())

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ PHASE 1: xG FEATURE DETECTION
#    football-data.co.uk à¸¡à¸µà¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ HomeXG / AwayXG à¸•à¸±à¹‰à¸‡à¹à¸•à¹ˆà¸‹à¸µà¸‹à¸±à¹ˆà¸™ 2017+
#    à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µ â†’ fallback à¹€à¸›à¹‡à¸™ None à¹à¸¥à¹‰à¸§ skip xG features
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_xg_home_col = next((c for c in data.columns if c.lower() in ['homexg','hxg','home_xg','xgh']), None)
_xg_away_col = next((c for c in data.columns if c.lower() in ['awayxg','axg','away_xg','xga','xgaway']), None)

# football-data.co.uk standard column names
if _xg_home_col is None and 'HomeXG' in data.columns:  _xg_home_col = 'HomeXG'
if _xg_away_col is None and 'AwayXG' in data.columns:  _xg_away_col = 'AwayXG'

XG_AVAILABLE = (_xg_home_col is not None and _xg_away_col is not None and
                data[_xg_home_col].notna().sum() > 200)

if XG_AVAILABLE:
    data['_HomeXG'] = pd.to_numeric(data[_xg_home_col], errors='coerce')
    data['_AwayXG'] = pd.to_numeric(data[_xg_away_col], errors='coerce')
    print(f"âœ… xG columns found: {_xg_home_col}/{_xg_away_col}  "
          f"({data['_HomeXG'].notna().sum()} valid rows)")
else:
    data['_HomeXG'] = np.nan
    data['_AwayXG'] = np.nan
    print("âš ï¸  xG columns NOT found â€” xG features will be skipped")
    print("   (Add HomeXG/AwayXG columns from football-data.co.uk to unlock +2-4% accuracy)")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ PHASE 2: BETTING ODDS DETECTION (optional)
#    à¸–à¹‰à¸² USE_MARKET_FEATURES=False à¸ˆà¸°à¸›à¸´à¸” market à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _find_odds_col(data, candidates):
    for c in candidates:
        if c in data.columns and pd.to_numeric(data[c], errors='coerce').notna().sum() > 200:
            return c
    return None

if USE_MARKET_FEATURES:
    _odds_h = _find_odds_col(data, ['B365H','BbAvH','PSH','WHH','MaxH','AvgH'])
    _odds_d = _find_odds_col(data, ['B365D','BbAvD','PSD','WHD','MaxD','AvgD'])
    _odds_a = _find_odds_col(data, ['B365A','BbAvA','PSA','WHA','MaxA','AvgA'])

    ODDS_AVAILABLE = all(x is not None for x in [_odds_h, _odds_d, _odds_a])

    if ODDS_AVAILABLE:
        data['_OddsH'] = pd.to_numeric(data[_odds_h], errors='coerce')
        data['_OddsD'] = pd.to_numeric(data[_odds_d], errors='coerce')
        data['_OddsA'] = pd.to_numeric(data[_odds_a], errors='coerce')
        # Implied probabilities (normalize to remove overround)
        _raw_h = 1 / data['_OddsH']
        _raw_d = 1 / data['_OddsD']
        _raw_a = 1 / data['_OddsA']
        _total = (_raw_h + _raw_d + _raw_a).replace(0, np.nan)
        data['_ImpH'] = _raw_h / _total   # implied P(Home Win) â€” overround removed
        data['_ImpD'] = _raw_d / _total
        data['_ImpA'] = _raw_a / _total
        data['_Overround'] = (_raw_h + _raw_d + _raw_a) - 1  # bookmaker margin
        print(f"âœ… Betting odds found: {_odds_h}/{_odds_d}/{_odds_a}  "
              f"(avg overround {data['_Overround'].mean()*100:.1f}%)")
    else:
        ODDS_AVAILABLE = False
        data['_ImpH'] = np.nan; data['_ImpD'] = np.nan; data['_ImpA'] = np.nan
        data['_Overround'] = np.nan
        print("âš ï¸  Betting odds NOT found â€” market features will be skipped")
        print("   (Add B365H/B365D/B365A from football-data.co.uk to improve calibration + ROI)")
else:
    ODDS_AVAILABLE = False
    data['_ImpH'] = np.nan; data['_ImpD'] = np.nan; data['_ImpA'] = np.nan
    data['_Overround'] = np.nan
    print("â„¹ï¸  USE_MARKET_FEATURES=False â€” à¸›à¸´à¸”à¸à¸²à¸£à¹ƒà¸Šà¹‰ market odds à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2) ELO RATING â€” Dynamic K-factor (à¹ƒà¸«à¸¡à¹ˆ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def compute_elo(data, k_base=32, base=1500):
    """
    Elo à¹à¸šà¸š Dynamic K-factor:
    - K à¹€à¸à¸´à¹ˆà¸¡à¸‚à¸¶à¹‰à¸™à¸–à¹‰à¸²à¸›à¸£à¸°à¸•à¸¹à¸•à¹ˆà¸²à¸‡à¸à¸±à¸™à¸¡à¸²à¸ (upset à¸¡à¸²à¸ = à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰à¸¡à¸²à¸à¸à¸§à¹ˆà¸²)
    - à¹à¸¢à¸ Elo à¹€à¸«à¸¢à¹‰à¸²/à¹€à¸¢à¸·à¸­à¸™ à¹€à¸à¸£à¸²à¸°à¸šà¸²à¸‡à¸—à¸µà¸¡à¹à¸‚à¹‡à¸‡à¹à¸à¸£à¹ˆà¸‡à¸—à¸µà¹ˆà¸šà¹‰à¸²à¸™à¸¡à¸²à¸
    """
    elo        = {}
    elo_home   = {}  # Elo à¹€à¸‰à¸à¸²à¸°à¸•à¸­à¸™à¹€à¸¥à¹ˆà¸™à¹€à¸«à¸¢à¹‰à¸²
    elo_away   = {}  # Elo à¹€à¸‰à¸à¸²à¸°à¸•à¸­à¸™à¹€à¸¥à¹ˆà¸™à¹€à¸¢à¸·à¸­à¸™

    home_elo_before = []
    away_elo_before = []
    home_elo_h_before = []  # home-specific elo
    away_elo_a_before = []  # away-specific elo

    for _, row in data.iterrows():
        home = row['HomeTeam']
        away = row['AwayTeam']
        hg   = row['FTHG']
        ag   = row['FTAG']

        if home not in elo:      elo[home]      = base
        if away not in elo:      elo[away]       = base
        if home not in elo_home: elo_home[home]  = base
        if away not in elo_away: elo_away[away]  = base

        # à¸šà¸±à¸™à¸—à¸¶à¸ Elo à¸à¹ˆà¸­à¸™à¹à¸¡à¸•à¸Šà¹Œ
        home_elo_before.append(elo[home])
        away_elo_before.append(elo[away])
        home_elo_h_before.append(elo_home.get(home, base))
        away_elo_a_before.append(elo_away.get(away, base))

        # Expected
        exp_home = 1 / (1 + 10 ** ((elo[away] - elo[home]) / 400))
        exp_away = 1 - exp_home

        # à¸œà¸¥à¸ˆà¸£à¸´à¸‡
        if pd.isna(hg) or pd.isna(ag):
            continue
        hg, ag = int(hg), int(ag)
        if hg > ag:
            score_home, score_away = 1.0, 0.0
        elif hg < ag:
            score_home, score_away = 0.0, 1.0
        else:
            score_home, score_away = 0.5, 0.5

        # Dynamic K: à¸–à¹‰à¸²à¹à¸à¹‰à¸‚à¸²à¸” K à¸ªà¸¹à¸‡à¸à¸§à¹ˆà¸² (à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰à¸ˆà¸²à¸ upset)
        goal_diff = abs(hg - ag)
        k = k_base * (1 + 0.1 * min(goal_diff, 5))

        # à¸­à¸±à¸›à¹€à¸”à¸• Elo à¸£à¸§à¸¡
        elo[home] += k * (score_home - exp_home)
        elo[away] += k * (score_away - exp_away)

        # à¸­à¸±à¸›à¹€à¸”à¸• Elo à¹€à¸‰à¸à¸²à¸°à¹€à¸«à¸¢à¹‰à¸²/à¹€à¸¢à¸·à¸­à¸™ (à¹ƒà¸Šà¹‰ K à¸¥à¸”à¸„à¸£à¸¶à¹ˆà¸‡ à¹€à¸à¸·à¹ˆà¸­ smooth)
        elo_home[home] = elo_home.get(home, base) + (k * 0.5) * (score_home - exp_home)
        elo_away[away] = elo_away.get(away, base) + (k * 0.5) * (score_away - exp_away)

    data = data.copy()
    data['Home_Elo']      = home_elo_before
    data['Away_Elo']      = away_elo_before
    data['Home_Elo_H']    = home_elo_h_before   # home-specific
    data['Away_Elo_A']    = away_elo_a_before   # away-specific
    data['Elo_Diff']      = data['Home_Elo'] - data['Away_Elo']
    return data, elo, elo_home, elo_away

data, final_elo, final_elo_home, final_elo_away = compute_elo(data)
print("âœ… Dynamic Elo computed")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3) TEAM-CENTRIC TABLE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

home_df = data[['MatchID','Date','HomeTeam','FTHG','FTAG',
                'Home_Elo','Away_Elo','Home_Elo_H','Away_Elo_A','Elo_Diff',
                '_HomeXG','_AwayXG']].copy()
home_df.columns = ['MatchID','Date','Team','GF','GA',
                   'Own_Elo','Opp_Elo','Own_Elo_HA','Opp_Elo_HA','Elo_Diff',
                   'xGF','xGA']
home_df['Home'] = 1

away_df = data[['MatchID','Date','AwayTeam','FTAG','FTHG',
                'Away_Elo','Home_Elo','Away_Elo_A','Home_Elo_H','Elo_Diff',
                '_AwayXG','_HomeXG']].copy()
away_df.columns = ['MatchID','Date','Team','GF','GA',
                   'Own_Elo','Opp_Elo','Own_Elo_HA','Opp_Elo_HA','Elo_Diff',
                   'xGF','xGA']
away_df['Home'] = 0

team_df = pd.concat([home_df, away_df], ignore_index=True)
team_df = team_df.sort_values(['Team','Date']).reset_index(drop=True)

team_df['Win']    = (team_df['GF'] > team_df['GA']).astype(int)
team_df['Draw']   = (team_df['GF'] == team_df['GA']).astype(int)
team_df['Loss']   = (team_df['GF'] < team_df['GA']).astype(int)
team_df['Points'] = team_df['Win']*3 + team_df['Draw']
team_df['CS']     = (team_df['GA'] == 0).astype(int)
team_df['Scored'] = (team_df['GF'] > 0).astype(int)
team_df['GD']     = team_df['GF'] - team_df['GA']   # Goal Difference

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4) ROLLING FEATURES â€” Standard + EWM (à¹ƒà¸«à¸¡à¹ˆ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def rolling_shift(df, col, window=5):
    """Standard rolling mean (lag-1)"""
    return (
        df.groupby('Team')[col]
        .rolling(window).mean()
        .shift(1)
        .reset_index(level=0, drop=True)
    )

def ewm_shift(df, col, span=5):
    """Exponential Weighted Mean â€” à¸™à¸±à¸”à¸¥à¹ˆà¸²à¸ªà¸¸à¸”à¸¡à¸µà¸™à¹‰à¸³à¸«à¸™à¸±à¸à¸¡à¸²à¸à¸à¸§à¹ˆà¸²"""
    return (
        df.groupby('Team')[col]
        .apply(lambda x: x.ewm(span=span, adjust=False).mean().shift(1))
        .reset_index(level=0, drop=True)
    )

def rolling_std_shift(df, col, window=5):
    """Rolling std â€” à¸§à¸±à¸”à¸„à¸§à¸²à¸¡à¹à¸›à¸£à¸›à¸£à¸§à¸™"""
    return (
        df.groupby('Team')[col]
        .rolling(window).std()
        .shift(1)
        .reset_index(level=0, drop=True)
    )

# Standard rolling
team_df['GF_last5']     = rolling_shift(team_df, 'GF')
team_df['GA_last5']     = rolling_shift(team_df, 'GA')
team_df['GD_last5']     = rolling_shift(team_df, 'GD')       # NEW: Goal Diff
team_df['Points_last5'] = rolling_shift(team_df, 'Points')
team_df['Win_last5']    = rolling_shift(team_df, 'Win')
team_df['Draw_last5']   = rolling_shift(team_df, 'Draw')     # NEW: Draw rate
team_df['CS_last5']     = rolling_shift(team_df, 'CS')
team_df['Scored_last5'] = rolling_shift(team_df, 'Scored')
team_df['Streak3']      = rolling_shift(team_df, 'Points', window=3)

# EWM features (à¹ƒà¸«à¸¡à¹ˆ)
team_df['GF_ewm5']      = ewm_shift(team_df, 'GF')
team_df['GA_ewm5']      = ewm_shift(team_df, 'GA')
team_df['Pts_ewm5']     = ewm_shift(team_df, 'Points')
team_df['GD_ewm5']      = ewm_shift(team_df, 'GD')

# Longer window (10 nà¸±à¸”) à¸ªà¸³à¸«à¸£à¸±à¸š momentum
team_df['Points_last10']= rolling_shift(team_df, 'Points', window=10)
team_df['GF_last10']    = rolling_shift(team_df, 'GF', window=10)

# GD variance â€” à¸—à¸µà¸¡ Draw à¸šà¹ˆà¸­à¸¢à¸¡à¸±à¸à¸¡à¸µ variance à¸•à¹ˆà¸³
team_df['GD_std5']      = rolling_std_shift(team_df, 'GD')

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ PHASE 1: xG ROLLING FEATURES
#    xGF/xGA = expected goals scored/conceded (à¸ˆà¸²à¸ football-data.co.uk)
#    à¸–à¹‰à¸² XG_AVAILABLE=False à¸—à¸¸à¸ feature à¸ˆà¸°à¹€à¸›à¹‡à¸™ NaN à¹à¸¥à¸°à¸–à¸¹à¸ drop à¸­à¸­à¸à¸ˆà¸²à¸ FEATURES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if XG_AVAILABLE:
    team_df['xGF_last5']   = rolling_shift(team_df, 'xGF')       # xG scored last 5
    team_df['xGA_last5']   = rolling_shift(team_df, 'xGA')       # xG conceded last 5
    team_df['xGF_ewm']     = ewm_shift(team_df, 'xGF')           # EWM xG scored
    team_df['xGA_ewm']     = ewm_shift(team_df, 'xGA')           # EWM xG conceded
    team_df['xGD_last5']   = team_df['xGF_last5'] - team_df['xGA_last5']  # xG diff
    # xG overperformance: Goals - xG  (à¸„à¹ˆà¸²à¸šà¸§à¸ = lucky/clinical, à¸„à¹ˆà¸²à¸¥à¸š = unlucky)
    team_df['xG_overperf'] = rolling_shift(team_df, 'GF') - rolling_shift(team_df, 'xGF')
    # xG trend slope (à¹€à¸£à¹ˆà¸‡à¸‚à¸¶à¹‰à¸™/à¸¥à¸‡)
    team_df['xGF_slope']   = (team_df['xGF_ewm'] - rolling_shift(team_df, 'xGF', window=10)) / 0.5
    print("âœ… xG rolling features computed (Phase 1 ACTIVE ğŸ”¥)")
else:
    for col in ['xGF_last5','xGA_last5','xGF_ewm','xGA_ewm',
                'xGD_last5','xG_overperf','xGF_slope']:
        team_df[col] = np.nan
    print("âš ï¸  xG features set to NaN (Phase 1 inactive)")

# Days rest (à¹ƒà¸«à¸¡à¹ˆ)
team_df['DaysRest']     = team_df.groupby('Team')['Date'].diff().dt.days.fillna(7)
team_df['DaysRest_lag'] = team_df.groupby('Team')['DaysRest'].shift(0)  # à¸à¹ˆà¸­à¸™à¹à¸¡à¸•à¸Šà¹Œà¸™à¸µà¹‰

team_df = team_df.dropna(subset=['GF_last5','GA_last5','Points_last5'])

print(f"âœ… Rolling + EWM features computed: {len(team_df)} rows")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 5) HOME STRENGTH PER TEAM (à¹ƒà¸«à¸¡à¹ˆ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

valid_data = data.dropna(subset=['FTHG','FTAG'])

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ FIX 1: SEQUENTIAL TEAM STATS (No Leakage!)
# à¸„à¸³à¸™à¸§à¸“ HomeWinRate / AwayWinRate / DrawRate à¹à¸šà¸š match-by-match
# à¸—à¸¸à¸ row à¹ƒà¸Šà¹‰à¹€à¸‰à¸à¸²à¸°à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¹ˆà¸­à¸™à¹à¸¡à¸•à¸Šà¹Œà¸™à¸±à¹‰à¸™ â€” à¹„à¸¡à¹ˆà¹ƒà¸Šà¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸±à¹‰à¸‡ season
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def compute_sequential_team_stats(data):
    """
    à¸„à¸³à¸™à¸§à¸“ HomeWinRate, AwayWinRate, HomeDrawRate à¹à¸šà¸š sequential
    à¹à¸•à¹ˆà¸¥à¸°à¹à¸¡à¸•à¸Šà¹Œà¹ƒà¸Šà¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ "à¸à¹ˆà¸­à¸™à¸§à¸±à¸™à¹à¸‚à¹ˆà¸‡" à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™ â€” à¹„à¸¡à¹ˆà¸¡à¸µ data leakage
    """
    home_wins  = {}; home_games  = {}
    away_wins  = {}; away_games  = {}
    home_draws = {}; home_g2     = {}

    hw_rates = []; aw_rates = []; hd_rates = []

    for _, row in data.sort_values('Date').iterrows():
        home = row['HomeTeam']; away = row['AwayTeam']
        hg   = row['FTHG'];    ag   = row['FTAG']

        # à¸šà¸±à¸™à¸—à¸¶à¸à¸„à¹ˆà¸²à¸à¹ˆà¸­à¸™à¸­à¸±à¸›à¹€à¸”à¸• (à¹ƒà¸Šà¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¹ˆà¸­à¸™à¹à¸¡à¸•à¸Šà¹Œà¸™à¸µà¹‰)
        hw_rates.append(home_wins.get(home, 0) / max(home_games.get(home, 1), 1))
        aw_rates.append(away_wins.get(away, 0) / max(away_games.get(away, 1), 1))
        hd_rates.append(home_draws.get(home, 0) / max(home_g2.get(home, 1), 1))

        if pd.isna(hg) or pd.isna(ag): continue
        hg, ag = int(hg), int(ag)

        # à¸­à¸±à¸›à¹€à¸”à¸•à¸«à¸¥à¸±à¸‡à¹à¸¡à¸•à¸Šà¹Œ
        home_games[home]  = home_games.get(home, 0) + 1
        away_games[away]  = away_games.get(away, 0) + 1
        home_g2[home]     = home_g2.get(home, 0) + 1

        if hg > ag:
            home_wins[home]  = home_wins.get(home, 0) + 1
        elif ag > hg:
            away_wins[away]  = away_wins.get(away, 0) + 1
        else:
            home_draws[home] = home_draws.get(home, 0) + 1

    data = data.sort_values('Date').reset_index(drop=True).copy()
    data['_HomeWinRate_seq']  = hw_rates
    data['_AwayWinRate_seq']  = aw_rates
    data['_HomeDrawRate_seq'] = hd_rates
    return data

data = compute_sequential_team_stats(data)
print("âœ… Sequential team stats computed (No Leakage!)")

# â”€â”€â”€â”€ Static lookups (à¹ƒà¸Šà¹‰à¸ªà¸³à¸«à¸£à¸±à¸š predict_match à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸¡à¸µ history) â”€â”€â”€â”€
home_stats = valid_data.groupby('HomeTeam').agg(
    HomeWins=('FTHG', lambda x: (x > valid_data.loc[x.index, 'FTAG']).sum()),
    HomeGames=('FTHG', 'count')
).reset_index()
home_stats['HomeWinRate'] = home_stats['HomeWins'] / home_stats['HomeGames'].clip(1)
home_stats = home_stats.rename(columns={'HomeTeam': 'Team'})

away_stats = valid_data.groupby('AwayTeam').agg(
    AwayWins=('FTAG', lambda x: (x > valid_data.loc[x.index, 'FTHG']).sum()),
    AwayGames=('FTAG', 'count')
).reset_index()
away_stats['AwayWinRate'] = away_stats['AwayWins'] / away_stats['AwayGames'].clip(1)
away_stats = away_stats.rename(columns={'AwayTeam': 'Team'})

draw_stats_home = valid_data.groupby('HomeTeam').agg(
    HomeDraws=('FTHG', lambda x: (x == valid_data.loc[x.index, 'FTAG']).sum()),
    HomeGames2=('FTHG', 'count')
).reset_index().rename(columns={'HomeTeam': 'Team'})
draw_stats_home['HomeDrawRate'] = draw_stats_home['HomeDraws'] / draw_stats_home['HomeGames2'].clip(1)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 6) MERGE BACK TO MATCH LEVEL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

h = team_df[team_df['Home'] == 1].copy().rename(columns={
    'Team':         'HomeTeam',
    'GF_last5':     'H_GF5',
    'GA_last5':     'H_GA5',
    'GD_last5':     'H_GD5',
    'Points_last5': 'H_Pts5',
    'Win_last5':    'H_Win5',
    'Draw_last5':   'H_Draw5',
    'CS_last5':     'H_CS5',
    'Scored_last5': 'H_Scored5',
    'Streak3':      'H_Streak3',
    'GF_ewm5':      'H_GF_ewm',
    'GA_ewm5':      'H_GA_ewm',
    'Pts_ewm5':     'H_Pts_ewm',
    'GD_ewm5':      'H_GD_ewm',
    'Points_last10':'H_Pts10',
    'GF_last10':    'H_GF10',
    'GD_std5':      'H_GD_std',
    'DaysRest_lag': 'H_DaysRest',
    'Own_Elo':      'H_Elo',
    'Own_Elo_HA':   'H_Elo_Home',
    # ğŸ”¥ Phase 1: xG
    'xGF_last5':    'H_xGF5',
    'xGA_last5':    'H_xGA5',
    'xGF_ewm':      'H_xGF_ewm',
    'xGA_ewm':      'H_xGA_ewm',
    'xGD_last5':    'H_xGD5',
    'xG_overperf':  'H_xG_overperf',
    'xGF_slope':    'H_xGF_slope',
})

a = team_df[team_df['Home'] == 0].copy().rename(columns={
    'Team':         'AwayTeam',
    'GF_last5':     'A_GF5',
    'GA_last5':     'A_GA5',
    'GD_last5':     'A_GD5',
    'Points_last5': 'A_Pts5',
    'Win_last5':    'A_Win5',
    'Draw_last5':   'A_Draw5',
    'CS_last5':     'A_CS5',
    'Scored_last5': 'A_Scored5',
    'Streak3':      'A_Streak3',
    'GF_ewm5':      'A_GF_ewm',
    'GA_ewm5':      'A_GA_ewm',
    'Pts_ewm5':     'A_Pts_ewm',
    'GD_ewm5':      'A_GD_ewm',
    'Points_last10':'A_Pts10',
    'GF_last10':    'A_GF10',
    'GD_std5':      'A_GD_std',
    'DaysRest_lag': 'A_DaysRest',
    'Own_Elo':      'A_Elo',
    'Own_Elo_HA':   'A_Elo_Away',
    # ğŸ”¥ Phase 1: xG
    'xGF_last5':    'A_xGF5',
    'xGA_last5':    'A_xGA5',
    'xGF_ewm':      'A_xGF_ewm',
    'xGA_ewm':      'A_xGA_ewm',
    'xGD_last5':    'A_xGD5',
    'xG_overperf':  'A_xG_overperf',
    'xGF_slope':    'A_xGF_slope',
})

match_df = pd.merge(h, a, on='MatchID')
# Merge actual goals (FTHG / FTAG) for Poisson model training
actual_goals = data[['MatchID','FTHG','FTAG']].copy()
match_df = match_df.merge(actual_goals, on='MatchID', how='left')

# ğŸ”¥ PHASE 2: Merge betting odds into match_df
if ODDS_AVAILABLE:
    odds_df = data[['MatchID','_ImpH','_ImpD','_ImpA','_Overround']].copy()
    match_df = match_df.merge(odds_df, on='MatchID', how='left')
    print("âœ… Betting odds merged into match_df (Phase 2 ACTIVE ğŸ”¥)")
else:
    match_df['_ImpH'] = np.nan; match_df['_ImpD'] = np.nan
    match_df['_ImpA'] = np.nan; match_df['_Overround'] = np.nan

print(f"âœ… Matches after feature engineering: {len(match_df)}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 7) DIFFERENCE + ADVANCED FEATURES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

match_df['Diff_Pts']      = match_df['H_Pts5']     - match_df['A_Pts5']
match_df['Diff_GF']       = match_df['H_GF5']      - match_df['A_GF5']
match_df['Diff_GA']       = match_df['H_GA5']       - match_df['A_GA5']
match_df['Diff_GD']       = match_df['H_GD5']      - match_df['A_GD5']       # NEW
match_df['Diff_Win']      = match_df['H_Win5']      - match_df['A_Win5']
match_df['Diff_CS']       = match_df['H_CS5']       - match_df['A_CS5']
match_df['Diff_Streak']   = match_df['H_Streak3']   - match_df['A_Streak3']
match_df['Diff_Elo']      = match_df['H_Elo']       - match_df['A_Elo']
match_df['Diff_Scored']   = match_df['H_Scored5']   - match_df['A_Scored5']

# EWM diffs (à¹ƒà¸«à¸¡à¹ˆ)
match_df['Diff_Pts_ewm']  = match_df['H_Pts_ewm']  - match_df['A_Pts_ewm']
match_df['Diff_GF_ewm']   = match_df['H_GF_ewm']   - match_df['A_GF_ewm']
match_df['Diff_GD_ewm']   = match_df['H_GD_ewm']   - match_df['A_GD_ewm']

# Momentum (form à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡) (à¹ƒà¸«à¸¡à¹ˆ)
match_df['H_Momentum']    = match_df['H_Pts5']      - match_df['H_Pts10'] / 2
match_df['A_Momentum']    = match_df['A_Pts5']      - match_df['A_Pts10'] / 2
match_df['Diff_Momentum'] = match_df['H_Momentum']  - match_df['A_Momentum']

# Days rest diff (à¹ƒà¸«à¸¡à¹ˆ)
match_df['Diff_DaysRest'] = match_df['H_DaysRest']  - match_df['A_DaysRest']
match_df['H_DaysRest']    = match_df['H_DaysRest'].clip(1, 21)
match_df['A_DaysRest']    = match_df['A_DaysRest'].clip(1, 21)

# Draw-specific features (à¹ƒà¸«à¸¡à¹ˆ)
match_df['Diff_Draw5']    = match_df['H_Draw5']     - match_df['A_Draw5']   # draw rate diff
# à¸—à¸µà¸¡à¸—à¸µà¹ˆà¸—à¸±à¹‰à¸‡à¸„à¸¹à¹ˆà¸¢à¸´à¸‡à¸™à¹‰à¸­à¸¢ à¸¡à¸±à¸à¸ˆà¸° 0-0 à¸«à¸£à¸·à¸­ 1-1
match_df['Combined_GF']   = match_df['H_GF5']       + match_df['A_GF5']
match_df['Combined_GF_ewm']= match_df['H_GF_ewm']  + match_df['A_GF_ewm']
# GD variance à¸•à¹ˆà¸³ = à¹€à¸à¸¡à¹ƒà¸à¸¥à¹‰à¹€à¸„à¸µà¸¢à¸‡ = Draw à¸¡à¸²à¸à¸‚à¸¶à¹‰à¸™
match_df['Mean_GD_std']   = (match_df['H_GD_std'].fillna(2) + match_df['A_GD_std'].fillna(2)) / 2

# Elo features
match_df['H_Elo_norm']    = match_df['H_Elo']      / 1500
match_df['A_Elo_norm']    = match_df['A_Elo']      / 1500
match_df['Elo_ratio']     = match_df['H_Elo']      / (match_df['A_Elo'] + 1)
match_df['H_Elo_Home_norm']= match_df['H_Elo_Home'] / 1500   # NEW: home-specific elo
match_df['A_Elo_Away_norm']= match_df['A_Elo_Away'] / 1500   # NEW: away-specific elo

# Seasonal features (à¹ƒà¸«à¸¡à¹ˆ)
match_df['Month']         = match_df['Date_x'].dt.month
# à¸Šà¹ˆà¸§à¸‡à¸•à¹‰à¸™à¸¤à¸”à¸¹à¸à¸²à¸¥ (Aug-Oct=1), à¸à¸¥à¸²à¸‡ (Nov-Feb=2), à¸›à¸¥à¸²à¸¢ (Mar-May=3)
match_df['SeasonPhase']   = match_df['Month'].map(
    lambda m: 1 if m in [8,9,10] else (2 if m in [11,12,1,2] else 3)
)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ S4: DEEP FEATURE ENGINEERING (v4.0)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# 1) Momentum Slope â€” trend à¸‚à¸­à¸‡ form (à¸à¸³à¸¥à¸±à¸‡à¸”à¸µà¸‚à¸¶à¹‰à¸™ / à¸•à¸à¸¥à¸‡)
#    slope = (ewm - rolling10/2) / std   â†’  normalized momentum direction
match_df['H_Form_slope'] = (match_df['H_Pts_ewm'] - match_df['H_Pts10'] / 2) / (match_df['H_GD_std'].fillna(1) + 0.5)
match_df['A_Form_slope'] = (match_df['A_Pts_ewm'] - match_df['A_Pts10'] / 2) / (match_df['A_GD_std'].fillna(1) + 0.5)
match_df['Diff_Form_slope'] = match_df['H_Form_slope'] - match_df['A_Form_slope']

# 2) Home/Away Specific Form â€” à¹à¸¢à¸ form à¹€à¸«à¸¢à¹‰à¸²à¹à¸¥à¸°à¹€à¸¢à¸·à¸­à¸™à¸­à¸­à¸à¸ˆà¸²à¸à¸à¸±à¸™
#    à¹ƒà¸Šà¹‰ Elo à¹€à¸‰à¸à¸²à¸° venue à¹à¸—à¸™ (à¸—à¸³à¹à¸¥à¹‰à¸§à¹ƒà¸™ Elo_Home / Elo_Away)
#    à¹€à¸à¸´à¹ˆà¸¡ ratio: Elo_Home / Elo_overall = home advantage index
match_df['H_HomeAdvantage'] = match_df['H_Elo_Home'] / (match_df['H_Elo'] + 1)
match_df['A_AwayPenalty']   = match_df['A_Elo_Away'] / (match_df['A_Elo'] + 1)
match_df['Venue_edge']      = match_df['H_HomeAdvantage'] - match_df['A_AwayPenalty']

# 3) Weighted H2H â€” H2H à¸¥à¹ˆà¸²à¸ªà¸¸à¸”à¸¡à¸µà¸™à¹‰à¸³à¸«à¸™à¸±à¸à¸¡à¸²à¸à¸à¸§à¹ˆà¸² (à¹ƒà¸Šà¹‰ EWM à¸‚à¸­à¸‡ H2H)
#    H2H_HomeWinRate à¹à¸šà¸š cumulative à¸­à¸¢à¸¹à¹ˆà¹à¸¥à¹‰à¸§ à¹ƒà¸Šà¹‰à¸£à¹ˆà¸§à¸¡à¸à¸±à¸š H2H_DrawRate

# 4) Attack / Defense indices
match_df['H_AttackIdx']  = match_df['H_GF_ewm'] / (match_df['A_GA_ewm'].clip(0.3) + 0.01)
match_df['A_AttackIdx']  = match_df['A_GF_ewm'] / (match_df['H_GA_ewm'].clip(0.3) + 0.01)
match_df['Diff_AttackIdx'] = match_df['H_AttackIdx'] - match_df['A_AttackIdx']

# 5) Clean Sheet / Scored ratio (defensive strength)
match_df['H_DefStr']     = match_df['H_CS5']    / (match_df['H_GA5'].clip(0.1) + 0.1)
match_df['A_DefStr']     = match_df['A_CS5']    / (match_df['A_GA5'].clip(0.1) + 0.1)
match_df['Diff_DefStr']  = match_df['H_DefStr'] - match_df['A_DefStr']

# 6) Expected Tightness â€” à¸—à¸³à¸™à¸²à¸¢à¸§à¹ˆà¸²à¹€à¸à¸¡à¸™à¸µà¹‰à¸ˆà¸°à¸ªà¸¹à¸ªà¸µà¹„à¸«à¸¡ (Draw indicator)
match_df['Elo_closeness']   = 1 / (np.abs(match_df['Diff_Elo']) + 50)  # à¸¢à¸´à¹ˆà¸‡ Elo à¹ƒà¸à¸¥à¹‰ à¸¢à¸´à¹ˆà¸‡à¸ªà¸¹à¸‡
match_df['Form_closeness']  = 1 / (np.abs(match_df['Diff_Pts_ewm']) + 0.5)
match_df['Draw_likelihood'] = match_df['Elo_closeness'] * match_df['Form_closeness'] * match_df['Mean_GD_std'].clip(0.1)

print("âœ… Deep Feature Engineering (S4) computed")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ PHASE 1: xG MATCH-LEVEL FEATURES (à¸–à¹‰à¸² xG à¸à¸£à¹‰à¸­à¸¡)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if XG_AVAILABLE:
    match_df['Diff_xGF']        = match_df['H_xGF5']    - match_df['A_xGF5']
    match_df['Diff_xGA']        = match_df['H_xGA5']    - match_df['A_xGA5']
    match_df['Diff_xGD']        = match_df['H_xGD5']    - match_df['A_xGD5']
    match_df['Diff_xGF_ewm']    = match_df['H_xGF_ewm'] - match_df['A_xGF_ewm']
    match_df['Diff_xG_overperf']= match_df['H_xG_overperf'] - match_df['A_xG_overperf']
    match_df['Diff_xGF_slope']  = match_df['H_xGF_slope']   - match_df['A_xGF_slope']
    # xG-based attack/defense index (à¹à¸£à¸‡à¸à¸§à¹ˆà¸² GF à¸˜à¸£à¸£à¸¡à¸”à¸²à¹€à¸à¸£à¸²à¸° adjust à¸„à¸§à¸²à¸¡à¹‚à¸Šà¸„à¸”à¸µ)
    match_df['H_xAttackIdx']    = match_df['H_xGF_ewm'] / (match_df['A_xGA_ewm'].clip(0.3) + 0.01)
    match_df['A_xAttackIdx']    = match_df['A_xGF_ewm'] / (match_df['H_xGA_ewm'].clip(0.3) + 0.01)
    match_df['Diff_xAttackIdx'] = match_df['H_xAttackIdx'] - match_df['A_xAttackIdx']
    print("âœ… xG match-level features computed")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ PHASE 2: BETTING MARKET FEATURES (à¸–à¹‰à¸² odds à¸à¸£à¹‰à¸­à¸¡ à¹à¸¥à¸°à¹€à¸›à¸´à¸”à¹ƒà¸Šà¹‰ market)
#    implied probability = market consensus
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if USE_MARKET_FEATURES and ODDS_AVAILABLE:
    # implied prob à¸•à¸£à¸‡à¹†
    match_df['Mkt_ImpH']    = match_df['_ImpH']
    match_df['Mkt_ImpD']    = match_df['_ImpD']
    match_df['Mkt_ImpA']    = match_df['_ImpA']
    # market confidence: home - away implied spread
    match_df['Mkt_Spread']  = match_df['_ImpH'] - match_df['_ImpA']
    # Draw premium: implied draw prob à¹€à¸—à¸µà¸¢à¸šà¸à¸±à¸š base rate ~26%
    match_df['Mkt_DrawPrem']= match_df['_ImpD'] - 0.26
    # Model vs market delta (à¸„à¸³à¸™à¸§à¸“à¸«à¸¥à¸±à¸‡ model trained â€” placeholder à¸•à¸­à¸™à¸™à¸µà¹‰)
    match_df['Mkt_Overround']= match_df['_Overround']
    print("âœ… Betting market features computed (Phase 2 ACTIVE ğŸ”¥)")
else:
    for col in ['Mkt_ImpH','Mkt_ImpD','Mkt_ImpA','Mkt_Spread','Mkt_DrawPrem','Mkt_Overround']:
        match_df[col] = np.nan

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 8) HEAD-TO-HEAD (à¸£à¸§à¸¡ Draw Rate à¸”à¹‰à¸§à¸¢) (à¹ƒà¸«à¸¡à¹ˆ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def compute_h2h(data):
    """H2H win rate + draw rate à¸‚à¸­à¸‡à¸—à¸µà¸¡à¹€à¸«à¸¢à¹‰à¸² (à¹„à¸¡à¹ˆà¸¡à¸µ leakage)"""
    h2h_home_wins = {}
    h2h_draws     = {}
    h2h_total     = {}
    h2h_rates     = []
    h2h_draw_rates = []

    for _, row in data.sort_values('Date_x').iterrows():
        home = row['HomeTeam']
        away = row['AwayTeam']
        key  = tuple(sorted([home, away]))

        total = max(h2h_total.get(key, 0), 1)
        h2h_rates.append(h2h_home_wins.get((home, away), 0) / total)
        h2h_draw_rates.append(h2h_draws.get(key, 0) / total)

        if key not in h2h_total:      h2h_total[key] = 0
        if (home, away) not in h2h_home_wins: h2h_home_wins[(home, away)] = 0
        if key not in h2h_draws:      h2h_draws[key] = 0

        h2h_total[key] += 1
        if row['Win_x'] == 1:   h2h_home_wins[(home, away)] += 1
        if row['Draw_x'] == 1:  h2h_draws[key] += 1

    return h2h_rates, h2h_draw_rates

match_df = match_df.sort_values('Date_x').reset_index(drop=True)
h2h_win_rates, h2h_draw_rates = compute_h2h(match_df)
match_df['H2H_HomeWinRate'] = h2h_win_rates
match_df['H2H_DrawRate']    = h2h_draw_rates   # NEW
print("âœ… H2H (Win + Draw rate) computed")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 9) MERGE HOME/AWAY STRENGTH + TARGET
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Merge sequential (leak-free) stats from data â†’ match_df via MatchID
seq_stats = data[['MatchID', '_HomeWinRate_seq', '_AwayWinRate_seq', '_HomeDrawRate_seq']].copy()
match_df = match_df.merge(seq_stats, on='MatchID', how='left')

# Use sequential versions as primary â€” fall back to static for prediction helpers
match_df['HomeWinRate']  = match_df['_HomeWinRate_seq'].fillna(0.45)
match_df['AwayWinRate']  = match_df['_AwayWinRate_seq'].fillna(0.30)
match_df['HomeDrawRate'] = match_df['_HomeDrawRate_seq'].fillna(0.25)
match_df.drop(columns=['_HomeWinRate_seq','_AwayWinRate_seq','_HomeDrawRate_seq'], inplace=True)
print("âœ… Sequential (leak-free) stats merged into match_df")

def get_result(row):
    if row['Win_x'] == 1:    return 2   # Home Win
    elif row['Draw_x'] == 1: return 1   # Draw
    else:                     return 0  # Away Win

match_df['Result3'] = match_df.apply(get_result, axis=1)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 10) FEATURE LIST (à¹€à¸à¸´à¹ˆà¸¡à¸ˆà¸²à¸ 24 â†’ 40+ features)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

FEATURES = [
    # â”€â”€ Elo Features â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    'Diff_Elo', 'Elo_ratio', 'H_Elo_norm', 'A_Elo_norm',
    'H_Elo_Home_norm', 'A_Elo_Away_norm',

    # â”€â”€ Standard Rolling Form â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    'H_GF5', 'H_GA5', 'H_Pts5', 'H_Streak3', 'H_CS5', 'H_Scored5',
    'A_GF5', 'A_GA5', 'A_Pts5', 'A_Streak3', 'A_CS5', 'A_Scored5',

    # â”€â”€ Difference Features â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    'Diff_Pts', 'Diff_GF', 'Diff_GA', 'Diff_GD',
    'Diff_Win', 'Diff_CS', 'Diff_Streak', 'Diff_Scored',

    # â”€â”€ EWM Features â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    'H_GF_ewm', 'H_GA_ewm', 'H_Pts_ewm',
    'A_GF_ewm', 'A_GA_ewm', 'A_Pts_ewm',
    'Diff_Pts_ewm', 'Diff_GF_ewm', 'Diff_GD_ewm',

    # â”€â”€ Momentum â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    'Diff_Momentum',

    # â”€â”€ Draw-Specific Features â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    'H_Draw5', 'A_Draw5', 'Diff_Draw5',
    'H2H_DrawRate',
    'Combined_GF', 'Mean_GD_std',

    # â”€â”€ H2H â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    'H2H_HomeWinRate',

    # â”€â”€ Home/Away Strength â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    'HomeWinRate', 'AwayWinRate', 'HomeDrawRate',

    # â”€â”€ Days Rest â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    'H_DaysRest', 'A_DaysRest', 'Diff_DaysRest',

    # â”€â”€ Seasonal â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    'Month', 'SeasonPhase',

    # â”€â”€ ğŸ”¥ S4: Deep Features â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    'H_Form_slope', 'A_Form_slope', 'Diff_Form_slope',   # momentum slope
    'H_HomeAdvantage', 'A_AwayPenalty', 'Venue_edge',    # venue-specific
    'H_AttackIdx', 'A_AttackIdx', 'Diff_AttackIdx',      # attack index
    'H_DefStr', 'A_DefStr', 'Diff_DefStr',               # defensive strength
    'Elo_closeness', 'Form_closeness', 'Draw_likelihood', # draw signal
]

# ğŸ”¥ PHASE 1: à¹€à¸à¸´à¹ˆà¸¡ xG features à¸–à¹‰à¸² dataset à¸¡à¸µ xG
_XG_FEATURES = [
    'H_xGF5', 'H_xGA5', 'H_xGD5', 'H_xGF_ewm', 'H_xGA_ewm',
    'H_xG_overperf', 'H_xGF_slope',
    'A_xGF5', 'A_xGA5', 'A_xGD5', 'A_xGF_ewm', 'A_xGA_ewm',
    'A_xG_overperf', 'A_xGF_slope',
    'Diff_xGF', 'Diff_xGA', 'Diff_xGD', 'Diff_xGF_ewm',
    'Diff_xG_overperf', 'Diff_xGF_slope',
    'H_xAttackIdx', 'A_xAttackIdx', 'Diff_xAttackIdx',
]
if XG_AVAILABLE:
    # à¹€à¸à¸´à¹ˆà¸¡à¹€à¸‰à¸à¸²à¸° columns à¸—à¸µà¹ˆà¸¡à¸µà¸­à¸¢à¸¹à¹ˆà¸ˆà¸£à¸´à¸‡à¹ƒà¸™ match_df
    FEATURES += [f for f in _XG_FEATURES if f in match_df.columns]
    print(f"âœ… Phase 1 xG: +{len([f for f in _XG_FEATURES if f in match_df.columns])} features")

# ğŸ”¥ PHASE 2: à¹€à¸à¸´à¹ˆà¸¡ Betting Market features à¸–à¹‰à¸² dataset à¸¡à¸µ odds à¹à¸¥à¸°à¹€à¸›à¸´à¸”à¹ƒà¸Šà¹‰ market
_MKT_FEATURES = [
    'Mkt_ImpH', 'Mkt_ImpD', 'Mkt_ImpA',
    'Mkt_Spread', 'Mkt_DrawPrem', 'Mkt_Overround',
]
if USE_MARKET_FEATURES and ODDS_AVAILABLE:
    FEATURES += [f for f in _MKT_FEATURES if f in match_df.columns]
    print(f"âœ… Phase 2 Market: +{len([f for f in _MKT_FEATURES if f in match_df.columns])} features")

# à¸à¸£à¸­à¸‡ features à¸—à¸µà¹ˆà¸¡à¸µà¸­à¸¢à¸¹à¹ˆà¸ˆà¸£à¸´à¸‡à¹ƒà¸™ match_df à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™ (safety net)
FEATURES = [f for f in FEATURES if f in match_df.columns]

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ FIX 4: à¸•à¸±à¸” Low-Importance Features (à¸ˆà¸²à¸ SHAP analysis)
#    à¸¥à¸” features à¸ˆà¸²à¸ 95 â†’ ~88 à¸•à¸±à¸§ à¹€à¸à¸·à¹ˆà¸­à¸¥à¸” noise + overfitting
#    à¸ˆà¸²à¸ SHAP: H_CS5, A_CS5, Diff_CS, Diff_Scored,
#              H_Draw5, H2H_DrawRate, H2H_HomeWinRate à¸¡à¸µ importance à¸•à¹ˆà¸³à¸ªà¸¸à¸”
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

LOW_IMPORTANCE_FEATURES = [
    'H_CS5', 'A_CS5',           # Clean sheet â€” à¸‹à¹‰à¸³à¸‹à¹‰à¸­à¸™à¸à¸±à¸š GA/DefStr features
    'Diff_CS',                   # Derived à¸ˆà¸²à¸ CS5 à¸—à¸µà¹ˆà¸•à¸±à¸”à¹„à¸›à¹à¸¥à¹‰à¸§
    'Diff_Scored',               # à¸‹à¹‰à¸³à¸à¸±à¸š Diff_AttackIdx + Diff_GF
    'H_Draw5',                   # Draw rate à¸£à¸²à¸¢à¸—à¸µà¸¡ â€” sample à¹€à¸¥à¹‡à¸, noisy
    'H2H_DrawRate',              # H2H sample à¹€à¸¥à¹‡à¸à¸¡à¸²à¸ (< 10 à¸™à¸±à¸”à¸ªà¹ˆà¸§à¸™à¹ƒà¸«à¸à¹ˆ)
    'H2H_HomeWinRate',           # H2H â€” à¹€à¸Šà¹ˆà¸™à¸à¸±à¸™ sample à¸™à¹‰à¸­à¸¢
]

FEATURES_PRUNED = [f for f in FEATURES if f not in LOW_IMPORTANCE_FEATURES]
print(f"âœ… Features v5.0: {len(FEATURES)} à¸•à¸±à¸§  "
      f"(xG={'âœ…' if XG_AVAILABLE else 'âŒ'}  Market={'âœ…' if ODDS_AVAILABLE else 'âŒ'})")
print(f"âœ… Features v5.1 (pruned): {len(FEATURES_PRUNED)} à¸•à¸±à¸§  (-{len(FEATURES)-len(FEATURES_PRUNED)} low-importance)")

# à¹ƒà¸Šà¹‰ pruned version à¹€à¸›à¹‡à¸™ default
FEATURES = FEATURES_PRUNED

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 11) TIME-BASED SPLIT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# à¹€à¸¥à¸·à¸­à¸ CORE_FEATURES à¸ˆà¸²à¸ columns à¸—à¸µà¹ˆà¹à¸—à¸šà¹„à¸¡à¹ˆà¸¡à¸µ NaN à¹€à¸à¸·à¹ˆà¸­à¹„à¸¡à¹ˆà¹ƒà¸«à¹‰à¸—à¸´à¹‰à¸‡à¹à¸¡à¸•à¸Šà¹Œà¹€à¸¢à¸­à¸°à¹€à¸à¸´à¸™à¹„à¸›
core_feature_threshold = 0.95
core_feature_stats = match_df[FEATURES].notna().mean()
CORE_FEATURES = [f for f in FEATURES if core_feature_stats.get(f, 0) >= core_feature_threshold]

if len(CORE_FEATURES) < 20:
    # safety fallback: à¸–à¹‰à¸²à¹€à¸¥à¸·à¸­à¸à¹„à¸”à¹‰à¸™à¹‰à¸­à¸¢à¹€à¸à¸´à¸™à¹„à¸› à¹ƒà¸«à¹‰à¹ƒà¸Šà¹‰ FEATURES à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸” à¹à¸•à¹ˆà¸à¸´à¸¡à¸à¹Œà¹€à¸•à¸·à¸­à¸™
    CORE_FEATURES = FEATURES.copy()
    print("âš ï¸  CORE_FEATURES coverage à¸•à¹ˆà¸³ â€” fallback à¹ƒà¸Šà¹‰ FEATURES à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸ªà¸³à¸«à¸£à¸±à¸š dropna")
else:
    print(f"âœ… CORE_FEATURES selected: {len(CORE_FEATURES)} / {len(FEATURES)} "
          f"(>= {core_feature_threshold*100:.0f}% non-NaN)")

match_df_clean = match_df.dropna(subset=CORE_FEATURES + ['Result3']).reset_index(drop=True)
print(f"âœ… match_df_clean rows after CORE_FEATURES dropna: {len(match_df_clean)} à¸ˆà¸²à¸à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸” {len(match_df)}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ FIX 1+2: SEASON-BASED SPLIT (à¹à¸—à¸™ quantile 80/20)
#    Season = Aug â†’ Jul à¸›à¸µà¸–à¸±à¸”à¹„à¸›
#    Train: à¸—à¸¸à¸ season à¸à¹ˆà¸­à¸™ TEST_SEASON
#    Test : TEST_SEASON à¹€à¸•à¹‡à¸¡à¸‹à¸µà¸‹à¸±à¹ˆà¸™ (â‰¥380 à¸™à¸±à¸”)
#    â†’ test set à¹ƒà¸«à¸à¹ˆà¸à¸§à¹ˆà¸²à¹€à¸”à¸´à¸¡ 6Ã— à¹à¸¥à¸° reflect à¸„à¸§à¸²à¸¡à¹€à¸›à¹‡à¸™à¸ˆà¸£à¸´à¸‡
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def get_season(date):
    """Aug-Dec â†’ season=year, Jan-Jul â†’ season=year-1"""
    if pd.isna(date): return np.nan
    return date.year if date.month >= 8 else date.year - 1

match_df_clean['Season'] = match_df_clean['Date_x'].apply(get_season)

# à¸«à¸² season à¸—à¸µà¹ˆà¸ˆà¸šà¹à¸¥à¹‰à¸§ (à¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆà¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™) à¹à¸¥à¸°à¸¡à¸µà¸™à¸±à¸”à¸à¸­
season_counts = match_df_clean.groupby('Season').size()
completed_seasons = season_counts[season_counts >= 200].index.tolist()
completed_seasons = sorted([s for s in completed_seasons if s < get_season(TODAY)])

if len(completed_seasons) >= 2:
    # à¹ƒà¸Šà¹‰ season à¸¥à¹ˆà¸²à¸ªà¸¸à¸”à¸—à¸µà¹ˆà¸ˆà¸šà¹à¸¥à¹‰à¸§à¹€à¸›à¹‡à¸™ test
    TEST_SEASON  = completed_seasons[-1]
    TRAIN_SEASON = completed_seasons[:-1]   # à¸—à¸¸à¸ season à¸à¹ˆà¸­à¸™à¸«à¸™à¹‰à¸²
    train = match_df_clean[match_df_clean['Season'].isin(TRAIN_SEASON)]
    test  = match_df_clean[match_df_clean['Season'] == TEST_SEASON]
    print(f"\nâœ… Season-Based Split (FIX 1+2):")
    print(f"   Train seasons : {sorted(TRAIN_SEASON)}  ({len(train)} matches)")
    print(f"   Test season   : {TEST_SEASON}           ({len(test)} matches)")
else:
    # fallback: index-based 80/20 split (à¹ƒà¸Šà¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸” ~3,000+ à¸™à¸±à¸”à¸ªà¸³à¸«à¸£à¸±à¸š train)
    sorted_df = match_df_clean.sort_values('Date_x').reset_index(drop=True)
    split_idx = int(len(sorted_df) * 0.8)
    train = sorted_df.iloc[:split_idx].copy()
    test  = sorted_df.iloc[split_idx:].copy()
    TEST_SEASON  = None
    TRAIN_SEASON = None
    print(f"\nâš ï¸  Season-based split à¹ƒà¸Šà¹‰à¹„à¸¡à¹ˆà¹„à¸”à¹‰ â€” fallback à¹€à¸›à¹‡à¸™ index 80/20")
    print(f"   Train matches : {len(train)}")
    print(f"   Test  matches : {len(test)}")

X_train = train[FEATURES].fillna(0)
y_train = train['Result3']
X_test  = test[FEATURES].fillna(0)
y_test  = test['Result3']

print(f"\nTrain: {len(train)}  |  Test: {len(test)}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 12) UPGRADED ENSEMBLE MODEL
#     LR + RF + GBT + ExtraTrees + MLP â†’ Stacking + Calibration
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

scaler = StandardScaler()
X_train_sc = scaler.fit_transform(X_train)
X_test_sc  = scaler.transform(X_test)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ S3: OPTUNA HYPERPARAMETER TUNING (LightGBM)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def tune_lgbm_optuna(X_tr, y_tr, n_trials=40, timeout=120):
    """
    Optuna Bayesian optimization à¸ªà¸³à¸«à¸£à¸±à¸š LightGBM
    ğŸ”¥ FIX A: à¹ƒà¸Šà¹‰ log loss à¹à¸—à¸™ macro F1 à¹€à¸›à¹‡à¸™ objective
              â†’ à¹‚à¸¡à¹€à¸”à¸¥à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰ calibrated probability à¸ˆà¸£à¸´à¸‡ à¹† à¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆà¹à¸„à¹ˆ classification boundary
              â†’ à¸Šà¹ˆà¸§à¸¢ Draw calibration à¹‚à¸”à¸¢à¸•à¸£à¸‡ (Brier Skill Score)
    à¹ƒà¸Šà¹‰ TimeSeriesSplit CV à¹€à¸à¸·à¹ˆà¸­à¸›à¹‰à¸­à¸‡à¸à¸±à¸™ future leakage
    """
    if not LGBM_AVAILABLE or not OPTUNA_AVAILABLE:
        print("  âš ï¸  Optuna/LGBM à¹„à¸¡à¹ˆà¸à¸£à¹‰à¸­à¸¡ â€” à¹ƒà¸Šà¹‰ default params")
        return {}

    tscv = TimeSeriesSplit(n_splits=4)

    def objective(trial):
        params = {
            'n_estimators':      trial.suggest_int('n_estimators', 200, 800),
            'learning_rate':     trial.suggest_float('learning_rate', 0.01, 0.15, log=True),
            'max_depth':         trial.suggest_int('max_depth', 3, 8),
            'num_leaves':        trial.suggest_int('num_leaves', 15, 63),
            'min_child_samples': trial.suggest_int('min_child_samples', 10, 50),
            'subsample':         trial.suggest_float('subsample', 0.6, 1.0),
            'colsample_bytree':  trial.suggest_float('colsample_bytree', 0.6, 1.0),
            'reg_alpha':         trial.suggest_float('reg_alpha', 1e-4, 1.0, log=True),
            'reg_lambda':        trial.suggest_float('reg_lambda', 1e-4, 1.0, log=True),
            # ğŸ”¥ FIX A: à¹€à¸à¸´à¹ˆà¸¡ multiclass objective à¹€à¸à¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¹‚à¸¡à¹€à¸”à¸¥à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰ probability à¸ˆà¸£à¸´à¸‡
            'objective':         'multiclass',
            'metric':            'multi_logloss',
            'num_class':         3,
            'class_weight':      'balanced',
            'random_state':      42,
            'n_jobs':            -1,
            'verbose':           -1,
        }
        model = lgb.LGBMClassifier(**params)
        scores = []
        for train_idx, val_idx in tscv.split(X_tr):
            model.fit(X_tr[train_idx], y_tr[train_idx])
            # ğŸ”¥ FIX A: Optimize log loss à¹à¸—à¸™ F1 â€” proper scoring rule à¸ªà¸³à¸«à¸£à¸±à¸š probability
            #    log loss à¸šà¸±à¸‡à¸„à¸±à¸šà¹ƒà¸«à¹‰ model output probability à¸—à¸µà¹ˆ calibrated à¸ˆà¸£à¸´à¸‡ à¹†
            #    à¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆà¹à¸„à¹ˆà¸—à¸²à¸¢ class à¹ƒà¸«à¹‰à¸–à¸¹à¸ â†’ à¸Šà¹ˆà¸§à¸¢ Draw calibration à¹‚à¸”à¸¢à¸•à¸£à¸‡
            prob = model.predict_proba(X_tr[val_idx])
            scores.append(-log_loss(y_tr[val_idx], prob))  # negative à¹€à¸à¸£à¸²à¸° maximize
        return np.mean(scores)

    study = optuna.create_study(direction='maximize',
                                sampler=optuna.samplers.TPESampler(seed=42))
    study.optimize(objective, n_trials=n_trials, timeout=timeout, show_progress_bar=False)
    print(f"  âœ… Optuna best macro F1: {study.best_value:.4f}  (trials={len(study.trials)})")
    print(f"  Best params: n_est={study.best_params.get('n_estimators')}, "
          f"lr={study.best_params.get('learning_rate'):.3f}, "
          f"leaves={study.best_params.get('num_leaves')}, "
          f"depth={study.best_params.get('max_depth')}")
    return study.best_params


print("\nğŸ”¥ S3: Optuna LightGBM Tuning (max 40 trials / 2 min)...")
best_lgbm_params = tune_lgbm_optuna(X_train_sc, y_train.values)


def get_cv_lgbm_params():
    """
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    ğŸ”¥ FIX CONSISTENCY: Single source of truth à¸ªà¸³à¸«à¸£à¸±à¸š LightGBM params
       à¹ƒà¸Šà¹‰à¸—à¸¸à¸à¸—à¸µà¹ˆ â€” rolling CV, walk-forward, ablation test
       à¸›à¹‰à¸­à¸‡à¸à¸±à¸™ bug à¸—à¸µà¹ˆà¹à¸•à¹ˆà¸¥à¸° function à¹ƒà¸Šà¹‰ params à¸•à¹ˆà¸²à¸‡à¸à¸±à¸™
       à¸—à¸³à¹ƒà¸«à¹‰à¸•à¸±à¸§à¹€à¸¥à¸‚à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸à¸±à¸™à¹„à¸”à¹‰à¸ˆà¸£à¸´à¸‡
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    base = {
        'n_estimators':      300,
        'learning_rate':     0.05,
        'max_depth':         5,
        'num_leaves':        25,
        'min_child_samples': 15,
        'subsample':         0.8,
        'colsample_bytree':  0.8,
        'objective':         'multiclass',   # ğŸ”¥ consistent: log loss objective
        'metric':            'multi_logloss',
        'num_class':         3,
        'class_weight':      'balanced',
        'random_state':      42,
        'n_jobs':            -1,
        'verbose':           -1,
    }
    # merge Optuna best params (à¸–à¹‰à¸²à¸¡à¸µ)
    optuna_keys = ['learning_rate', 'max_depth', 'num_leaves', 'n_estimators',
                   'min_child_samples', 'subsample', 'colsample_bytree',
                   'reg_alpha', 'reg_lambda']
    base.update({k: v for k, v in best_lgbm_params.items() if k in optuna_keys})
    return base


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ S5: SMOTE â€” oversample Draw class
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def apply_smote(X_tr, y_tr):
    """
    à¹ƒà¸Šà¹‰ SMOTE à¹€à¸à¸´à¹ˆà¸¡ Draw samples à¹ƒà¸«à¹‰ balance à¸à¸±à¸š Home/Away Win
    à¹€à¸‰à¸à¸²à¸° Draw class à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™ à¹„à¸¡à¹ˆà¹à¸•à¸° class à¸­à¸·à¹ˆà¸™
    """
    if not SMOTE_AVAILABLE:
        print("  âš ï¸  SMOTE à¹„à¸¡à¹ˆà¸à¸£à¹‰à¸­à¸¡ â€” à¹ƒà¸Šà¹‰ class_weight à¹à¸—à¸™")
        return X_tr, y_tr

    counts = np.bincount(y_tr)
    # ğŸ”¥ FIX B: à¸¥à¸” target à¸ˆà¸²à¸ 80% â†’ 50% à¸‚à¸­à¸‡ majority class
    #    SMOTE 80% à¸—à¸³à¹ƒà¸«à¹‰à¹‚à¸¡à¹€à¸”à¸¥ overestimate draw probability (+11% bias)
    #    50% à¸”à¸±à¸™ draw à¸‚à¸¶à¹‰à¸™à¸à¸­à¹ƒà¸«à¹‰ recall à¸”à¸µà¸‚à¸¶à¹‰à¸™ à¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸—à¸³à¸¥à¸²à¸¢ precision
    target_draw = int(max(counts) * 0.50)
    if target_draw <= counts[1]:
        print(f"  â„¹ï¸  Draw ({counts[1]}) à¸¡à¸²à¸à¸à¸­à¹à¸¥à¹‰à¸§ â€” à¸‚à¹‰à¸²à¸¡ SMOTE")
        return X_tr, y_tr

    sm = SMOTE(
        sampling_strategy={1: target_draw},   # class 1 = Draw
        k_neighbors=min(5, counts[1]-1),
        random_state=42
    )
    X_res, y_res = sm.fit_resample(X_tr, y_tr)
    new_counts = np.bincount(y_res)
    print(f"  âœ… SMOTE: Draw {counts[1]} â†’ {new_counts[1]}  "
          f"(total {len(y_tr)} â†’ {len(y_res)})")
    return X_res, y_res


print("\nğŸ”¥ S5: Applying SMOTE for Draw class...")
X_train_smote, y_train_smote = apply_smote(X_train_sc, y_train.values)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ S1: 2-STAGE MODEL (à¹ƒà¸«à¸à¹ˆà¸—à¸µà¹ˆà¸ªà¸¸à¸” â€” à¹à¸à¹‰ Draw à¹‚à¸”à¸¢à¸•à¸£à¸‡)
#
#   Stage 1: à¹à¸¢à¸ Draw vs Not-Draw
#            à¹‚à¸¡à¹€à¸”à¸¥à¸™à¸µà¹‰à¸–à¸²à¸¡ "à¹€à¸à¸¡à¸™à¸µà¹‰à¸ˆà¸°à¹€à¸ªà¸¡à¸­à¹„à¸«à¸¡?"
#   Stage 2: à¹à¸¢à¸ Home Win vs Away Win (à¹€à¸‰à¸à¸²à¸° Not-Draw)
#            à¹‚à¸¡à¹€à¸”à¸¥à¸™à¸µà¹‰à¸–à¸²à¸¡ "à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¹€à¸ªà¸¡à¸­ à¹ƒà¸„à¸£à¸Šà¸™à¸°?"
#
#   Final prediction = combine stage 1 + stage 2 proba
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\nğŸ”§ Building v4.0 â€” 2-Stage Model...")

# â”€â”€â”€ Build Stage 1: Draw vs Not-Draw â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
y_train_draw   = (y_train_smote == 1).astype(int)   # 1=Draw, 0=Not Draw
y_train_nodraw = y_train_smote[y_train_smote != 1]   # only 0 (Away) and 2 (Home)
X_train_nodraw = X_train_smote[y_train_smote != 1]

# Stage 1 LightGBM params
if LGBM_AVAILABLE:
    stage1_params = {**{
        'n_estimators': 400, 'learning_rate': 0.05, 'max_depth': 5,
        'num_leaves': 25, 'min_child_samples': 15, 'subsample': 0.8,
        'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1,
        'class_weight': 'balanced', 'random_state': 42, 'n_jobs': -1, 'verbose': -1,
    }, **{k: v for k, v in best_lgbm_params.items() if k in [
        'learning_rate', 'max_depth', 'num_leaves', 'min_child_samples',
        'subsample', 'colsample_bytree', 'reg_alpha', 'reg_lambda', 'n_estimators'
    ]}}
    stage1_model = lgb.LGBMClassifier(**stage1_params)
    stage2_model = lgb.LGBMClassifier(**{**stage1_params, 'class_weight': 'balanced'})
    print("  Stage 1 (Draw vs Not): LightGBM ğŸ”¥")
    print("  Stage 2 (Home vs Away): LightGBM ğŸ”¥")
else:
    stage1_model = GradientBoostingClassifier(
        n_estimators=300, max_depth=4, learning_rate=0.05,
        subsample=0.8, random_state=42
    )
    stage2_model = GradientBoostingClassifier(
        n_estimators=300, max_depth=4, learning_rate=0.05,
        subsample=0.8, random_state=42
    )
    print("  Stage 1 (Draw vs Not): GBT")
    print("  Stage 2 (Home vs Away): GBT")

# Train Stage 1
stage1_model.fit(X_train_smote, y_train_draw)
print("  âœ… Stage 1 trained")

# Train Stage 2 (only on non-draw matches)
# Remap: 0 (Away Win) â†’ 0,  2 (Home Win) â†’ 1
y_train_nodraw_bin = (y_train_nodraw == 2).astype(int)
stage2_model.fit(X_train_nodraw, y_train_nodraw_bin)
print("  âœ… Stage 2 trained")

# â”€â”€â”€ Calibrate both stages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("  ğŸ¯ Calibrating stages (isotonic)...")
try:
    stage1_cal = CalibratedClassifierCV(stage1_model, method='isotonic', cv=3)
    stage1_cal.fit(X_train_smote, y_train_draw)
    stage2_cal = CalibratedClassifierCV(stage2_model, method='isotonic', cv=3)
    stage2_cal.fit(X_train_nodraw, y_train_nodraw_bin)
    print("  âœ… Calibration done")
except Exception as e:
    print(f"  âš ï¸  Calibration failed: {e}  â€” using raw models")
    stage1_cal = stage1_model
    stage2_cal = stage2_model


def predict_2stage(X, stage1=None, stage2=None):
    """
    2-Stage prediction:
    P(Away Win) = P(Not Draw) Ã— P(Away | Not Draw)
    P(Home Win) = P(Not Draw) Ã— P(Home | Not Draw)
    P(Draw)     = P(Draw from stage1)
    """
    if stage1 is None: stage1 = stage1_cal
    if stage2 is None: stage2 = stage2_cal

    p_draw_stage1  = stage1.predict_proba(X)[:, 1]   # P(Draw)
    p_notdraw      = 1 - p_draw_stage1                # P(Not Draw)

    p_home_given_nd = stage2.predict_proba(X)[:, 1]  # P(Home | Not Draw)
    p_away_given_nd = 1 - p_home_given_nd

    p_home_win = p_notdraw * p_home_given_nd
    p_away_win = p_notdraw * p_away_given_nd
    p_draw     = p_draw_stage1

    # Normalize
    total = p_home_win + p_draw + p_away_win
    p_home_win /= total; p_draw /= total; p_away_win /= total

    proba = np.column_stack([p_away_win, p_draw, p_home_win])
    return proba


# â”€â”€â”€ 2-Stage Test Evaluation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
proba_2stage = predict_2stage(X_test_sc)
y_pred_2stage_raw = np.argmax(proba_2stage, axis=1)
acc_2stage = accuracy_score(y_test, y_pred_2stage_raw)

print(f"\n===== 2-STAGE RAW RESULTS =====")
print(f"Accuracy: {round(acc_2stage*100, 2)}%")
print(classification_report(y_test, y_pred_2stage_raw,
                             target_names=['Away Win','Draw','Home Win']))

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ PHASE 3: POISSON HYBRID BLEND â€” helper functions
#    (execution block à¸­à¸¢à¸¹à¹ˆà¸«à¸¥à¸±à¸‡ Poisson model training)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def build_poisson_proba_for_test(test_df, poisson_features, poisson_scaler,
                                  home_poisson_model, away_poisson_model):
    """
    à¸„à¸³à¸™à¸§à¸“ Poisson proba à¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸¸à¸à¹à¸¡à¸•à¸Šà¹Œà¹ƒà¸™ test set
    Return array shape (n, 3): [p_away, p_draw, p_home]
    """
    pf_avail = [f for f in poisson_features if f in test_df.columns]
    X_pois = test_df[pf_avail].fillna(0)
    X_pois_sc = poisson_scaler.transform(X_pois)

    home_xg_arr = np.clip(home_poisson_model.predict(X_pois_sc), 0.3, 6.0)
    away_xg_arr = np.clip(away_poisson_model.predict(X_pois_sc), 0.3, 6.0)

    proba_poisson = np.zeros((len(test_df), 3))  # [away, draw, home]
    for i, (hxg, axg) in enumerate(zip(home_xg_arr, away_xg_arr)):
        ph, pd_, pa = poisson_win_draw_loss(hxg, axg)
        proba_poisson[i] = [pa, pd_, ph]
    return proba_poisson


def blend_ml_poisson(ml_proba, poisson_proba, alpha=0.6):
    """
    Blend ML + Poisson probabilities
    alpha = weight for ML (1-alpha = Poisson weight)
    Normalize à¸«à¸¥à¸±à¸‡ blend
    """
    blended = alpha * ml_proba + (1 - alpha) * poisson_proba
    row_sums = blended.sum(axis=1, keepdims=True)
    return blended / np.where(row_sums > 0, row_sums, 1)


def suppress_draw_proba(proba, draw_factor=0.85):
    """
    ğŸ”¥ FIX C: Draw Suppression â€” à¹à¸à¹‰ Systematic Bias +11%
    à¹‚à¸¡à¹€à¸”à¸¥à¸¡à¸µà¹à¸™à¸§à¹‚à¸™à¹‰à¸¡ overestimate draw probability à¸­à¸¢à¹ˆà¸²à¸‡à¸ªà¸¡à¹ˆà¸³à¹€à¸ªà¸¡à¸­
    à¸à¸²à¸£ multiply draw proba à¸”à¹‰à¸§à¸¢ factor < 1 à¹à¸¥à¹‰à¸§ re-normalize
    à¸ˆà¸°à¸”à¸¶à¸‡ calibration à¸à¸¥à¸±à¸šà¸¡à¸²à¹ƒà¸à¸¥à¹‰ base rate (~23%) à¸¡à¸²à¸à¸‚à¸¶à¹‰à¸™
    draw_factor=0.85 â†’ à¸¥à¸” draw prob à¸¥à¸‡ ~15% à¸à¹ˆà¸­à¸™ normalize
    à¸„à¹ˆà¸²à¸™à¸µà¹‰à¹„à¸”à¹‰à¸ˆà¸²à¸: systematic_bias â‰ˆ +11% â†’ factor â‰ˆ 1 - (0.11/0.32) â‰ˆ 0.66
    à¹à¸•à¹ˆà¹ƒà¸Šà¹‰ 0.85 à¹€à¸à¸·à¹ˆà¸­ conservative à¹„à¸¡à¹ˆà¹ƒà¸«à¹‰ overcorrect à¸à¸¥à¸±à¸š
    """
    suppressed = proba.copy()
    suppressed[:, 1] *= draw_factor   # column 1 = Draw
    row_sums = suppressed.sum(axis=1, keepdims=True)
    return suppressed / np.where(row_sums > 0, row_sums, 1)


def optimize_blend_alpha(ml_proba, poisson_proba, y_true, alphas=None):
    """Grid search à¸«à¸² alpha à¸—à¸µà¹ˆà¹ƒà¸«à¹‰ accuracy à¸ªà¸¹à¸‡à¸ªà¸¸à¸”"""
    from sklearn.metrics import f1_score
    if alphas is None:
        alphas = np.arange(0.3, 1.01, 0.05)
    best_alpha, best_score = 0.6, 0.0
    for a in alphas:
        blended = blend_ml_poisson(ml_proba, poisson_proba, alpha=a)
        preds = np.argmax(blended, axis=1)
        score = f1_score(y_true, preds, average='macro', zero_division=0)
        if score > best_score:
            best_score = score; best_alpha = a
    return best_alpha, best_score

# NOTE: Phase 3 execution runs AFTER Poisson model is trained (see below)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ S6: THRESHOLD OPTIMIZATION (maximize macro F1)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def optimize_thresholds(proba, y_true, n_steps=50,
                        t_home_range=(0.15, 0.55), t_draw_range=(0.15, 0.55)):
    """
    à¸«à¸² threshold à¸—à¸µà¹ˆ maximize macro F1
    à¹à¸—à¸™à¸—à¸µà¹ˆà¸ˆà¸°à¹ƒà¸Šà¹‰ argmax à¸•à¸£à¸‡ à¹† â†’ à¸—à¸²à¸¢ Draw à¸–à¹‰à¸² p_draw > threshold_draw
    Strategy: grid search à¸šà¸™ (t_away, t_draw) à¹à¸¥à¹‰à¸§ t_home = 1 - à¸—à¸±à¹‰à¸‡à¸„à¸¹à¹ˆ

    ğŸ”¥ v7b: à¸£à¸±à¸š t_home_range / t_draw_range à¹€à¸à¸·à¹ˆà¸­ narrow search à¸£à¸­à¸šà¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸£à¸¹à¹‰à¹à¸¥à¹‰à¸§
    â†’ à¸¥à¸” variance à¹ƒà¸™ CV à¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡ freeze threshold à¸•à¸²à¸¢à¸•à¸±à¸§
    """
    from sklearn.metrics import f1_score as f1
    best_f1   = 0.0
    best_t    = (0.33, 0.33)
    thresholds_home = np.linspace(t_home_range[0], t_home_range[1], n_steps)
    thresholds_draw = np.linspace(t_draw_range[0], t_draw_range[1], n_steps)

    for t_draw in thresholds_draw:
        for t_home in thresholds_home:
            preds = []
            for row in proba:
                p_away, p_draw, p_home = row
                if p_draw >= t_draw:    preds.append(1)
                elif p_home >= t_home:  preds.append(2)
                else:                   preds.append(0)
            score = f1(y_true, preds, average='macro', zero_division=0)
            if score > best_f1:
                best_f1 = score
                best_t  = (t_home, t_draw)

    return best_t[0], best_t[1], best_f1


def apply_thresholds(proba, t_home=None, t_draw=None):
    """Apply optimized thresholds â€” Draw à¹„à¸”à¹‰à¸£à¸±à¸šà¹‚à¸­à¸à¸²à¸ªà¸Šà¸±à¸”à¸‚à¸¶à¹‰à¸™"""
    if t_home is None: t_home = OPT_T_HOME
    if t_draw is None: t_draw = OPT_T_DRAW
    preds = []
    for row in proba:
        p_away, p_draw, p_home = row
        if p_draw >= t_draw:    preds.append(1)
        elif p_home >= t_home:  preds.append(2)
        else:                   preds.append(0)
    return np.array(preds)

# NOTE: S6 execution (threshold optimization + final results + model save)
# runs AFTER Poisson model training + Phase 3 hybrid blend (see below)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 14) HELPER: GET LATEST FEATURES (à¸­à¸±à¸›à¹€à¸”à¸•à¹ƒà¸«à¹‰à¸£à¸­à¸‡à¸£à¸±à¸š features à¹ƒà¸«à¸¡à¹ˆ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import datetime
TODAY = pd.Timestamp(datetime.date.today())

final_table        = None
remaining_fixtures = []

def get_latest_features(team, is_home):
    """à¸”à¸¶à¸‡ features à¸¥à¹ˆà¸²à¸ªà¸¸à¸”à¸‚à¸­à¸‡à¸—à¸µà¸¡ à¸£à¸­à¸‡à¸£à¸±à¸š features à¹ƒà¸«à¸¡à¹ˆà¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”"""
    if is_home:
        rows = match_df_clean[match_df_clean['HomeTeam'] == team].sort_values('Date_x')
        if len(rows) > 0:
            last = rows.iloc[-1]
            return {
                'GF5':     last['H_GF5'],     'GA5':     last['H_GA5'],
                'GD5':     last['H_GD5'],     'Pts5':    last['H_Pts5'],
                'Streak3': last['H_Streak3'], 'Win5':    last['H_Win5'],
                'Draw5':   last['H_Draw5'],   'CS5':     last['H_CS5'],
                'Scored5': last['H_Scored5'],
                'GF_ewm':  last['H_GF_ewm'],  'GA_ewm':  last['H_GA_ewm'],
                'Pts_ewm': last['H_Pts_ewm'], 'GD_ewm':  last['H_GD_ewm'],
                'Pts10':   last['H_Pts10'],   'DaysRest':last['H_DaysRest'],
                'GD_std':  last['H_GD_std'],
                'Elo_HA':  last['H_Elo_Home'],
            }
    rows = match_df_clean[match_df_clean['AwayTeam'] == team].sort_values('Date_x')
    if len(rows) > 0:
        last = rows.iloc[-1]
        return {
            'GF5':     last['A_GF5'],     'GA5':     last['A_GA5'],
            'GD5':     last['A_GD5'],     'Pts5':    last['A_Pts5'],
            'Streak3': last['A_Streak3'], 'Win5':    last['A_Win5'],
            'Draw5':   last['A_Draw5'],   'CS5':     last['A_CS5'],
            'Scored5': last['A_Scored5'],
            'GF_ewm':  last['A_GF_ewm'],  'GA_ewm':  last['A_GA_ewm'],
            'Pts_ewm': last['A_Pts_ewm'], 'GD_ewm':  last['A_GD_ewm'],
            'Pts10':   last['A_Pts10'],   'DaysRest':last['A_DaysRest'],
            'GD_std':  last['A_GD_std'],
            'Elo_HA':  last['A_Elo_Away'],
        }
    # Default fallback
    return {
        'GF5': 1.5, 'GA5': 1.5, 'GD5': 0.0, 'Pts5': 1.5,
        'Streak3': 1.5, 'Win5': 0.5, 'Draw5': 0.25, 'CS5': 0.2,
        'Scored5': 0.6, 'GF_ewm': 1.5, 'GA_ewm': 1.5, 'Pts_ewm': 1.5,
        'GD_ewm': 0.0, 'Pts10': 1.5, 'DaysRest': 7, 'GD_std': 1.5,
        'Elo_HA': 1500,
    }


def build_match_row(home_team, away_team, match_date=None):
    """à¸ªà¸£à¹‰à¸²à¸‡ feature row à¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸³à¸™à¸²à¸¢à¹à¸¡à¸•à¸Šà¹Œ"""
    if match_date is None:
        match_date = TODAY
    month  = match_date.month if hasattr(match_date, 'month') else TODAY.month
    season_phase = 1 if month in [8,9,10] else (2 if month in [11,12,1,2] else 3)

    h = get_latest_features(home_team, is_home=True)
    a = get_latest_features(away_team, is_home=False)

    h_elo      = final_elo.get(home_team, 1500)
    a_elo      = final_elo.get(away_team, 1500)
    h_elo_home = final_elo_home.get(home_team, 1500)
    a_elo_away = final_elo_away.get(away_team, 1500)

    h2h_rows = match_df_clean[
        (match_df_clean['HomeTeam'] == home_team) &
        (match_df_clean['AwayTeam'] == away_team)
    ]
    h2h_rate      = h2h_rows['H2H_HomeWinRate'].iloc[-1] if len(h2h_rows) > 0 else 0.33
    h2h_draw_rate = h2h_rows['H2H_DrawRate'].iloc[-1]    if len(h2h_rows) > 0 else 0.25

    h_stats = home_stats[home_stats['Team'] == home_team]
    a_stats_r = away_stats[away_stats['Team'] == away_team]
    h_draw_r  = draw_stats_home[draw_stats_home['Team'] == home_team]

    home_win_rate  = h_stats['HomeWinRate'].values[0]  if len(h_stats) > 0  else 0.45
    away_win_rate  = a_stats_r['AwayWinRate'].values[0] if len(a_stats_r) > 0 else 0.30
    home_draw_rate = h_draw_r['HomeDrawRate'].values[0] if len(h_draw_r) > 0  else 0.25

    momentum_h = h['Pts5'] - h['Pts10'] / 2
    momentum_a = a['Pts5'] - a['Pts10'] / 2

    row = {
        # Elo
        'Diff_Elo':         h_elo - a_elo,
        'Elo_ratio':        h_elo / (a_elo + 1),
        'H_Elo_norm':       h_elo / 1500,
        'A_Elo_norm':       a_elo / 1500,
        'H_Elo_Home_norm':  h_elo_home / 1500,
        'A_Elo_Away_norm':  a_elo_away / 1500,
        # Standard form
        'H_GF5': h['GF5'],    'H_GA5': h['GA5'],     'H_Pts5': h['Pts5'],
        'H_Streak3': h['Streak3'], 'H_CS5': h['CS5'], 'H_Scored5': h['Scored5'],
        'A_GF5': a['GF5'],    'A_GA5': a['GA5'],     'A_Pts5': a['Pts5'],
        'A_Streak3': a['Streak3'], 'A_CS5': a['CS5'], 'A_Scored5': a['Scored5'],
        # Diffs
        'Diff_Pts':     h['Pts5']    - a['Pts5'],
        'Diff_GF':      h['GF5']     - a['GF5'],
        'Diff_GA':      h['GA5']     - a['GA5'],
        'Diff_GD':      h['GD5']     - a['GD5'],
        'Diff_Win':     h['Win5']    - a['Win5'],
        'Diff_CS':      h['CS5']     - a['CS5'],
        'Diff_Streak':  h['Streak3'] - a['Streak3'],
        'Diff_Scored':  h['Scored5'] - a['Scored5'],
        # EWM
        'H_GF_ewm': h['GF_ewm'],  'H_GA_ewm': h['GA_ewm'],  'H_Pts_ewm': h['Pts_ewm'],
        'A_GF_ewm': a['GF_ewm'],  'A_GA_ewm': a['GA_ewm'],  'A_Pts_ewm': a['Pts_ewm'],
        'Diff_Pts_ewm': h['Pts_ewm'] - a['Pts_ewm'],
        'Diff_GF_ewm':  h['GF_ewm']  - a['GF_ewm'],
        'Diff_GD_ewm':  h['GD_ewm']  - a['GD_ewm'],
        # Momentum
        'Diff_Momentum': momentum_h - momentum_a,
        # Draw features
        'H_Draw5': h['Draw5'],   'A_Draw5': a['Draw5'],
        'Diff_Draw5':    h['Draw5']  - a['Draw5'],
        'H2H_DrawRate':  h2h_draw_rate,
        'Combined_GF':   h['GF5']   + a['GF5'],
        'Mean_GD_std':   (h['GD_std'] + a['GD_std']) / 2,
        # H2H
        'H2H_HomeWinRate': h2h_rate,
        # Strength
        'HomeWinRate':   home_win_rate,
        'AwayWinRate':   away_win_rate,
        'HomeDrawRate':  home_draw_rate,
        # Days Rest
        'H_DaysRest':    min(h['DaysRest'], 21),
        'A_DaysRest':    min(a['DaysRest'], 21),
        'Diff_DaysRest': min(h['DaysRest'], 21) - min(a['DaysRest'], 21),
        # Seasonal
        'Month':         month,
        'SeasonPhase':   season_phase,
        # ğŸ”¥ S4: Deep Features
        'H_Form_slope':   (h['Pts_ewm'] - h['Pts10'] / 2) / (h['GD_std'] + 0.5),
        'A_Form_slope':   (a['Pts_ewm'] - a['Pts10'] / 2) / (a['GD_std'] + 0.5),
        'Diff_Form_slope':((h['Pts_ewm'] - h['Pts10'] / 2) / (h['GD_std'] + 0.5) -
                           (a['Pts_ewm'] - a['Pts10'] / 2) / (a['GD_std'] + 0.5)),
        'H_HomeAdvantage': h_elo_home / (h_elo + 1),
        'A_AwayPenalty':   a_elo_away / (a_elo + 1),
        'Venue_edge':      h_elo_home / (h_elo + 1) - a_elo_away / (a_elo + 1),
        'H_AttackIdx':     h['GF_ewm'] / (max(a['GA_ewm'], 0.3) + 0.01),
        'A_AttackIdx':     a['GF_ewm'] / (max(h['GA_ewm'], 0.3) + 0.01),
        'Diff_AttackIdx':  h['GF_ewm'] / (max(a['GA_ewm'], 0.3) + 0.01) -
                           a['GF_ewm'] / (max(h['GA_ewm'], 0.3) + 0.01),
        'H_DefStr':        h['CS5'] / (max(h['GA5'], 0.1) + 0.1),
        'A_DefStr':        a['CS5'] / (max(a['GA5'], 0.1) + 0.1),
        'Diff_DefStr':     h['CS5'] / (max(h['GA5'], 0.1) + 0.1) -
                           a['CS5'] / (max(a['GA5'], 0.1) + 0.1),
        'Elo_closeness':   1 / (abs(h_elo - a_elo) + 50),
        'Form_closeness':  1 / (abs(h['Pts_ewm'] - a['Pts_ewm']) + 0.5),
        'Draw_likelihood': (1 / (abs(h_elo - a_elo) + 50)) *
                           (1 / (abs(h['Pts_ewm'] - a['Pts_ewm']) + 0.5)) *
                           max((h['GD_std'] + a['GD_std']) / 2, 0.1),
        # ğŸ”¥ Phase 1: xG features (à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ â†’ NaN â†’ drop)
        'H_xGF5':        h.get('xGF5', np.nan),   'H_xGA5':  h.get('xGA5', np.nan),
        'H_xGD5':        h.get('xGD5', np.nan),
        'H_xGF_ewm':     h.get('xGF_ewm', np.nan), 'H_xGA_ewm': h.get('xGA_ewm', np.nan),
        'H_xG_overperf': h.get('xG_overperf', np.nan),
        'H_xGF_slope':   h.get('xGF_slope', np.nan),
        'A_xGF5':        a.get('xGF5', np.nan),   'A_xGA5':  a.get('xGA5', np.nan),
        'A_xGD5':        a.get('xGD5', np.nan),
        'A_xGF_ewm':     a.get('xGF_ewm', np.nan), 'A_xGA_ewm': a.get('xGA_ewm', np.nan),
        'A_xG_overperf': a.get('xG_overperf', np.nan),
        'A_xGF_slope':   a.get('xGF_slope', np.nan),
        'Diff_xGF':          h.get('xGF5', np.nan)  - a.get('xGF5', np.nan)  if XG_AVAILABLE else np.nan,
        'Diff_xGA':          h.get('xGA5', np.nan)  - a.get('xGA5', np.nan)  if XG_AVAILABLE else np.nan,
        'Diff_xGD':          h.get('xGD5', np.nan)  - a.get('xGD5', np.nan)  if XG_AVAILABLE else np.nan,
        'Diff_xGF_ewm':      h.get('xGF_ewm', np.nan) - a.get('xGF_ewm', np.nan) if XG_AVAILABLE else np.nan,
        'Diff_xG_overperf':  h.get('xG_overperf', np.nan) - a.get('xG_overperf', np.nan) if XG_AVAILABLE else np.nan,
        'Diff_xGF_slope':    h.get('xGF_slope', np.nan) - a.get('xGF_slope', np.nan) if XG_AVAILABLE else np.nan,
        'H_xAttackIdx':  h.get('xGF_ewm', np.nan) / (max(a.get('xGA_ewm', 0.3) or 0.3, 0.3) + 0.01) if XG_AVAILABLE else np.nan,
        'A_xAttackIdx':  a.get('xGF_ewm', np.nan) / (max(h.get('xGA_ewm', 0.3) or 0.3, 0.3) + 0.01) if XG_AVAILABLE else np.nan,
        'Diff_xAttackIdx': (h.get('xGF_ewm', np.nan) / (max(a.get('xGA_ewm', 0.3) or 0.3, 0.3) + 0.01) -
                            a.get('xGF_ewm', np.nan) / (max(h.get('xGA_ewm', 0.3) or 0.3, 0.3) + 0.01)) if XG_AVAILABLE else np.nan,
    }
    return row


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 15) PREDICT SINGLE MATCH
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def predict_match(home_team, away_team, match_date=None,
                  odds_home=None, odds_draw=None, odds_away=None):
    """
    à¸—à¸³à¸™à¸²à¸¢à¸œà¸¥à¹à¸¡à¸•à¸Šà¹Œ
    odds_home/draw/away: decimal odds à¸ˆà¸²à¸ bookmaker (optional)
    à¸–à¹‰à¸²à¹ƒà¸ªà¹ˆ odds â†’ à¹ƒà¸Šà¹‰ implied prob à¹€à¸›à¹‡à¸™ features + à¹à¸ªà¸”à¸‡ edge analysis
    """
    teams_in_data = set(match_df_clean['HomeTeam'].tolist() + match_df_clean['AwayTeam'].tolist())
    if home_team not in teams_in_data:
        print(f"âŒ à¹„à¸¡à¹ˆà¸à¸šà¸—à¸µà¸¡ '{home_team}'  |  à¸—à¸µà¸¡à¸—à¸µà¹ˆà¸¡à¸µ: {sorted(teams_in_data)}")
        return None
    if away_team not in teams_in_data:
        print(f"âŒ à¹„à¸¡à¹ˆà¸à¸šà¸—à¸µà¸¡ '{away_team}'")
        return None

    row  = build_match_row(home_team, away_team, match_date)

    # ğŸ”¥ Phase 2: à¸–à¹‰à¸²à¸ªà¹ˆà¸‡ live odds à¸¡à¸² â†’ override market features (à¹€à¸‰à¸à¸²à¸°à¹€à¸¡à¸·à¹ˆà¸­ USE_MARKET_FEATURES=True)
    if USE_MARKET_FEATURES and all(x is not None for x in [odds_home, odds_draw, odds_away]):
        try:
            rh, rd, ra = 1/odds_home, 1/odds_draw, 1/odds_away
            total = rh + rd + ra
            row['Mkt_ImpH']     = rh / total
            row['Mkt_ImpD']     = rd / total
            row['Mkt_ImpA']     = ra / total
            row['Mkt_Spread']   = (rh / total) - (ra / total)
            row['Mkt_DrawPrem'] = (rd / total) - 0.26
            row['Mkt_Overround']= total - 1
        except Exception:
            pass

    X    = pd.DataFrame([row])[FEATURES].fillna(0)
    X_sc = scaler.transform(X)

    # ğŸ”¥ 2-Stage ML prediction
    proba_ml = predict_2stage(X_sc)[0]

    # ğŸ”¥ Phase 3: Poisson Hybrid blend (à¸–à¹‰à¸²à¸à¸£à¹‰à¸­à¸¡)
    if POISSON_HYBRID_READY:
        try:
            pf_row = pd.DataFrame([row])[poisson_features_used].fillna(0)
            pf_sc  = poisson_scaler.transform(pf_row)
            hxg    = float(np.clip(home_poisson_model.predict(pf_sc)[0], 0.3, 6.0))
            axg    = float(np.clip(away_poisson_model.predict(pf_sc)[0], 0.3, 6.0))
            ph, pd_, pa = poisson_win_draw_loss(hxg, axg)
            proba_pois  = np.array([pa, pd_, ph])
            proba       = blend_ml_poisson(proba_ml.reshape(1,-1),
                                           proba_pois.reshape(1,-1),
                                           alpha=best_alpha)
            # ğŸ”¥ FIX C: Apply draw suppression à¹ƒà¸«à¹‰ consistent à¸à¸±à¸š training
            proba       = suppress_draw_proba(proba, draw_factor=DRAW_SUPPRESS_FACTOR)[0]
            model_tag   = f"Hybrid Î±={best_alpha:.2f} ğŸ”¥"
        except Exception:
            proba = proba_ml
            hxg = axg = None
            model_tag = "2-Stage ML"
    else:
        proba = proba_ml
        hxg = axg = None
        model_tag = "2-Stage ML"

    pred  = apply_thresholds(proba.reshape(1, -1))[0]

    label_map = {0: 'Away Win', 1: 'Draw', 2: 'Home Win'}
    h_elo = final_elo.get(home_team, 1500)
    a_elo = final_elo.get(away_team, 1500)
    draw_signal = "ğŸ¯ Draw signal!" if proba[1] >= OPT_T_DRAW else ""

    result = {
        'Away Win': round(proba[0]*100, 1),
        'Draw':     round(proba[1]*100, 1),
        'Home Win': round(proba[2]*100, 1),
        'Prediction': label_map[pred],
        'Home_Elo': round(h_elo),
        'Away_Elo': round(a_elo),
    }

    print(f"\n{'='*52}")
    print(f"  âš½  {home_team}  vs  {away_team}")
    print(f"{'='*52}")
    print(f"  Elo:   {home_team} {round(h_elo)}  |  {away_team} {round(a_elo)}")
    print(f"  Model: {model_tag}  (t_draw={OPT_T_DRAW:.2f}, t_home={OPT_T_HOME:.2f})")
    if hxg is not None:
        print(f"  xG:    {home_team} {hxg:.2f}  |  {away_team} {axg:.2f}")
    print(f"{'â”€'*52}")
    bar_chars = 28
    for label, pct in [('Home Win', result['Home Win']),
                        ('Draw    ', result['Draw']),
                        ('Away Win', result['Away Win'])]:
        bar   = 'â–ˆ' * int(pct / 100 * bar_chars)
        t_tag = ' â† threshold' if (label.strip()=='Draw' and proba[1]>=OPT_T_DRAW) else ''
        print(f"  {label}: {bar:<28} {pct}%{t_tag}")
    print(f"{'â”€'*52}")
    print(f"  ğŸ¯ Prediction: {result['Prediction']}  {draw_signal}")

    # ğŸ”¥ Edge analysis à¸–à¹‰à¸²à¸¡à¸µ odds
    if all(x is not None for x in [odds_home, odds_draw, odds_away]):
        mkt_p = {2: 1/odds_home, 1: 1/odds_draw, 0: 1/odds_away}
        tot   = sum(mkt_p.values())
        imp   = {k: v/tot for k, v in mkt_p.items()}
        model_p = {2: proba[2], 1: proba[1], 0: proba[0]}
        print(f"\n  ğŸ’° Betting Edge Analysis:")
        print(f"  {'Outcome':<12} {'Model%':>8} {'Market%':>9} {'Edge%':>8} {'Odds':>7}")
        print(f"  {'â”€'*48}")
        for cls, label in [(2,'Home Win'),(1,'Draw'),(0,'Away Win')]:
            edge = model_p[cls] - imp[cls]
            o = {2: odds_home, 1: odds_draw, 0: odds_away}[cls]
            flag = ' âœ… VALUE' if edge > 0.03 else (' âš ï¸' if edge > 0 else '')
            print(f"  {label:<12} {model_p[cls]*100:>7.1f}% {imp[cls]*100:>8.1f}% "
                  f"{edge*100:>+7.1f}% {o:>7.2f}{flag}")

    print(f"{'='*52}")
    return result


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 16) ğŸ”¥ POISSON REGRESSION GOAL MODEL (v3.0)
#     Dixon-Coles style: à¹à¸¢à¸ model à¹€à¸«à¸¢à¹‰à¸²/à¹€à¸¢à¸·à¸­à¸™ â†’ xG â†’ W/D/L prob
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

from sklearn.linear_model import PoissonRegressor

def build_poisson_model():
    """
    à¸ªà¸£à¹‰à¸²à¸‡ Poisson regression model à¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸³à¸™à¸²à¸¢ expected goals
    - Home model: à¸—à¸³à¸™à¸²à¸¢ FTHG (home goals)
    - Away model: à¸—à¸³à¸™à¸²à¸¢ FTAG (away goals)
    Feature: Elo_diff, form features
    """
    poisson_features = [
        'Diff_Elo', 'H_GF_ewm', 'H_GA_ewm', 'A_GF_ewm', 'A_GA_ewm',
        'H_Pts_ewm', 'A_Pts_ewm', 'H_Elo_norm', 'A_Elo_norm',
        'HomeWinRate', 'AwayWinRate',
    ]
    pf_available = [f for f in poisson_features if f in match_df_clean.columns]

    train_p = train[pf_available].fillna(0)
    # à¹ƒà¸Šà¹‰ actual goals (à¸”à¸µà¸—à¸µà¹ˆà¸ªà¸¸à¸”à¸ªà¸³à¸«à¸£à¸±à¸š Poisson regression)
    if 'FTHG' in train.columns and train['FTHG'].notna().sum() > 100:
        y_home_goals = train['FTHG'].fillna(train['FTHG'].median()).clip(0, 8)
        y_away_goals = train['FTAG'].fillna(train['FTAG'].median()).clip(0, 8)
        print("  Using actual FTHG/FTAG for Poisson target")
    else:
        # fallback: à¹ƒà¸Šà¹‰ rolling average (à¸„à¹ˆà¸²à¸›à¸£à¸°à¸¡à¸²à¸“)
        y_home_goals = train['H_GF5'].fillna(1.3).clip(0, 5)
        y_away_goals = train['A_GF5'].fillna(1.1).clip(0, 5)
        print("  Using rolling average as Poisson target (fallback)")

    sc_p = StandardScaler()
    train_p_sc = sc_p.fit_transform(train_p)

    home_poisson = PoissonRegressor(alpha=0.5, max_iter=500)
    away_poisson = PoissonRegressor(alpha=0.5, max_iter=500)
    home_poisson.fit(train_p_sc, y_home_goals.clip(0, 8))
    away_poisson.fit(train_p_sc, y_away_goals.clip(0, 8))

    return home_poisson, away_poisson, sc_p, pf_available

print("\nğŸ”¥ Building Poisson Goal Model...")
try:
    home_poisson_model, away_poisson_model, poisson_scaler, poisson_features_used = build_poisson_model()
    POISSON_MODEL_READY = True
    print("âœ… Poisson Goal Model trained")
except Exception as e:
    POISSON_MODEL_READY = False
    print(f"âš ï¸  Poisson model failed: {e}")


def poisson_win_draw_loss(home_xg, away_xg, max_goals=8):
    """
    à¸„à¸³à¸™à¸§à¸“ P(Win), P(Draw), P(Loss) à¸ˆà¸²à¸ Poisson distribution
    à¸™à¸µà¹ˆà¸„à¸·à¸­à¹à¸à¹ˆà¸™à¸‚à¸­à¸‡ betting market calculation
    """
    p_home_win = p_draw = p_away_win = 0.0
    for hg in range(max_goals + 1):
        for ag in range(max_goals + 1):
            p = poisson.pmf(hg, home_xg) * poisson.pmf(ag, away_xg)
            if hg > ag:   p_home_win += p
            elif hg == ag: p_draw    += p
            else:          p_away_win += p
    total = p_home_win + p_draw + p_away_win
    return p_home_win/total, p_draw/total, p_away_win/total


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ PHASE 3: EXECUTION â€” now POISSON_MODEL_READY is defined
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\nğŸ”¥ PHASE 3: Building Poisson Hybrid Blend...")
POISSON_HYBRID_READY = False
best_alpha = 0.6   # default fallback
proba_hybrid = proba_2stage.copy()   # default: ML-only

if POISSON_MODEL_READY:
    try:
        poisson_proba_test = build_poisson_proba_for_test(
            test, poisson_features_used,
            poisson_scaler, home_poisson_model, away_poisson_model
        )
        best_alpha, best_blend_f1 = optimize_blend_alpha(
            proba_2stage, poisson_proba_test, y_test.values
        )
        proba_hybrid = blend_ml_poisson(proba_2stage, poisson_proba_test, alpha=best_alpha)
        POISSON_HYBRID_READY = True
        print(f"  âœ… Poisson Hybrid: best alpha={best_alpha:.2f}  macro F1={best_blend_f1:.4f}")
        print(f"     ({best_alpha:.2f} ML + {1-best_alpha:.2f} Poisson)")
    except Exception as e:
        print(f"  âš ï¸  Poisson hybrid failed: {e} â€” using ML-only")
else:
    print("  âš ï¸  Poisson model not ready â€” using ML-only proba")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ S6 EXECUTION: Threshold optimization on final hybrid proba
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\nğŸ”¥ S6: Optimizing prediction thresholds...")
# ğŸ”¥ FIX C: Apply draw suppression à¹€à¸à¸·à¹ˆà¸­à¹à¸à¹‰ systematic bias +11%
#    à¸—à¸³à¸à¹ˆà¸­à¸™ threshold optimization à¹€à¸à¸·à¹ˆà¸­à¹ƒà¸«à¹‰ thresholds calibrate à¸šà¸™ proba à¸—à¸µà¹ˆà¸–à¸¹à¸à¸•à¹‰à¸­à¸‡
DRAW_SUPPRESS_FACTOR = 0.85
proba_hybrid = suppress_draw_proba(proba_hybrid, draw_factor=DRAW_SUPPRESS_FACTOR)
print(f"  ğŸ”§ Draw suppression applied (factor={DRAW_SUPPRESS_FACTOR}) â€” fixing systematic bias")
OPT_T_HOME, OPT_T_DRAW, best_macro_f1 = optimize_thresholds(proba_hybrid, y_test)
print(f"  Optimal t_home={OPT_T_HOME:.3f}  t_draw={OPT_T_DRAW:.3f}")
print(f"  Best macro F1 = {best_macro_f1:.4f}")

# ğŸ”¥ FIX C diagnostic: à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š draw bias à¸«à¸¥à¸±à¸‡ suppression
_draw_pred_mean = proba_hybrid[:, 1].mean()
_draw_actual    = (y_test == 1).mean()
_draw_bias_after = (_draw_pred_mean - _draw_actual) * 100
print(f"  ğŸ“ Draw calibration check: predicted={_draw_pred_mean:.1%}  "
      f"actual={_draw_actual:.1%}  bias={_draw_bias_after:+.1f}%"
      f"  {'âœ… improved' if abs(_draw_bias_after) < 8 else 'âš ï¸ still biased'}")

y_pred_final = apply_thresholds(proba_hybrid)
acc_final    = accuracy_score(y_test, y_pred_final)

hybrid_tag = "2-Stage + Poisson Hybrid ğŸ”¥" if POISSON_HYBRID_READY else "2-Stage ML only"
print(f"\n===== v5.0 FINAL RESULTS ({hybrid_tag}) =====")
print(f"Accuracy : {round(acc_final*100, 2)}%  "
      f"(ML-only 2-stage: {round(acc_2stage*100,2)}%)")
if POISSON_HYBRID_READY:
    print(f"Hybrid gain: {round((acc_final - acc_2stage)*100, 2)}%  "
          f"(Î±={best_alpha:.2f} ML + {1-best_alpha:.2f} Poisson)")
print(f"\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred_final))
print(f"\nClassification Report:")
print(classification_report(y_test, y_pred_final,
                             target_names=['Away Win','Draw','Home Win']))

# Keep backward compatibility â€” ensemble = 2-stage predict wrapper
class TwoStageEnsemble:
    """Wrapper class à¹ƒà¸«à¹‰à¹ƒà¸Šà¹‰à¹„à¸”à¹‰à¹€à¸«à¸¡à¸·à¸­à¸™ sklearn classifier"""
    def predict_proba(self, X):
        return predict_2stage(X)
    def predict(self, X):
        return apply_thresholds(predict_2stage(X))

ensemble   = TwoStageEnsemble()
calibrated = TwoStageEnsemble()
y_pred     = y_pred_final  # backward compat

# â”€â”€ Fallback single-stage ensemble (à¸ªà¸³à¸«à¸£à¸±à¸š CV / backtest) â”€â”€â”€â”€
print("\nğŸ”§ Building fallback single-stage ensemble (for CV + backtest)...")
# ğŸ”¥ FIX CONSISTENCY: à¹ƒà¸Šà¹‰ shared params à¹€à¸«à¸¡à¸·à¸­à¸™ main model à¹à¸¥à¸° CV
if LGBM_AVAILABLE:
    lgbm_clf = lgb.LGBMClassifier(**get_cv_lgbm_params())
else:
    lgbm_clf = GradientBoostingClassifier(n_estimators=300, max_depth=4,
                                          learning_rate=0.05, random_state=42)

fallback_single = lgbm_clf
fallback_single.fit(X_train_sc, y_train)
print("  âœ… Fallback single-stage trained")

# â”€â”€ Isotonic Calibration (inline) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("ğŸ¯ Applying Isotonic Calibration (single-stage fallback)...")
try:
    calibrated_single = CalibratedClassifierCV(fallback_single, method='isotonic', cv=3)
    calibrated_single.fit(X_train_sc, y_train)
    y_pred_cal = calibrated_single.predict(X_test_sc)
    acc_cal = accuracy_score(y_test, y_pred_cal)
    print(f"Single-stage Calibrated Accuracy: {round(acc_cal*100, 2)}%")
except Exception as e:
    print(f"âš ï¸  Calibration skipped: {e}")
    calibrated_single = fallback_single

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 13) SAVE MODEL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

model_bundle = {
    'model':               ensemble,
    'calibrated':          calibrated,
    'stage1':              stage1_cal,
    'stage2':              stage2_cal,
    'fallback_single':     calibrated_single,
    'scaler':              scaler,
    'features':            FEATURES,
    'elo':                 final_elo,
    'elo_home':            final_elo_home,
    'elo_away':            final_elo_away,
    'teams':               list(final_elo.keys()),
    'home_stats':          home_stats,
    'away_stats':          away_stats,
    'opt_t_home':          OPT_T_HOME,
    'opt_t_draw':          OPT_T_DRAW,
    'draw_suppress_factor': DRAW_SUPPRESS_FACTOR,   # ğŸ”¥ FIX C: save factor
    'poisson_hybrid_ready':POISSON_HYBRID_READY,
    'poisson_alpha':       best_alpha if POISSON_HYBRID_READY else 0.6,
    'poisson_model_home':  home_poisson_model if POISSON_MODEL_READY else None,
    'poisson_model_away':  away_poisson_model if POISSON_MODEL_READY else None,
    'poisson_scaler':      poisson_scaler if POISSON_MODEL_READY else None,
    'poisson_features':    poisson_features_used if POISSON_MODEL_READY else [],
    'xg_available':        XG_AVAILABLE,
    'odds_available':      ODDS_AVAILABLE,
    'version':             '8.0',   # ğŸ”¥ bump version
}

os.makedirs("model", exist_ok=True)
with open("model/football_model_v8.pkl", "wb") as f:
    pickle.dump(model_bundle, f)

print("âœ… Model v8 saved â†’ model/football_model_v8.pkl")


def predict_score(home_team, away_team, use_poisson_model=True):
    """
    v3.0: à¹ƒà¸Šà¹‰ Poisson regression model à¸—à¸³à¸™à¸²à¸¢ xG â†’ à¸ªà¸à¸­à¸£à¹Œ + W/D/L probs
    """
    teams_in_data = set(match_df_clean['HomeTeam'].tolist() + match_df_clean['AwayTeam'].tolist())
    if home_team not in teams_in_data or away_team not in teams_in_data:
        return None

    h = get_latest_features(home_team, is_home=True)
    a = get_latest_features(away_team, is_home=False)

    lg_home = data.dropna(subset=['FTHG'])['FTHG'].mean()
    lg_away = data.dropna(subset=['FTAG'])['FTAG'].mean()

    # Poisson regression xG (à¸–à¹‰à¸² model à¸à¸£à¹‰à¸­à¸¡)
    if POISSON_MODEL_READY and use_poisson_model:
        row = build_match_row(home_team, away_team)
        pf_row = pd.DataFrame([row])[poisson_features_used].fillna(0)
        pf_sc  = poisson_scaler.transform(pf_row)
        home_xg = float(home_poisson_model.predict(pf_sc)[0])
        away_xg = float(away_poisson_model.predict(pf_sc)[0])
        home_xg = max(0.3, min(home_xg, 6.0))
        away_xg = max(0.3, min(away_xg, 6.0))
        xg_source = "Poisson Regression ğŸ”¥"
    else:
        # fallback: ratio method
        h_gf = h['GF_ewm'] if h['GF_ewm'] > 0 else h['GF5']
        h_ga = h['GA_ewm'] if h['GA_ewm'] > 0 else h['GA5']
        a_gf = a['GF_ewm'] if a['GF_ewm'] > 0 else a['GF5']
        a_ga = a['GA_ewm'] if a['GA_ewm'] > 0 else a['GA5']
        home_xg = (h_gf / lg_home) * (a_ga / lg_home) * lg_home
        away_xg = (a_gf / lg_away) * (h_ga / lg_away) * lg_away
        home_xg = max(0.3, min(home_xg, 6.0))
        away_xg = max(0.3, min(away_xg, 6.0))
        xg_source = "Ratio Method"

    # à¸„à¸³à¸™à¸§à¸“ score probabilities
    score_probs = {}
    for hg in range(8):
        for ag in range(8):
            score_probs[f"{hg}-{ag}"] = round(
                poisson.pmf(hg, home_xg) * poisson.pmf(ag, away_xg) * 100, 2
            )
    top5 = sorted(score_probs.items(), key=lambda x: x[1], reverse=True)[:5]

    # Poisson-derived W/D/L probs (independent of classifier)
    p_hw, p_d, p_aw = poisson_win_draw_loss(home_xg, away_xg)

    print(f"\n  âš½ xG ({xg_source}):  {home_team} {round(home_xg,2)}  vs  {away_team} {round(away_xg,2)}")
    print(f"  ğŸ“Š Poisson W/D/L: {p_hw*100:.1f}% / {p_d*100:.1f}% / {p_aw*100:.1f}%")
    print(f"  ğŸ¯ à¸ªà¸à¸­à¸£à¹Œà¸—à¸µà¹ˆà¸™à¹ˆà¸²à¸ˆà¸°à¹€à¸›à¹‡à¸™ (Top 5):")
    for score, pct in top5:
        bar = 'â–ˆ' * int(pct * 2)
        print(f"     {score:<8} {bar:<20} {pct}%")

    return {
        'home_xg':           round(home_xg, 2),
        'away_xg':           round(away_xg, 2),
        'most_likely_score': top5[0][0],
        'top5_scores':       top5,
        'poisson_home_win':  round(p_hw*100, 1),
        'poisson_draw':      round(p_d*100, 1),
        'poisson_away_win':  round(p_aw*100, 1),
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 17) GET LAST 5 RESULTS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def get_last_5_results(team):
    valid = data.dropna(subset=['FTHG', 'FTAG']).copy()
    hm = valid[valid['HomeTeam'] == team][['Date','HomeTeam','AwayTeam','FTHG','FTAG']].copy()
    hm['Venue'] = 'H'; hm['GF'] = hm['FTHG']; hm['GA'] = hm['FTAG']
    hm['Opponent'] = hm['AwayTeam']
    am = valid[valid['AwayTeam'] == team][['Date','HomeTeam','AwayTeam','FTHG','FTAG']].copy()
    am['Venue'] = 'A'; am['GF'] = am['FTAG']; am['GA'] = am['FTHG']
    am['Opponent'] = am['HomeTeam']
    all_m = pd.concat([hm, am]).sort_values('Date', ascending=False)
    last5 = all_m.head(5).copy()
    def rl(r):
        if r['GF'] > r['GA']: return 'W'
        elif r['GF'] == r['GA']: return 'D'
        else: return 'L'
    last5['Result'] = last5.apply(rl, axis=1)
    icon_map = {'W': 'âœ… à¸Šà¸™à¸°', 'D': 'ğŸŸ¡ à¹€à¸ªà¸¡à¸­', 'L': 'âŒ à¹à¸à¹‰'}
    print(f"\n{'='*58}")
    print(f"  ğŸ“‹  5 à¹à¸¡à¸•à¸Šà¹Œà¸¥à¹ˆà¸²à¸ªà¸¸à¸”à¸‚à¸­à¸‡ {team}")
    print(f"{'='*58}")
    print(f"  {'à¸§à¸±à¸™à¸—à¸µà¹ˆ':<13} {'à¸„à¸¹à¹ˆà¹à¸‚à¹ˆà¸‡':<22} {'à¸ªà¸™à¸²à¸¡':<6} {'à¸ªà¸à¸­à¸£à¹Œ':<10} {'à¸œà¸¥'}")
    print(f"  {'â”€'*55}")
    for _, row in last5.iterrows():
        ds = row['Date'].strftime('%d/%m/%Y') if pd.notna(row['Date']) else 'N/A'
        sc = f"{int(row['GF'])}-{int(row['GA'])}"
        print(f"  {ds:<13} {str(row['Opponent']):<22} "
              f"{'à¹€à¸«à¸¢à¹‰à¸²' if row['Venue']=='H' else 'à¹€à¸¢à¸·à¸­à¸™':<6} {sc:<10} {icon_map[row['Result']]}")
    print(f"{'='*58}")
    return last5


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 18) SEASON SIMULATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import requests

API_KEY = "745c5b802b204590bfa05c093f00bd43"

TEAM_NAME_MAP = {
    "Arsenal FC": "Arsenal", "Aston Villa FC": "Aston Villa",
    "AFC Bournemouth": "Bournemouth", "Brentford FC": "Brentford",
    "Brighton & Hove Albion FC": "Brighton", "Burnley FC": "Burnley",
    "Chelsea FC": "Chelsea", "Crystal Palace FC": "Crystal Palace",
    "Everton FC": "Everton", "Fulham FC": "Fulham",
    "Leeds United FC": "Leeds", "Liverpool FC": "Liverpool",
    "Manchester City FC": "Man City", "Manchester United FC": "Man United",
    "Newcastle United FC": "Newcastle", "Nottingham Forest FC": "Nott'm Forest",
    "Sunderland AFC": "Sunderland", "Tottenham Hotspur FC": "Tottenham",
    "West Ham United FC": "West Ham", "Wolverhampton Wanderers FC": "Wolves",
}

def normalize(name):
    return TEAM_NAME_MAP.get(name, name)


def update_season_csv_from_api():
    from datetime import datetime, timedelta
    url = "https://api.football-data.org/v4/competitions/PL/matches"
    headers = {"X-Auth-Token": API_KEY}
    try:
        print("\n" + "="*55)
        print("  ğŸ“¥  à¸­à¸±à¸›à¹€à¸”à¸• season 2025.csv à¸ˆà¸²à¸ API...")
        r = requests.get(url, headers=headers, params={"season": "2025"}, timeout=15)
        r.raise_for_status()
        matches = r.json().get("matches", [])
        print(f"  âœ… à¸”à¸¶à¸‡à¹„à¸”à¹‰ {len(matches)} à¹à¸¡à¸•à¸Šà¹Œ")
        rows = []
        for m in matches:
            utc_dt   = datetime.fromisoformat(m["utcDate"].replace("Z", "+00:00"))
            th_dt    = utc_dt + timedelta(hours=7)
            date_str = th_dt.strftime("%d/%m/%Y")
            status   = m.get("status", "")
            full     = m.get("score", {}).get("fullTime", {})
            if status in ["FINISHED", "IN_PLAY", "PAUSED"]:
                hg  = full.get("home", "")
                ag  = full.get("away", "")
                ftr = ("H" if hg > ag else ("A" if ag > hg else "D")) if hg != "" else ""
            else:
                hg, ag, ftr = "", "", ""
            rows.append({"Date": date_str,
                         "HomeTeam": normalize(m["homeTeam"]["name"]),
                         "AwayTeam": normalize(m["awayTeam"]["name"]),
                         "FTHG": hg, "FTAG": ag, "FTR": ftr})
        df_new = pd.DataFrame(rows)
        played   = len(df_new[df_new["FTHG"] != ""])
        upcoming = len(df_new[df_new["FTHG"] == ""])
        df_new.to_csv("data_set/season 2025.csv", index=False)
        print(f"  âœ… à¹à¸‚à¹ˆà¸‡à¹à¸¥à¹‰à¸§ {played} à¸™à¸±à¸” | à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹à¸‚à¹ˆà¸‡ {upcoming} à¸™à¸±à¸”")
        print(f"  ğŸ’¾ à¸šà¸±à¸™à¸—à¸¶à¸ â†’ data_set/season 2025.csv")
        print("="*55)
        return df_new
    except Exception as e:
        print(f"  âŒ Error: {e}")


def run_season_simulation():
    global final_table, remaining_fixtures
    season_file = pd.read_csv("data_set/season 2025.csv")
    season_file['Date'] = pd.to_datetime(season_file['Date'], dayfirst=True, errors='coerce')
    played = season_file.dropna(subset=['FTHG', 'FTAG']).copy()
    played = played[played['Date'] <= TODAY]
    season_teams = list(set(season_file['HomeTeam'].tolist() + season_file['AwayTeam'].tolist()))
    played_pairs = set(zip(played['HomeTeam'], played['AwayTeam']))
    remaining_fixtures = [
        {'HomeTeam': h, 'AwayTeam': a}
        for h in season_teams for a in season_teams
        if h != a and (h, a) not in played_pairs
    ]
    unplayed = pd.DataFrame(remaining_fixtures)
    print(f"\nğŸ“… à¸§à¸±à¸™à¸™à¸µà¹‰: {TODAY.date()}")
    print(f"âœ… à¹à¸¡à¸•à¸Šà¹Œà¹à¸‚à¹ˆà¸‡à¹à¸¥à¹‰à¸§:    {len(played)} à¸™à¸±à¸”")
    print(f"â³ à¹à¸¡à¸•à¸Šà¹Œà¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹à¸‚à¹ˆà¸‡: {len(unplayed)} à¸™à¸±à¸”")
    print(f"   à¸£à¸§à¸¡: {len(played) + len(unplayed)} à¸™à¸±à¸”")

    real_table = {}
    for _, row in played.iterrows():
        home, away = row['HomeTeam'], row['AwayTeam']
        hg, ag = int(row['FTHG']), int(row['FTAG'])
        for t in [home, away]:
            if t not in real_table: real_table[t] = 0
        if hg > ag:   real_table[home] += 3
        elif hg < ag: real_table[away] += 3
        else: real_table[home] += 1; real_table[away] += 1

    real_table_df = pd.DataFrame.from_dict(real_table, orient='index', columns=['RealPoints'])
    pred_table    = {}
    print(f"ğŸ¤– à¸—à¸³à¸™à¸²à¸¢ {len(unplayed)} à¹à¸¡à¸•à¸Šà¹Œà¸—à¸µà¹ˆà¹€à¸«à¸¥à¸·à¸­")

    if len(unplayed) > 0:
        future_rows = []
        for _, match in unplayed.iterrows():
            home, away = match['HomeTeam'], match['AwayTeam']
            row = build_match_row(home, away)
            row['HomeTeam'] = home
            row['AwayTeam'] = away
            future_rows.append(row)
        future_df  = pd.DataFrame(future_rows)
        X_future   = scaler.transform(future_df[FEATURES])
        future_df['Pred'] = ensemble.predict(X_future)

        for _, row in future_df.iterrows():
            home, away = row['HomeTeam'], row['AwayTeam']
            pred = row['Pred']
            for t in [home, away]:
                if t not in pred_table: pred_table[t] = 0
            if pred == 2:    pred_table[home] += 3
            elif pred == 1:  pred_table[home] += 1; pred_table[away] += 1
            else:            pred_table[away] += 3

    pred_table_df = pd.DataFrame.from_dict(pred_table, orient='index', columns=['PredictedPoints'])
    final_table   = real_table_df.join(pred_table_df, how='left').fillna(0)
    final_table['PredictedPoints'] = final_table['PredictedPoints'].astype(int)
    final_table['FinalPoints']     = final_table['RealPoints'] + final_table['PredictedPoints']
    final_table.index.name = 'Team'

    real_sorted  = final_table.sort_values('RealPoints', ascending=False)
    played_count = len(played) // max(len(season_teams), 1)

    print(f"\n{'='*58}")
    print(f"  ğŸ“Š  à¸•à¸²à¸£à¸²à¸‡à¸„à¸°à¹à¸™à¸™à¸ˆà¸£à¸´à¸‡ à¸“ à¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™  (à¸–à¸¶à¸‡ {TODAY.date()})")
    print(f"{'='*58}")
    print(f"  {'#':<4} {'Team':<22} {'à¹à¸‚à¹ˆà¸‡':>5} {'à¹à¸•à¹‰à¸¡':>6}  {'à¸ªà¸–à¸²à¸™à¸°'}")
    print(f"  {'â”€'*55}")
    for rank, (team, row) in enumerate(real_sorted.iterrows(), 1):
        if rank <= 4:    status = "ğŸ”´ CL Zone"
        elif rank <= 6:  status = "ğŸŸ  Euro Zone"
        elif rank >= 18: status = "ğŸŸ¡ Relegation"
        else:            status = ""
        print(f"  {rank:<4} {team:<22} {played_count:>5} {int(row['RealPoints']):>6}  {status}")
    print(f"  {'â”€'*55}")
    print(f"  ğŸ”´ CL  ğŸŸ  Europa  ğŸŸ¡ à¸•à¸à¸Šà¸±à¹‰à¸™")

    final_sorted = final_table.sort_values('FinalPoints', ascending=False)
    print(f"\n{'='*62}")
    print(f"  ğŸ”®  à¸•à¸²à¸£à¸²à¸‡à¸„à¸²à¸”à¸à¸²à¸£à¸“à¹Œà¸ªà¸´à¹‰à¸™à¸¤à¸”à¸¹à¸à¸²à¸¥  (Real + AI à¸—à¸³à¸™à¸²à¸¢ {len(unplayed)} à¸™à¸±à¸”à¸—à¸µà¹ˆà¹€à¸«à¸¥à¸·à¸­)")
    print(f"{'='*62}")
    print(f"  {'#':<4} {'Team':<22} {'à¹à¸•à¹‰à¸¡à¸ˆà¸£à¸´à¸‡':>9} {'AI à¸—à¸³à¸™à¸²à¸¢':>10} {'à¸£à¸§à¸¡à¸„à¸²à¸”':>8}  {'à¸ªà¸–à¸²à¸™à¸°'}")
    print(f"  {'â”€'*60}")
    for rank, (team, row) in enumerate(final_sorted.iterrows(), 1):
        if rank <= 4:    status = "ğŸ”´ CL Zone"
        elif rank <= 6:  status = "ğŸŸ  Euro Zone"
        elif rank >= 18: status = "ğŸŸ¡ Relegation"
        else:            status = ""
        try:
            real_rank = list(real_sorted.index).index(team) + 1
        except ValueError:
            real_rank = rank
        arrow = "â–²" if rank < real_rank else ("â–¼" if rank > real_rank else "â”€")
        print(f"  {rank:<4} {team:<22} {int(row['RealPoints']):>9} "
              f"{int(row['PredictedPoints']):>10} {int(row['FinalPoints']):>8}  {arrow} {status}")
    print(f"  {'â”€'*60}")
    print(f"  ğŸ”´ CL  ğŸŸ  Europa  ğŸŸ¡ à¸•à¸à¸Šà¸±à¹‰à¸™  â”‚  â–²à¸‚à¸¶à¹‰à¸™ â–¼à¸¥à¸‡ â”€à¸„à¸‡à¸—à¸µà¹ˆ")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 19) PREDICT NEXT 5 MATCHES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def fetch_fixtures_from_api(target_team, num_matches=5):
    if API_KEY == "YOUR_API_KEY_HERE":
        print("  âŒ à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹ƒà¸ªà¹ˆ API Key!")
        return None
    url     = "https://api.football-data.org/v4/competitions/PL/matches"
    headers = {"X-Auth-Token": API_KEY}
    try:
        print(f"  ğŸŒ à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸ football-data.org API...")
        r = requests.get(url, headers=headers, params={"status": "SCHEDULED"}, timeout=10)
        if r.status_code == 401: print("  âŒ API Key à¹„à¸¡à¹ˆà¸–à¸¹à¸à¸•à¹‰à¸­à¸‡"); return None
        if r.status_code == 429: print("  âŒ Rate limit â€” à¸£à¸­à¹à¸¥à¹‰à¸§à¸¥à¸­à¸‡à¹ƒà¸«à¸¡à¹ˆ"); return None
        r.raise_for_status()
        matches = r.json().get("matches", [])
        print(f"  âœ… à¸”à¸¶à¸‡à¹„à¸”à¹‰ {len(matches)} à¸™à¸±à¸”à¸—à¸µà¹ˆà¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹à¸‚à¹ˆà¸‡")
        all_fixtures = []
        for m in matches:
            from datetime import datetime, timedelta
            utc_dt = datetime.fromisoformat(m["utcDate"].replace("Z", "+00:00"))
            th_dt  = utc_dt + timedelta(hours=7)
            all_fixtures.append({
                "HomeTeam": normalize(m["homeTeam"]["name"]),
                "AwayTeam": normalize(m["awayTeam"]["name"]),
                "Date":     th_dt.strftime("%Y-%m-%d"),
                "DateObj":  th_dt,
            })
        team_fixtures = [
            f for f in all_fixtures
            if f["HomeTeam"] == target_team or f["AwayTeam"] == target_team
        ][:num_matches]
        if not team_fixtures:
            print(f"  âŒ à¹„à¸¡à¹ˆà¸à¸šà¸™à¸±à¸”à¸‚à¸­à¸‡ '{target_team}'"); return None

        print(f"\n  ğŸ“… à¸•à¸²à¸£à¸²à¸‡à¹à¸‚à¹ˆà¸‡ {num_matches} à¸™à¸±à¸”à¸‚à¹‰à¸²à¸‡à¸«à¸™à¹‰à¸²à¸‚à¸­à¸‡ {target_team}:")
        print(f"  {'à¸™à¸±à¸”':<5} {'à¸§à¸±à¸™à¸—à¸µà¹ˆ':<14} {'à¹€à¸«à¸¢à¹‰à¸²':<22} {'à¹€à¸¢à¸·à¸­à¸™':<22} {'à¸ªà¸™à¸²à¸¡'}")
        print(f"  {'â”€'*65}")
        for i, f in enumerate(team_fixtures, 1):
            venue = "à¹€à¸«à¸¢à¹‰à¸²" if f["HomeTeam"] == target_team else "à¹€à¸¢à¸·à¸­à¸™"
            print(f"  {i:<5} {f['Date']:<14} {f['HomeTeam']:<22} {f['AwayTeam']:<22} {venue}")
        return team_fixtures
    except requests.exceptions.ConnectionError:
        print("  âŒ à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¸­à¸´à¸™à¹€à¸—à¸­à¸£à¹Œà¹€à¸™à¹‡à¸•à¹„à¸¡à¹ˆà¹„à¸”à¹‰"); return None
    except Exception as e:
        print(f"  âŒ Error: {e}"); return None


def predict_next_5_matches(team, fixtures=None):
    print(f"\n{'#'*62}")
    print(f"  ğŸ”®  à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸—à¸µà¸¡: {team.upper()}")
    print(f"{'#'*62}")
    get_last_5_results(team)
    if fixtures:
        next5 = [f for f in fixtures if f['HomeTeam'] == team or f['AwayTeam'] == team][:5]
        print(f"  âœ… à¹ƒà¸Šà¹‰à¸•à¸²à¸£à¸²à¸‡à¹à¸‚à¹ˆà¸‡à¸—à¸µà¹ˆà¸£à¸°à¸šà¸¸ ({len(next5)} à¸™à¸±à¸”)")
    else:
        next5 = [f for f in remaining_fixtures if f['HomeTeam'] == team or f['AwayTeam'] == team][:5]
        print(f"  âš ï¸  à¹ƒà¸Šà¹‰à¸à¸²à¸£à¹€à¸”à¸²à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´")
    if not next5:
        print(f"\nâš ï¸  à¹„à¸¡à¹ˆà¸à¸šà¹à¸¡à¸•à¸Šà¹Œà¸‚à¹‰à¸²à¸‡à¸«à¸™à¹‰à¸²à¸‚à¸­à¸‡ {team}"); return None

    print(f"\n{'='*62}")
    print(f"  ğŸ”®  5 à¹à¸¡à¸•à¸Šà¹Œà¸‚à¹‰à¸²à¸‡à¸«à¸™à¹‰à¸²: {team}")
    print(f"{'='*62}")

    predictions = []
    for i, match in enumerate(next5, 1):
        hm, aw = match['HomeTeam'], match['AwayTeam']
        is_home = (hm == team)
        opponent = aw if is_home else hm
        venue_th = 'à¹€à¸«à¸¢à¹‰à¸²' if is_home else 'à¹€à¸¢à¸·à¸­à¸™'
        match_date = pd.Timestamp(match.get('DateObj', TODAY))
        print(f"\n  à¸™à¸±à¸”à¸—à¸µà¹ˆ {i}  |  {hm}  vs  {aw}  ({venue_th})")
        print(f"  {'â”€'*58}")
        r_pred = predict_match(hm, aw, match_date)
        s_pred = predict_score(hm, aw)
        if r_pred and s_pred:
            if is_home:
                win_pct, draw_pct, loss_pct = r_pred['Home Win'], r_pred['Draw'], r_pred['Away Win']
                outcome = r_pred['Prediction']
            else:
                win_pct, draw_pct, loss_pct = r_pred['Away Win'], r_pred['Draw'], r_pred['Home Win']
                flip = {'Home Win': 'Away Win', 'Away Win': 'Home Win', 'Draw': 'Draw'}
                outcome = flip.get(r_pred['Prediction'], r_pred['Prediction'])
            is_win  = (is_home and outcome == 'Home Win') or (not is_home and outcome == 'Away Win')
            is_draw = (outcome == 'Draw')
            result_th = f"âœ… {team} à¸Šà¸™à¸°" if is_win else ("ğŸŸ¡ à¹€à¸ªà¸¡à¸­" if is_draw else f"âŒ {team} à¹à¸à¹‰")
            print(f"\n  ğŸ“Œ à¸œà¸¥à¸—à¸µà¹ˆà¸™à¹ˆà¸²à¸ˆà¸°à¹€à¸›à¹‡à¸™ : {result_th}")
            print(f"  ğŸ“Š à¸Šà¸™à¸° {win_pct}%  |  à¹€à¸ªà¸¡à¸­ {draw_pct}%  |  à¹à¸à¹‰ {loss_pct}%")
            print(f"  ğŸ¯ à¸ªà¸à¸­à¸£à¹Œà¸„à¸²à¸”      : {s_pred['most_likely_score']}")
            predictions.append({
                'match_no': i, 'home': hm, 'away': aw,
                'venue': venue_th, 'opponent': opponent,
                'win_pct': win_pct, 'draw_pct': draw_pct, 'loss_pct': loss_pct,
                'predicted_result': outcome,
                'predicted_score': s_pred['most_likely_score'],
            })

    print(f"\n{'#'*62}")
    print(f"  ğŸ“‹  à¸ªà¸£à¸¸à¸› 5 à¹à¸¡à¸•à¸Šà¹Œà¸‚à¹‰à¸²à¸‡à¸«à¸™à¹‰à¸²: {team}")
    print(f"{'#'*62}")
    print(f"  {'à¸™à¸±à¸”':<5} {'à¸„à¸¹à¹ˆà¹à¸‚à¹ˆà¸‡':<24} {'à¸ªà¸™à¸²à¸¡':<7} {'à¸Šà¸™à¸°%':<8} {'à¹€à¸ªà¸¡à¸­%':<8} {'à¹à¸à¹‰%':<8} {'à¸ªà¸à¸­à¸£à¹Œà¸„à¸²à¸”'}")
    print(f"  {'â”€'*68}")
    for p in predictions:
        print(f"  {p['match_no']:<5} {p['opponent']:<24} {p['venue']:<7} "
              f"{p['win_pct']:<8} {p['draw_pct']:<8} {p['loss_pct']:<8} {p['predicted_score']}")
    print(f"{'#'*62}\n")
    return predictions


def predict_with_api(team, num_matches=5):
    SEP = '=' * 62
    print(f"\n{SEP}\n  ğŸ”®  à¸—à¸³à¸™à¸²à¸¢ {num_matches} à¹à¸¡à¸•à¸Šà¹Œà¸‚à¹‰à¸²à¸‡à¸«à¸™à¹‰à¸²: {team}\n{SEP}")
    fixtures = fetch_fixtures_from_api(team, num_matches)
    if fixtures:
        predict_next_5_matches(team, fixtures=fixtures)
    else:
        print('  âš ï¸  fallback: à¹ƒà¸Šà¹‰à¸à¸²à¸£à¹€à¸”à¸²à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´')
        predict_next_5_matches(team)


def show_next_pl_fixtures(num_matches=5):
    SEP = "=" * 65
    url = "https://api.football-data.org/v4/competitions/PL/matches"
    headers = {"X-Auth-Token": API_KEY}
    try:
        r = requests.get(url, headers=headers, params={"status": "SCHEDULED"}, timeout=10)
        r.raise_for_status()
        matches = r.json().get("matches", [])
        matches = sorted(matches, key=lambda x: x["utcDate"])[:num_matches]
        if not matches:
            print("  âš ï¸  à¹„à¸¡à¹ˆà¸à¸šà¹à¸¡à¸•à¸Šà¹Œ"); return

        from datetime import datetime, timedelta
        print(f"\n{SEP}\n  ğŸ“…  à¸•à¸²à¸£à¸²à¸‡à¹à¸‚à¹ˆà¸‡ Premier League {num_matches} à¸™à¸±à¸”à¸–à¸±à¸”à¹„à¸›\n{SEP}")
        print(f"  {'à¸™à¸±à¸”':<5} {'à¸§à¸±à¸™à¸—à¸µà¹ˆ':<14} {'à¹€à¸§à¸¥à¸²(TH)':<11} {'à¹€à¸«à¸¢à¹‰à¸²':<22} {'à¹€à¸¢à¸·à¸­à¸™'}")
        print("  " + "-" * 60)
        upcoming = []
        for i, m in enumerate(matches, 1):
            home = normalize(m["homeTeam"]["name"])
            away = normalize(m["awayTeam"]["name"])
            utc_dt = datetime.fromisoformat(m["utcDate"].replace("Z", "+00:00"))
            th_dt  = utc_dt + timedelta(hours=7)
            ds = th_dt.strftime("%d/%m/%Y"); ts = th_dt.strftime("%H:%M")
            print(f"  {i:<5} {ds:<14} {ts:<11} {home:<22} {away}")
            upcoming.append({"HomeTeam": home, "AwayTeam": away, "Date": ds, "Time": ts})

        print(f"\n{SEP}\n  ğŸ¤–  à¸œà¸¥à¸—à¸³à¸™à¸²à¸¢ {num_matches} à¸™à¸±à¸”à¸–à¸±à¸”à¹„à¸›\n{SEP}")
        print(f"  {'à¸™à¸±à¸”':<5} {'à¹€à¸«à¸¢à¹‰à¸²':<20} {'vs':^4} {'à¹€à¸¢à¸·à¸­à¸™':<20} "
              f"{'à¸Šà¸™à¸°%':>7} {'à¹€à¸ªà¸¡à¸­%':>7} {'à¹à¸à¹‰%':>7}  {'à¸ªà¸à¸­à¸£à¹Œ'}")
        print("  " + "-" * 75)
        teams_ok = set(match_df_clean["HomeTeam"].tolist() + match_df_clean["AwayTeam"].tolist())
        for i, f in enumerate(upcoming, 1):
            home, away = f["HomeTeam"], f["AwayTeam"]
            if home not in teams_ok or away not in teams_ok:
                print(f"  {i:<5} {home:<20} {'vs':^4} {away:<20}  âš ï¸ à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥"); continue
            r_pred = predict_match(home, away)
            s_pred = predict_score(home, away)
            if r_pred and s_pred:
                hw    = r_pred["Home Win"]; dr = r_pred["Draw"]; aw = r_pred["Away Win"]
                pred  = r_pred["Prediction"]
                icon  = "ğŸ " if pred == "Home Win" else ("ğŸ¤" if pred == "Draw" else "âœˆï¸")
                score = s_pred["most_likely_score"]
                print(f"  {i:<5} {home:<20} {'vs':^4} {away:<20} "
                      f"{hw:>7} {dr:>7} {aw:>7}  {icon} {score}")
        print("  " + "-" * 75)
        print("  ğŸ  à¹€à¸«à¸¢à¹‰à¸²à¸Šà¸™à¸°  ğŸ¤ à¹€à¸ªà¸¡à¸­  âœˆï¸ à¹€à¸¢à¸·à¸­à¸™à¸Šà¸™à¸°")
        print(SEP)
        return upcoming
    except requests.exceptions.ConnectionError:
        print("  âŒ à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¸­à¸´à¸™à¹€à¸—à¸­à¸£à¹Œà¹€à¸™à¹‡à¸•à¹„à¸¡à¹ˆà¹„à¸”à¹‰")
    except Exception as e:
        print(f"  âŒ Error: {e}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 20) FULL SUMMARY REPORT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def print_full_summary():
    SEP  = "=" * 65
    LINE = "â”€" * 65
    print()
    print("â–ˆ" * 65)
    print("  ğŸ“Š  FOOTBALL AI v4.0 â€” FULL SUMMARY REPORT")
    print(f"  ğŸ—“ï¸  à¸§à¸±à¸™à¸—à¸µà¹ˆà¸£à¸²à¸¢à¸‡à¸²à¸™: {TODAY.date()}  |  à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸–à¸¶à¸‡: {data['Date'].max().date()}")
    print("  ğŸ”¥  v4.0: 2-Stage | Optuna | SMOTE | Threshold | Deep Features")
    print("â–ˆ" * 65)

    # 1. Data info
    print(f"\n{SEP}\n  ğŸ“  1. à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¹€à¸—à¸£à¸™\n{SEP}")
    total_seasons = data['Date'].dt.year.nunique()
    teams_count   = data['HomeTeam'].nunique()
    print(f"  â€¢ à¹à¸¡à¸•à¸Šà¹Œà¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”    : {len(data):,} à¸™à¸±à¸” ({total_seasons} à¸¤à¸”à¸¹à¸à¸²à¸¥)")
    print(f"  â€¢ à¸ˆà¸³à¸™à¸§à¸™à¸—à¸µà¸¡        : {teams_count} à¸—à¸µà¸¡")
    print(f"  â€¢ à¸Šà¹ˆà¸§à¸‡à¹€à¸§à¸¥à¸²        : {data['Date'].min().date()} â†’ {data['Date'].max().date()}")
    print(f"  â€¢ à¹à¸¡à¸•à¸Šà¹Œà¹€à¸—à¸£à¸™ (80%) : {len(train):,} à¸™à¸±à¸”")
    print(f"  â€¢ à¹à¸¡à¸•à¸Šà¹Œà¹€à¸—à¸ªà¸•à¹Œ(20%) : {len(test):,} à¸™à¸±à¸”")
    print(f"  â€¢ Features à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰  : {len(FEATURES)} à¸•à¸±à¸§ (v1: 24 â†’ v2: {len(FEATURES)} âœ…)")

    # 2. Model performance
    print(f"\n{SEP}\n  ğŸ¤–  2. à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸à¹‚à¸¡à¹€à¸”à¸¥ (v4.0: 2-Stage + Optuna + SMOTE + Threshold)\n{SEP}")
    acc = round(accuracy_score(y_test, y_pred) * 100, 2)
    print(f"  â€¢ Accuracy à¸šà¸™ Test Set  : {acc}%")
    cm = confusion_matrix(y_test, y_pred)
    labels = ['Away Win', 'Draw', 'Home Win']
    print(f"\n  Confusion Matrix:")
    print(f"  {'':>14}", end="")
    for l in labels: print(f"  {l:>10}", end="")
    print()
    for i, label in enumerate(labels):
        print(f"  {'Actual ':>7}{label:>9}  ", end="")
        for j in range(3): print(f"  {cm[i][j]:>10}", end="")
        print()
    report = classification_report(y_test, y_pred, target_names=labels, output_dict=True)
    print(f"\n  {'à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ':<15} {'Precision':>10} {'Recall':>10} {'F1-Score':>10} {'Support':>10}")
    print(f"  {LINE}")
    for label in labels:
        r = report[label]
        print(f"  {label:<15} {r['precision']:>10.2f} {r['recall']:>10.2f} "
              f"{r['f1-score']:>10.2f} {int(r['support']):>10}")
    print(f"  {LINE}")
    print(f"  {'Accuracy':<15} {'':>10} {'':>10} {report['accuracy']:>10.2f} "
          f"{int(report['macro avg']['support']):>10}")

    # 3. Elo Top 10
    print(f"\n{SEP}\n  ğŸ†  3. Elo Rating à¸¥à¹ˆà¸²à¸ªà¸¸à¸” (Top 10)\n{SEP}")
    elo_sorted = sorted(final_elo.items(), key=lambda x: x[1], reverse=True)[:10]
    max_elo = elo_sorted[0][1]
    print(f"  {'#':<5} {'à¸—à¸µà¸¡':<25} {'Elo':>8}  {'Bar'}")
    print(f"  {LINE}")
    for rank, (team, elo_val) in enumerate(elo_sorted, 1):
        bar    = 'â–ˆ' * int((elo_val / max_elo) * 20)
        marker = "ğŸ¥‡" if rank==1 else ("ğŸ¥ˆ" if rank==2 else ("ğŸ¥‰" if rank==3 else f"{rank:<2} "))
        print(f"  {marker}   {team:<25} {round(elo_val):>8}  {bar}")

    # 4. Season table
    if final_table is not None:
        print(f"\n{SEP}\n  ğŸ“‹  4. à¸•à¸²à¸£à¸²à¸‡à¸„à¸²à¸”à¸à¸²à¸£à¸“à¹Œà¸ªà¸´à¹‰à¸™à¸¤à¸”à¸¹à¸à¸²à¸¥ Season 2025-26\n{SEP}")
        print(f"  {'#':<5} {'à¸—à¸µà¸¡':<22} {'à¸„à¸°à¹à¸™à¸™à¸ˆà¸£à¸´à¸‡':>10} {'à¸„à¸°à¹à¸™à¸™à¸—à¸³à¸™à¸²à¸¢':>12} {'à¸£à¸§à¸¡':>7}  {'à¸ªà¸–à¸²à¸™à¸°'}")
        print(f"  {LINE}")
        for rank, (team, row) in enumerate(final_table.sort_values('FinalPoints', ascending=False).iterrows(), 1):
            if rank<=4:    status = "ğŸ”´ Champions League"
            elif rank<=6:  status = "ğŸŸ  Europa / Conf."
            elif rank>=18: status = "ğŸŸ¡ à¸•à¸à¸Šà¸±à¹‰à¸™"
            else:          status = ""
            print(f"  {rank:<5} {team:<22} {int(row['RealPoints']):>10} "
                  f"{int(row['PredictedPoints']):>12} {int(row['FinalPoints']):>7}  {status}")
        print(f"  {LINE}")
        print(f"  ğŸ”´ Top 4 = UEFA CL  |  ğŸŸ  Top 5-6 = Europa/Conf.  |  ğŸŸ¡ 18-20 = à¸•à¸à¸Šà¸±à¹‰à¸™")

    # 5. à¸ªà¸–à¸´à¸•à¸´
    print(f"\n{SEP}\n  ğŸ“ˆ  5. à¸ªà¸–à¸´à¸•à¸´à¸™à¹ˆà¸²à¸ªà¸™à¹ƒà¸ˆà¸ˆà¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥\n{SEP}")
    valid = data.dropna(subset=['FTHG', 'FTAG'])
    home_wins  = (valid['FTHG'] > valid['FTAG']).sum()
    draws      = (valid['FTHG'] == valid['FTAG']).sum()
    away_wins  = (valid['FTHG'] < valid['FTAG']).sum()
    total_v    = len(valid)
    avg_goals  = (valid['FTHG'] + valid['FTAG']).mean()
    print(f"  â€¢ à¹€à¸«à¸¢à¹‰à¸²à¸Šà¸™à¸°       : {home_wins:,} à¸™à¸±à¸” ({home_wins/total_v*100:.1f}%)")
    print(f"  â€¢ à¹€à¸ªà¸¡à¸­           : {draws:,} à¸™à¸±à¸” ({draws/total_v*100:.1f}%)")
    print(f"  â€¢ à¹€à¸¢à¸·à¸­à¸™à¸Šà¸™à¸°       : {away_wins:,} à¸™à¸±à¸” ({away_wins/total_v*100:.1f}%)")
    print(f"  â€¢ à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸›à¸£à¸°à¸•à¸¹/à¸™à¸±à¸” : {avg_goals:.2f} à¸›à¸£à¸°à¸•à¸¹")

    goals_scored   = valid.groupby('HomeTeam')['FTHG'].sum() + valid.groupby('AwayTeam')['FTAG'].sum()
    goals_conceded = valid.groupby('HomeTeam')['FTAG'].sum() + valid.groupby('AwayTeam')['FTHG'].sum()
    print(f"  â€¢ à¸—à¸µà¸¡à¸¢à¸´à¸‡à¸¡à¸²à¸à¸ªà¸¸à¸”   : {goals_scored.idxmax()} ({int(goals_scored.max())} à¸›à¸£à¸°à¸•à¸¹)")
    print(f"  â€¢ à¸—à¸µà¸¡à¹€à¸ªà¸µà¸¢à¸¡à¸²à¸à¸ªà¸¸à¸”  : {goals_conceded.idxmax()} ({int(goals_conceded.max())} à¸›à¸£à¸°à¸•à¸¹)")

    # 6. à¸ªà¸£à¸¸à¸›à¹‚à¸¡à¹€à¸”à¸¥
    print(f"\n{SEP}\n  ğŸ’¡  6. à¸ªà¸£à¸¸à¸›à¹à¸¥à¸°à¸„à¸³à¹à¸™à¸°à¸™à¸³\n{SEP}")
    draw_f1  = report['Draw']['f1-score']
    home_f1  = report['Home Win']['f1-score']
    away_f1  = report['Away Win']['f1-score']
    print(f"  â€¢ à¹‚à¸¡à¹€à¸”à¸¥ Ensemble v2 (LR+RF+ET+GBT+MLP): {acc}% accuracy")
    print(f"  â€¢ Home Win F1: {home_f1:.2f}  |  Draw F1: {draw_f1:.2f}  |  Away Win F1: {away_f1:.2f}")
    print(f"  â€¢ Features: {len(FEATURES)} à¸•à¸±à¸§ (à¹€à¸à¸´à¹ˆà¸¡ EWM, GD, Draw rate, Days Rest, Seasonal)")
    if draw_f1 > 0.1:
        print(f"  âœ… Draw F1 à¸”à¸µà¸‚à¸¶à¹‰à¸™à¸ˆà¸²à¸ ~0.03 â†’ {draw_f1:.2f} (class_weight + draw features)")
    else:
        print(f"  âš ï¸  Draw F1 à¸¢à¸±à¸‡à¸•à¹ˆà¸³ ({draw_f1:.2f}) â€” à¸¥à¸­à¸‡à¹€à¸à¸´à¹ˆà¸¡ SMOTE à¸«à¸£à¸·à¸­ injury data")
    print(f"\n  ğŸš€ v2 improvements:")
    print(f"     âœ… EWM rolling features (à¸Ÿà¸­à¸£à¹Œà¸¡à¸¥à¹ˆà¸²à¸ªà¸¸à¸”à¸ªà¸³à¸„à¸±à¸à¸à¸§à¹ˆà¸²)")
    print(f"     âœ… Draw-specific features (H2H draw rate, combined GF, GD variance)")
    print(f"     âœ… Venue-specific Elo (à¹€à¸«à¸¢à¹‰à¸²/à¹€à¸¢à¸·à¸­à¸™ à¹à¸¢à¸à¸à¸±à¸™)")
    print(f"     âœ… Days rest, Momentum, Seasonal phase")
    print(f"     âœ… 5 models ensemble + calibration")

    print()
    print("â–ˆ" * 65)
    print("  âœ…  END OF REPORT v2.0")
    print("â–ˆ" * 65)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 21) MONTE CARLO SIMULATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run_monte_carlo(n_simulations=1000, verbose=True):
    if final_table is None:
        print("âŒ à¸à¸£à¸¸à¸“à¸²à¹€à¸£à¸µà¸¢à¸ run_season_simulation() à¸à¹ˆà¸­à¸™"); return None

    SEP  = "=" * 65
    LINE = "â”€" * 65
    if verbose:
        print(f"\n{SEP}")
        print(f"  ğŸ²  MONTE CARLO SEASON SIMULATION  ({n_simulations:,} à¸£à¸­à¸š)")
        print(SEP)
        print(f"  à¸à¸³à¸¥à¸±à¸‡à¸ˆà¸³à¸¥à¸­à¸‡ {len(remaining_fixtures)} à¹à¸¡à¸•à¸Šà¹Œ Ã— {n_simulations:,} à¸£à¸­à¸š ...")

    if not remaining_fixtures:
        print("  â„¹ï¸  à¸¤à¸”à¸¹à¸à¸²à¸¥à¸ˆà¸šà¹à¸¥à¹‰à¸§"); return None

    future_rows = []
    for match in remaining_fixtures:
        home, away = match['HomeTeam'], match['AwayTeam']
        row = build_match_row(home, away)
        future_rows.append(row)

    future_df    = pd.DataFrame(future_rows)
    X_future_sc  = scaler.transform(future_df[FEATURES])
    proba_matrix = ensemble.predict_proba(X_future_sc)

    all_teams = list(final_table.index)
    real_pts  = {t: int(final_table.loc[t, 'RealPoints']) for t in all_teams}
    counts    = {t: {'top4': 0, 'top6': 0, 'relegation': 0, 'pts_sum': 0.0, 'pts_sq': 0.0}
                 for t in all_teams}
    rng = np.random.default_rng(42)

    for _ in range(n_simulations):
        sim_pts = dict(real_pts)
        for idx, match in enumerate(remaining_fixtures):
            home, away = match['HomeTeam'], match['AwayTeam']
            p_away, p_draw, p_home = proba_matrix[idx]
            probs = np.array([p_away, p_draw, p_home], dtype=np.float64)
            probs /= probs.sum()
            outcome = rng.choice([0, 1, 2], p=probs)
            if outcome == 2:    sim_pts[home] += 3
            elif outcome == 1:  sim_pts[home] += 1; sim_pts[away] += 1
            else:               sim_pts[away] += 3
        ranked = sorted(sim_pts.items(), key=lambda x: x[1], reverse=True)
        for rank, (team, pts) in enumerate(ranked, 1):
            if rank <= 4:  counts[team]['top4'] += 1
            if rank <= 6:  counts[team]['top6'] += 1
            if rank >= 18: counts[team]['relegation'] += 1
            counts[team]['pts_sum'] += pts
            counts[team]['pts_sq']  += pts ** 2

    results = {}
    for t in all_teams:
        c    = counts[t]
        mean = c['pts_sum'] / n_simulations
        std  = ((c['pts_sq'] / n_simulations) - mean**2) ** 0.5
        results[t] = {
            'top4':       round(c['top4']       / n_simulations * 100, 1),
            'top6':       round(c['top6']       / n_simulations * 100, 1),
            'relegation': round(c['relegation'] / n_simulations * 100, 1),
            'mean_pts':   round(mean, 1),
            'std_pts':    round(std,  1),
        }

    if verbose:
        sorted_results = sorted(results.items(), key=lambda x: x[1]['mean_pts'], reverse=True)
        print(f"\n  {'Team':<22} {'Mean Pts':>9} {'Â±Std':>6} {'Top4%':>7} {'Top6%':>7} {'Rel%':>7}  {'Bar'}")
        print(f"  {LINE}")
        for team, r in sorted_results:
            bar_top4 = 'â–ˆ' * int(r['top4'] / 5)
            bar_rel  = 'â–“' * int(r['relegation'] / 5)
            bar      = bar_top4 if r['top4'] >= r['relegation'] else bar_rel
            c_t4     = "ğŸ”´" if r['top4'] >= 60 else ("ğŸŸ¡" if r['top4'] >= 20 else "  ")
            c_rel    = "ğŸŸ¡" if r['relegation'] >= 60 else ("âš ï¸ " if r['relegation'] >= 20 else "  ")
            print(f"  {team:<22} {r['mean_pts']:>9} {r['std_pts']:>6} "
                  f"{c_t4}{r['top4']:>5}%  {r['top6']:>6}%  {c_rel}{r['relegation']:>4}%  {bar}")
        print(f"\n  âœ… Monte Carlo à¹€à¸ªà¸£à¹‡à¸ˆà¸ªà¸´à¹‰à¸™ ({n_simulations:,} simulations)")
        print(SEP)
    return results


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 22) DRAW CALIBRATION ANALYSIS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def analyze_draw_calibration():
    SEP  = "=" * 65
    LINE = "â”€" * 65
    print(f"\n{SEP}\n  ğŸ“  DRAW CALIBRATION ANALYSIS\n{SEP}")

    # ğŸ”¥ FIX 2 (v7): à¹ƒà¸Šà¹‰ proba_hybrid (à¸œà¹ˆà¸²à¸™ draw suppression + Poisson blend à¹à¸¥à¹‰à¸§)
    #    à¹€à¸”à¸´à¸¡: ensemble.predict_proba() â†’ raw proba à¸à¹ˆà¸­à¸™ suppression â†’ bias à¸¢à¸±à¸‡à¸­à¸¢à¸¹à¹ˆ
    #    à¹ƒà¸«à¸¡à¹ˆ: proba_hybrid â†’ proba à¸—à¸µà¹ˆà¸œà¹ˆà¸²à¸™ suppress_draw_proba() à¹à¸¥à¹‰à¸§ â†’ calibration à¹à¸¡à¹ˆà¸™à¸à¸§à¹ˆà¸²
    #    à¸–à¹‰à¸² proba_hybrid à¸¢à¸±à¸‡à¹„à¸¡à¹ˆ define â†’ fallback à¹„à¸› proba_2stage
    try:
        draw_proba_source = proba_hybrid
        source_tag = "Hybrid (post-suppression)"
    except NameError:
        try:
            draw_proba_source = proba_2stage
            source_tag = "2-Stage (post-suppression fallback)"
        except NameError:
            draw_proba_source = ensemble.predict_proba(X_test_sc)
            source_tag = "Ensemble raw (fallback)"

    draw_proba  = draw_proba_source[:, 1]
    actual_draw = (y_test == 1).astype(int).values
    print(f"  ğŸ“Œ Source: {source_tag}")

    n_bins = 8
    fraction_of_positives, mean_predicted_value = calibration_curve(
        actual_draw, draw_proba, n_bins=n_bins, strategy='quantile'
    )
    print(f"\n  Predicted%   Actual%    Diff     Calibration Bar")
    print(f"  {LINE}")
    for pred_p, act_p in zip(mean_predicted_value, fraction_of_positives):
        diff     = act_p - pred_p
        bar_pred = 'â–ˆ' * int(pred_p * 30)
        bar_act  = 'â–‘' * int(act_p  * 30)
        sign     = "+" if diff >= 0 else "-"
        flag     = "âœ…" if abs(diff) < 0.05 else ("âš ï¸ " if abs(diff) < 0.10 else "âŒ")
        print(f"  {pred_p*100:>8.1f}%   {act_p*100:>6.1f}%   {sign}{abs(diff)*100:>4.1f}%  {flag}  "
              f"pred:{bar_pred:<15} act:{bar_act:<15}")

    brier          = brier_score_loss(actual_draw, draw_proba)
    brier_baseline = brier_score_loss(actual_draw, np.full_like(draw_proba, actual_draw.mean()))
    skill          = (1 - brier / brier_baseline) * 100

    print(f"\n  {LINE}")
    print(f"  ğŸ“Š Brier Score (Draw)  : {brier:.4f}")
    print(f"  ğŸ“Š Baseline Brier      : {brier_baseline:.4f}")
    print(f"  ğŸ“Š Brier Skill Score   : {skill:.1f}%  {'âœ… à¸”à¸µà¸à¸§à¹ˆà¸² baseline' if skill>0 else 'âŒ à¹à¸¢à¹ˆà¸à¸§à¹ˆà¸² baseline'}")
    bias = draw_proba.mean()*100 - actual_draw.mean()*100
    print(f"  ğŸ“Š Systematic Bias     : {bias:+.1f}%")
    print(SEP)
    return {'brier': brier, 'brier_baseline': brier_baseline, 'skill': skill, 'bias': bias}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 23) ğŸ”¥ SHAP FEATURE IMPORTANCE (v3.0)
#     SHAP à¸”à¸µà¸à¸§à¹ˆà¸² impurity à¹€à¸à¸£à¸²à¸°: consistent, accounts for interactions
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run_feature_importance(max_display=20):
    SEP  = "=" * 65
    LINE = "â”€" * 65
    print(f"\n{SEP}\n  ğŸ”  SHAP + Feature IMPORTANCE (v4.0)\n{SEP}")

    # ğŸ”¥ v4.0: à¹ƒà¸Šà¹‰ stage1 (Draw vs Not-Draw) à¹à¸¥à¸° stage2 (Home vs Away) à¹à¸¢à¸à¸à¸±à¸™
    lgbm_fitted = stage1_cal if hasattr(stage1_cal, 'feature_importances_') else None
    if lgbm_fitted is None and hasattr(stage1_cal, 'estimators_'):
        # calibrated wrapper
        try: lgbm_fitted = stage1_cal.estimators_[0] if hasattr(stage1_cal, 'estimators_') else None
        except: pass
    # fallback to single-stage
    if lgbm_fitted is None:
        lgbm_fitted = fallback_single if hasattr(fallback_single, 'feature_importances_') else None
    rf_fitted   = lgbm_fitted   # for compatibility
    gbt_fitted  = None

    # ğŸ”¥ SHAP à¸”à¹‰à¸§à¸¢ LightGBM (à¸–à¹‰à¸²à¸à¸£à¹‰à¸­à¸¡) â€” à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡à¸à¸§à¹ˆà¸² impurity
    if SHAP_AVAILABLE and lgbm_fitted is not None:
        print(f"\n  ğŸ”¥ SHAP Values (LightGBM â€” per class average |SHAP|)")
        print(f"  {'#':<4} {'Feature':<28} {'SHAP Importance':>16}  {'Bar'}")
        print(f"  {LINE}")
        try:
            explainer   = shap.TreeExplainer(lgbm_fitted)
            shap_values = explainer.shap_values(X_test_sc)  # shape: (n_samples, n_features, n_classes) or list
            if isinstance(shap_values, list):
                # list of arrays per class
                mean_abs_shap = np.mean([np.abs(sv).mean(axis=0) for sv in shap_values], axis=0)
            else:
                mean_abs_shap = np.abs(shap_values).mean(axis=0)
                if mean_abs_shap.ndim > 1:
                    mean_abs_shap = mean_abs_shap.mean(axis=-1)

            shap_sorted = np.argsort(mean_abs_shap)[::-1][:max_display]
            max_shap = mean_abs_shap[shap_sorted[0]]
            for rank, idx in enumerate(shap_sorted, 1):
                bar = 'â–ˆ' * int(mean_abs_shap[idx] / max_shap * 30)
                print(f"  {rank:<4} {FEATURES[idx]:<28} {mean_abs_shap[idx]:>16.4f}  {bar}")

            # Feature reduction suggestion
            low_imp_features = [FEATURES[i] for i in range(len(FEATURES))
                                if mean_abs_shap[i] < mean_abs_shap.mean() * 0.1]
            if low_imp_features:
                print(f"\n  ğŸ’¡ Low-importance features (consider dropping):")
                print(f"     {', '.join(low_imp_features[:10])}")
                print(f"     Dropping these may improve accuracy by 1-2%")
        except Exception as e:
            print(f"  âš ï¸  SHAP computation failed: {e}")
    elif SHAP_AVAILABLE and rf_fitted is not None:
        print(f"\n  ğŸ”¥ SHAP Values (RandomForest)")
        try:
            explainer   = shap.TreeExplainer(rf_fitted)
            shap_values = explainer.shap_values(X_test_sc[:200])  # sample for speed
            if isinstance(shap_values, list):
                mean_abs_shap = np.mean([np.abs(sv).mean(axis=0) for sv in shap_values], axis=0)
            else:
                mean_abs_shap = np.abs(shap_values).mean(axis=0)
            shap_sorted = np.argsort(mean_abs_shap)[::-1][:max_display]
            max_shap = mean_abs_shap[shap_sorted[0]]
            for rank, idx in enumerate(shap_sorted, 1):
                bar = 'â–ˆ' * int(mean_abs_shap[idx] / max_shap * 30)
                print(f"  {rank:<4} {FEATURES[idx]:<28} {mean_abs_shap[idx]:>16.4f}  {bar}")
        except Exception as e:
            print(f"  âš ï¸  SHAP computation failed: {e}")
    else:
        if not SHAP_AVAILABLE:
            print("  âš ï¸  SHAP not installed â€” pip install shap")
        print("  â†’ Falling back to RF impurity importance")

    # â”€â”€ RF impurity (always show as reference) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if rf_fitted:
        importances = rf_fitted.feature_importances_
        sorted_idx  = np.argsort(importances)[::-1][:max_display]
        max_imp     = importances[sorted_idx[0]]
        print(f"\n  RandomForest Impurity Importance (reference)")
        print(f"  {'#':<4} {'Feature':<28} {'Score':>8}  {'Bar'}")
        print(f"  {LINE}")
        for rank, idx in enumerate(sorted_idx[:10], 1):
            bar = 'â–ˆ' * int(importances[idx] / max_imp * 30)
            print(f"  {rank:<4} {FEATURES[idx]:<28} {importances[idx]:>8.4f}  {bar}")

    # ğŸ”¥ LightGBM built-in importance (gain)
    if lgbm_fitted is not None:
        try:
            lgbm_imp = lgbm_fitted.feature_importances_
            lgbm_sorted = np.argsort(lgbm_imp)[::-1][:10]
            max_lgbm = lgbm_imp[lgbm_sorted[0]]
            print(f"\n  LightGBM Gain Importance ğŸ”¥")
            print(f"  {'#':<4} {'Feature':<28} {'Gain':>8}  {'Bar'}")
            print(f"  {LINE}")
            for rank, idx in enumerate(lgbm_sorted, 1):
                bar = 'â–ˆ' * int(lgbm_imp[idx] / max_lgbm * 30)
                print(f"  {rank:<4} {FEATURES[idx]:<28} {lgbm_imp[idx]:>8.0f}  {bar}")
        except Exception as e:
            print(f"  âš ï¸  LightGBM importance failed: {e}")

    print(SEP)
    return sorted_idx if rf_fitted else None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 24) ROLLING WINDOW CV
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def rolling_window_cv(n_splits=5, verbose=True):
    SEP  = "=" * 65
    LINE = "â”€" * 65
    if verbose:
        print(f"\n{SEP}\n  ğŸ”„  ROLLING WINDOW CROSS-VALIDATION  ({n_splits} folds)\n{SEP}")

    cv_df = match_df_clean.sort_values('Date_x').reset_index(drop=True)
    X_cv  = cv_df[FEATURES].values
    y_cv  = cv_df['Result3'].values

    # ğŸ”¥ FIX E: à¹ƒà¸Šà¹‰ min_train_size à¹€à¸à¸·à¹ˆà¸­à¸¥à¸” variance à¸‚à¸­à¸‡ fold à¹à¸£à¸ à¹†
    #    Fold 1 à¹€à¸”à¸´à¸¡ train à¹à¸„à¹ˆ 638 à¸™à¸±à¸” â†’ LGBM à¸—à¸µà¹ˆ tuned à¸¡à¸²à¸ˆà¸²à¸ 3000+ à¸™à¸±à¸” overfit
    #    min_train_size=800 â†’ skip fold à¸—à¸µà¹ˆ train à¸™à¹‰à¸­à¸¢à¹€à¸à¸´à¸™à¹„à¸›
    MIN_TRAIN_SIZE = 800
    tscv = TimeSeriesSplit(n_splits=n_splits)
    fold_results = []

    if verbose:
        print(f"\n  {'Fold':<6} {'Train':>7} {'Val':>6} {'Acc':>7} "
              f"{'HW-F1':>9} {'DR-F1':>9} {'AW-F1':>9} {'LogLoss':>9}")
        print(f"  {LINE}")

    for fold, (train_idx, val_idx) in enumerate(tscv.split(X_cv), 1):
        X_tr, X_vl = X_cv[train_idx], X_cv[val_idx]
        y_tr, y_vl = y_cv[train_idx], y_cv[val_idx]

        # ğŸ”¥ FIX E: Skip fold à¸–à¹‰à¸² train set à¹€à¸¥à¹‡à¸à¹€à¸à¸´à¸™à¹„à¸›
        if len(X_tr) < MIN_TRAIN_SIZE:
            if verbose:
                print(f"  {fold:<6} {len(X_tr):>7} {len(X_vl):>6}  "
                      f"â­ï¸ Skip (train < {MIN_TRAIN_SIZE} â€” à¸œà¸¥à¹„à¸¡à¹ˆà¸™à¹ˆà¸²à¹€à¸Šà¸·à¹ˆà¸­à¸–à¸·à¸­)")
            continue

        sc_fold  = StandardScaler()
        X_tr_sc  = sc_fold.fit_transform(X_tr)
        X_vl_sc  = sc_fold.transform(X_vl)

        # ğŸ”¥ FIX CONSISTENCY: à¹ƒà¸Šà¹‰ shared params à¹€à¸«à¸¡à¸·à¸­à¸™ main model
        if LGBM_AVAILABLE:
            cv_gbt = lgb.LGBMClassifier(**get_cv_lgbm_params())
        else:
            cv_gbt = GradientBoostingClassifier(
                n_estimators=200, max_depth=4, learning_rate=0.05,
                subsample=0.8, random_state=42
            )
        cv_gbt.fit(X_tr_sc, y_tr)

        # ğŸ”¥ FIX 1 v7b: Narrow threshold search anchored à¸£à¸­à¸šà¸„à¹ˆà¸²à¸ˆà¸²à¸ main model
        #    à¹€à¸”à¸´à¸¡ v7a: freeze threshold â†’ CV accuracy à¸•à¸ (threshold à¸•à¹ˆà¸²à¸‡à¸¢à¸¸à¸„à¹ƒà¸Šà¹‰à¹„à¸¡à¹ˆà¹„à¸”à¹‰)
        #    à¹€à¸”à¸´à¸¡ v6:  full grid search n_steps=30 â†’ variance à¸ªà¸¹à¸‡ + leakage à¹€à¸¥à¹‡à¸à¸™à¹‰à¸­à¸¢
        #    à¹ƒà¸«à¸¡à¹ˆ v7b: search à¹à¸„à¹ˆ Â±0.05 à¸£à¸­à¸š main model threshold â†’ à¸¥à¸” variance + à¹€à¸«à¸¡à¸²à¸°à¸à¸±à¸š fold
        y_proba_fold  = cv_gbt.predict_proba(X_vl_sc)
        y_proba_fold  = suppress_draw_proba(y_proba_fold, draw_factor=DRAW_SUPPRESS_FACTOR)
        try:
            # narrow search: Â±0.05 à¸£à¸­à¸š main model thresholds
            t_home_center = OPT_T_HOME
            t_draw_center = OPT_T_DRAW
            t_h, t_d, _ = optimize_thresholds(
                y_proba_fold, y_vl, n_steps=10,
                t_home_range=(max(0.15, t_home_center - 0.05), min(0.55, t_home_center + 0.05)),
                t_draw_range=(max(0.15, t_draw_center - 0.05), min(0.55, t_draw_center + 0.05)),
            )
        except (NameError, TypeError):
            # fallback à¸–à¹‰à¸² OPT_T_HOME à¸¢à¸±à¸‡à¹„à¸¡à¹ˆ define à¸«à¸£à¸·à¸­ optimize_thresholds à¹„à¸¡à¹ˆà¸£à¸±à¸š range params
            t_h, t_d, _ = optimize_thresholds(y_proba_fold, y_vl, n_steps=15)
        y_pred_fold   = apply_thresholds(y_proba_fold, t_home=t_h, t_draw=t_d)

        a   = accuracy_score(y_vl, y_pred_fold)
        ll  = log_loss(y_vl, y_proba_fold)
        rep = classification_report(y_vl, y_pred_fold, output_dict=True, zero_division=0)
        hw_f1   = rep.get('2', {}).get('f1-score', 0)
        draw_f1 = rep.get('1', {}).get('f1-score', 0)
        aw_f1   = rep.get('0', {}).get('f1-score', 0)
        fold_results.append({'fold': fold, 'train': len(train_idx), 'val': len(val_idx),
                             'acc': a, 'hw_f1': hw_f1, 'draw_f1': draw_f1,
                             'aw_f1': aw_f1, 'logloss': ll})
        if verbose:
            print(f"  {fold:<6} {len(train_idx):>7} {len(val_idx):>6} {a:>7.4f} "
                  f"{hw_f1:>9.4f} {draw_f1:>9.4f} {aw_f1:>9.4f} {ll:>9.4f}")

    accs = [r['acc'] for r in fold_results]
    lls  = [r['logloss'] for r in fold_results]
    dr   = [r['draw_f1'] for r in fold_results]
    if verbose:
        print(f"  {LINE}")
        print(f"  {'Mean':<6} {'':>7} {'':>6} {np.mean(accs):>7.4f} "
              f"{np.mean([r['hw_f1'] for r in fold_results]):>9.4f} "
              f"{np.mean(dr):>9.4f} "
              f"{np.mean([r['aw_f1'] for r in fold_results]):>9.4f} "
              f"{np.mean(lls):>9.4f}")
        print(f"\n  ğŸ“Š Mean CV Accuracy : {np.mean(accs):.4f} Â± {np.std(accs):.4f}")
        print(f"  ğŸ“Š Mean Draw F1     : {np.mean(dr):.4f} (v1 â‰ˆ 0.03)")
        print(f"  ğŸ“Š CV LogLoss       : {np.mean(lls):.4f}")
        stab = "âœ… à¹€à¸ªà¸–à¸µà¸¢à¸£" if np.std(accs) < 0.03 else "âš ï¸ unstable"
        print(f"  ğŸ“Š à¸„à¸§à¸²à¸¡à¹€à¸ªà¸–à¸µà¸¢à¸£       : {stab}")

        # ğŸ”¥ FIX 3 (v7): à¹€à¸à¸´à¹ˆà¸¡ weighted accuracy (à¸™à¹‰à¸³à¸«à¸™à¸±à¸à¸•à¸²à¸¡ fold size)
        total_val = sum(r['val'] for r in fold_results)
        weighted_acc = sum(r['acc'] * r['val'] for r in fold_results) / total_val if total_val > 0 else 0
        print(f"  ğŸ“Š Weighted CV Acc  : {weighted_acc:.4f}  (à¸™à¹‰à¸³à¸«à¸™à¸±à¸à¸•à¸²à¸¡ fold size â€” à¹à¸¡à¹ˆà¸™à¸à¸§à¹ˆà¸² simple mean)")

        # ğŸ”¥ v8: à¸­à¸˜à¸´à¸šà¸²à¸¢ gap à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ CV à¹à¸¥à¸° main model
        print(f"\n  ğŸ’¡ à¸—à¸³à¹„à¸¡ CV Accuracy à¸•à¹ˆà¸³à¸à¸§à¹ˆà¸² Main Model:")
        print(f"     â€¢ CV folds à¹ƒà¸Šà¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸¢à¸¸à¸„ 2020-2022 (distribution à¸•à¹ˆà¸²à¸‡à¸ˆà¸²à¸ test à¸›à¸µ 2024-25)")
        print(f"     â€¢ CV à¹ƒà¸Šà¹‰ single-stage LightGBM (à¹„à¸¡à¹ˆà¸¡à¸µ 2-stage + Poisson hybrid)")
        print(f"     â€¢ Walk-forward accuracy (~0.48-0.52) à¸™à¹ˆà¸²à¹€à¸Šà¸·à¹ˆà¸­à¸–à¸·à¸­à¸à¸§à¹ˆà¸²à¸ªà¸³à¸«à¸£à¸±à¸š production")
        print(SEP)
    return fold_results


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 25) BACKTEST ROI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def backtest_roi(bankroll=1000.0, min_edge=0.03, kelly_fraction=0.25,
                 max_exposure=0.05, verbose=True, odds_shrink=0.0,
                 mode='closing'):
    """
    ğŸ”¥ v3.0 Kelly Criterion Betting Strategy
    - Full Kelly sizing with fraction
    - min_edge: à¸•à¹‰à¸­à¸‡à¸¡à¸µ edge > X% à¸–à¸¶à¸‡à¹€à¸”à¸´à¸¡à¸à¸±à¸™
    - max_exposure: à¸ˆà¸³à¸à¸±à¸” % bankroll à¸•à¹ˆà¸­à¹à¸¡à¸•à¸Šà¹Œ (risk management)
    - à¹à¸ªà¸”à¸‡ edge distribution + per-outcome ROI

    ğŸ”¥ FIX 3: Opening odds stress test
    - mode='closing'     : à¹ƒà¸Šà¹‰ B365 odds (closing) â€” optimistic
    - mode='conservative': shrink implied prob 5% à¹€à¸à¸·à¹ˆà¸­ simulate opening odds
    - mode='max_odds'    : à¹ƒà¸Šà¹‰ Max odds à¸–à¹‰à¸²à¸¡à¸µ (worst-case for edge)
    - odds_shrink=0.05   : à¸¥à¸” edge à¸¥à¸‡ 5% à¸ªà¸³à¸«à¸£à¸±à¸š conservative estimate
    """
    SEP  = "=" * 65
    LINE = "â”€" * 65
    if verbose:
        mode_tag = f"[{mode}{'  shrink='+str(odds_shrink) if odds_shrink>0 else ''}]"
        print(f"\n{SEP}")
        print(f"  ğŸ’°  KELLY CRITERION BACKTEST (v3.0) {mode_tag}")
        print(f"  Bankroll: Â£{bankroll:,.0f} | Min Edge: {min_edge*100:.0f}% | "
              f"Kelly: {kelly_fraction*100:.0f}% | Max: {max_exposure*100:.0f}%/bet")
        print(SEP)

    # ğŸ”¥ v5.0: à¹ƒà¸Šà¹‰ 2-Stage + Hybrid probabilities
    proba_test = proba_hybrid   # â† use hybrid (Poisson blended) if available
    label_map  = {0: 'Away Win', 1: 'Draw', 2: 'Home Win'}

    # ğŸ”¥ FIX 3: à¸”à¸¶à¸‡ odds à¸ˆà¸²à¸ market à¸•à¸²à¸¡ mode à¸—à¸µà¹ˆà¹€à¸¥à¸·à¸­à¸ (à¸–à¹‰à¸²à¹€à¸›à¸´à¸”à¹ƒà¸Šà¹‰ market à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™)
    real_odds_test = None
    if USE_MARKET_FEATURES and ODDS_AVAILABLE and '_ImpH' in test.columns:
        try:
            # ğŸ”¥ FIX 3a: à¸¥à¸­à¸‡à¹ƒà¸Šà¹‰ Max odds à¸à¹ˆà¸­à¸™ (à¸–à¹‰à¸²à¸¡à¸µ) â€” à¹€à¸›à¹‡à¸™ worst-case à¸ªà¸³à¸«à¸£à¸±à¸š edge
            _max_h = _find_odds_col(data, ['MaxH','BbMxH'])
            _max_d = _find_odds_col(data, ['MaxD','BbMxD'])
            _max_a = _find_odds_col(data, ['MaxA','BbMxA'])
            use_max = (mode == 'max_odds' and
                       all(x is not None for x in [_max_h, _max_d, _max_a]))

            if use_max:
                # Merge max odds into test
                max_odds_df = data[['MatchID',_max_h,_max_d,_max_a]].copy()
                test_with_max = test.merge(max_odds_df, on='MatchID', how='left')
                oh = 1 / pd.to_numeric(test_with_max[_max_h], errors='coerce').fillna(3)
                od = 1 / pd.to_numeric(test_with_max[_max_d], errors='coerce').fillna(3)
                oa = 1 / pd.to_numeric(test_with_max[_max_a], errors='coerce').fillna(3)
                print(f"  ğŸ“Œ Using Max odds (worst-case edge) ğŸ”¥")
            else:
                # à¹ƒà¸Šà¹‰ implied prob à¸ˆà¸²à¸ B365 (closing odds)
                oh = test['_ImpH'].values
                od = test['_ImpD'].values
                oa = test['_ImpA'].values

            # ğŸ”¥ FIX 3b: Conservative mode â€” simulate opening odds à¹‚à¸”à¸¢ shrink implied prob
            # Closing odds efficient à¸à¸§à¹ˆà¸² opening ~3-7%
            # à¸–à¹‰à¸² shrink=0.05 â†’ reduce edge by 5% â†’ simulate opening odds impact
            if odds_shrink > 0 and not use_max:
                total_imp = oh + od + oa
                # à¹€à¸à¸´à¹ˆà¸¡ overround à¸‚à¸¶à¹‰à¸™ (à¹à¸¢à¹ˆà¸à¸§à¹ˆà¸²à¸ªà¸³à¸«à¸£à¸±à¸š bettor)
                oh = oh + odds_shrink * oh / total_imp
                od = od + odds_shrink * od / total_imp
                oa = oa + odds_shrink * oa / total_imp
                print(f"  âš ï¸  Conservative mode: odds shrunk by {odds_shrink*100:.0f}% (simulate opening)")

            # Convert implied prob â†’ decimal odds
            real_odds_test = np.column_stack([
                np.where(oa > 0.01, 1/oa, 99),   # away odds (cls 0)
                np.where(od > 0.01, 1/od, 99),   # draw odds (cls 1)
                np.where(oh > 0.01, 1/oh, 99),   # home odds (cls 2)
            ])
            odds_source = "Max odds" if use_max else ("Conservative B365" if odds_shrink > 0 else "B365 closing")
            print(f"  âœ… Using {odds_source} for backtest (Phase 2) ğŸ”¥")
        except Exception as e:
            print(f"  âš ï¸  Real odds extraction failed: {e} â€” using simulated")
            real_odds_test = None

    bk = bankroll; bets = []; total_bets = 0; total_won = 0
    total_staked = 0.0; peak_bk = bk; max_dd = 0.0
    edge_dist = []

    for i, (proba, actual) in enumerate(zip(proba_test, y_test)):
        p_away, p_draw, p_home = proba

        # à¹ƒà¸Šà¹‰ real odds à¸–à¹‰à¸²à¸¡à¸µ à¹„à¸¡à¹ˆà¸‡à¸±à¹‰à¸™ simulate margin 5%
        if real_odds_test is not None and i < len(real_odds_test):
            r_odds = real_odds_test[i]
            odds = {0: float(r_odds[0]), 1: float(r_odds[1]), 2: float(r_odds[2])}
            # à¸à¸£à¸­à¸‡ odds à¸—à¸µà¹ˆà¸”à¸¹à¸œà¸´à¸”à¸›à¸à¸•à¸´
            odds = {k: v if 1.05 <= v <= 50 else 99 for k, v in odds.items()}
        else:
            # fallback: simulate margin 5%
            margin = 1.05
            odds = {
                0: (1/p_away) * margin if p_away > 0.01 else 99,
                1: (1/p_draw) * margin if p_draw > 0.01 else 99,
                2: (1/p_home) * margin if p_home > 0.01 else 99,
            }
        model_p = {0: p_away, 1: p_draw, 2: p_home}
        best_cls = max([0,1,2], key=lambda c: model_p[c] - (1/odds[c]))
        edge     = model_p[best_cls] - (1/odds[best_cls])
        edge_dist.append(edge)

        # ğŸ”¥ Kelly Criterion: f* = (p*o - 1) / (o - 1)
        if edge < min_edge: continue

        p = model_p[best_cls]; o = odds[best_cls]
        kelly_full = (p * o - 1) / (o - 1)   # full Kelly
        kelly_frac = kelly_full * kelly_fraction  # fractional Kelly
        stake = min(bk * kelly_frac, bk * max_exposure)  # cap exposure
        stake = max(stake, 0.5)  # minimum bet

        won    = (best_cls == actual)
        profit = stake * (o-1) if won else -stake
        bk    += profit
        total_bets += 1; total_staked += stake
        if won: total_won += 1
        if bk > peak_bk: peak_bk = bk
        dd = (peak_bk - bk) / peak_bk * 100
        if dd > max_dd: max_dd = dd
        bets.append({'bet': total_bets, 'cls': best_cls, 'edge': edge,
                     'stake': stake, 'odds': o, 'won': won, 'profit': profit,
                     'bk': bk, 'kelly_full': kelly_full})

    if total_bets == 0:
        print("  âš ï¸  à¹„à¸¡à¹ˆà¸¡à¸µà¸à¸²à¸£à¹à¸—à¸‡à¸—à¸µà¹ˆà¸•à¸£à¸‡à¹€à¸‡à¸·à¹ˆà¸­à¸™à¹„à¸‚"); return None

    roi      = (bk - bankroll) / total_staked * 100
    win_rate = total_won / total_bets * 100
    net_pnl  = bk - bankroll

    if verbose:
        print(f"\n  {'Metric':<38} {'Value':>15}")
        print(f"  {LINE}")
        print(f"  {'à¸ˆà¸³à¸™à¸§à¸™à¹à¸¡à¸•à¸Šà¹Œà¸—à¸µà¹ˆà¸œà¹ˆà¸²à¸™ threshold':<38} {total_bets:>15,}")
        print(f"  {'Win Rate':<38} {win_rate:>14.1f}%")
        print(f"  {'Total Staked':<38} Â£{total_staked:>13,.2f}")
        print(f"  {'Net P&L':<38} Â£{net_pnl:>+13,.2f}")
        print(f"  {'Final Bankroll':<38} Â£{bk:>13,.2f}")
        print(f"  {'ROI (per unit staked)':<38} {roi:>14.1f}%")
        print(f"  {'Max Drawdown':<38} {max_dd:>14.1f}%")

        # ğŸ”¥ Kelly stats
        avg_kelly = np.mean([b['kelly_full'] for b in bets]) * 100
        avg_edge  = np.mean([b['edge'] for b in bets]) * 100
        avg_stake_pct = np.mean([b['stake'] for b in bets]) / bankroll * 100
        print(f"  {'Avg Full Kelly %':<38} {avg_kelly:>14.1f}%")
        print(f"  {'Avg Edge (qualified bets)':<38} {avg_edge:>14.1f}%")
        print(f"  {'Avg Stake % of Bankroll':<38} {avg_stake_pct:>14.2f}%")
        print(f"  {LINE}")

        for cls in [2, 0, 1]:
            cls_bets = [b for b in bets if b['cls'] == cls]
            if not cls_bets: continue
            cls_won = sum(1 for b in cls_bets if b['won'])
            cls_roi = sum(b['profit'] for b in cls_bets) / sum(b['stake'] for b in cls_bets) * 100
            cls_avg_edge = np.mean([b['edge'] for b in cls_bets]) * 100
            print(f"  {label_map[cls]:<38} {len(cls_bets):>4} bets  "
                  f"Win:{cls_won/len(cls_bets)*100:.0f}%  "
                  f"Edge:{cls_avg_edge:.1f}%  ROI:{cls_roi:+.1f}%")

        print(f"\n  ğŸ’¡ à¸ªà¸£à¸¸à¸›:")
        if roi > 5:    print(f"  âœ… ROI {roi:.1f}% â€” à¹‚à¸¡à¹€à¸”à¸¥à¸¡à¸µ edge à¸ˆà¸£à¸´à¸‡à¹ƒà¸™à¸£à¸°à¸¢à¸°à¸¢à¸²à¸§ (Quant Level)")
        elif roi > 0:  print(f"  ğŸŸ¡ ROI {roi:.1f}% â€” à¸¡à¸µ edge à¹€à¸¥à¹‡à¸à¸™à¹‰à¸­à¸¢ (à¸”à¸µà¸à¸­à¸ªà¸³à¸«à¸£à¸±à¸š research)")
        else:          print(f"  âŒ ROI {roi:.1f}% â€” à¹‚à¸¡à¹€à¸”à¸¥à¸¢à¸±à¸‡à¹„à¸¡à¹ˆ beat the market")

        # Edge distribution
        pos_edge = [e for e in edge_dist if e >= min_edge]
        print(f"\n  ğŸ“Š Edge Distribution (all matches):")
        print(f"     Matches with edge â‰¥ {min_edge*100:.0f}% : {len(pos_edge):,} / {len(edge_dist):,} "
              f"({len(pos_edge)/len(edge_dist)*100:.1f}%)")
        print(f"     Max edge observed          : {max(edge_dist)*100:.1f}%")

        # Bankroll curve
        print(f"\n  ğŸ“ˆ Bankroll Curve:")
        step    = max(1, total_bets // 20)
        sampled = [bets[i] for i in range(0, len(bets), step)]
        max_bk_s = max(b['bk'] for b in sampled)
        min_bk_s = min(b['bk'] for b in sampled)
        rng_bk   = max_bk_s - min_bk_s or 1
        print(f"  Â£{max_bk_s:>8,.0f} â”")
        for b in sampled:
            bar_len = int((b['bk'] - min_bk_s) / rng_bk * 40)
            print(f"           {'â–ˆ' * bar_len}")
        print(f"  Â£{min_bk_s:>8,.0f} â”˜")
        print(SEP)
    return {'roi': roi, 'win_rate': win_rate, 'net_pnl': net_pnl,
            'total_bets': total_bets, 'max_dd': max_dd, 'final_bk': bk}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 26) PHASE 2 (Monte Carlo + Calibration)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run_phase2(n_simulations=1000):
    print(f"\n{'â–ˆ'*65}")
    print(f"  ğŸš€  PHASE 2 â€” COMPETITION GRADE ANALYSIS")
    print(f"{'â–ˆ'*65}")
    mc_results  = run_monte_carlo(n_simulations=n_simulations)
    draw_stats  = analyze_draw_calibration()
    feat_result = run_feature_importance()
    SEP = "=" * 65
    print(f"\n{SEP}\n  ğŸ“‹  PHASE 2 â€” SUMMARY\n{SEP}")
    if mc_results:
        top4_sorted = sorted(mc_results.items(), key=lambda x: x[1]['top4'], reverse=True)[:6]
        print(f"\n  ğŸ”´  Top 4 Probability")
        for team, r in top4_sorted:
            bar = 'â–ˆ' * int(r['top4'] / 5)
            print(f"      {team:<22} {bar:<20} {r['top4']}%")
        rel_sorted = sorted(mc_results.items(), key=lambda x: x[1]['relegation'], reverse=True)[:5]
        print(f"\n  ğŸŸ¡  Relegation Probability")
        for team, r in rel_sorted:
            if r['relegation'] > 0:
                bar = 'â–“' * int(r['relegation'] / 5)
                print(f"      {team:<22} {bar:<20} {r['relegation']}%")
    if draw_stats:
        print(f"\n  ğŸ“  Draw Calibration")
        print(f"      Brier Skill Score : {draw_stats['skill']:.1f}%")
        print(f"      Systematic Bias   : {draw_stats['bias']:+.1f}%")
    print(f"\n{SEP}\n  âœ…  PHASE 2 COMPLETE\n{SEP}\n")
    return {'mc': mc_results, 'draw': draw_stats}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ NEW: WALK-FORWARD SEASON-BY-SEASON VALIDATION (v3.0)
#    Train 2015â†’2019 â†’ test 2020, train 2015â†’2020 â†’ test 2021, ...
#    à¸™à¸µà¹ˆà¸„à¸·à¸­ production-grade validation à¸—à¸µà¹ˆà¸”à¸¹à¸§à¹ˆà¸²à¹‚à¸¡à¹€à¸”à¸¥ "à¸£à¸­à¸”à¹ƒà¸™à¸­à¸™à¸²à¸„à¸•" à¹„à¸”à¹‰à¸ˆà¸£à¸´à¸‡à¹„à¸«à¸¡
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def walk_forward_season_cv(verbose=True):
    SEP  = "=" * 65
    LINE = "â”€" * 65
    if verbose:
        print(f"\n{SEP}")
        print(f"  ğŸ†  WALK-FORWARD SEASON-BY-SEASON VALIDATION (v3.0)")
        print(f"  âš ï¸  à¸™à¸µà¹ˆà¸„à¸·à¸­ test à¸—à¸µà¹ˆà¹‚à¸«à¸”à¸—à¸µà¹ˆà¸ªà¸¸à¸” â€” à¸—à¸³à¸™à¸²à¸¢à¸­à¸™à¸²à¸„à¸•à¸ˆà¸£à¸´à¸‡ à¹†")
        print(SEP)

    cv_df = match_df_clean.copy()

    # ğŸ”¥ FIX 2: à¹ƒà¸Šà¹‰ Season (Augâ†’Jul) à¹à¸—à¸™ Calendar Year
    #    Season 2023 = Aug 2023 â€“ Jul 2024 â‰ˆ 380 à¸™à¸±à¸” (à¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆà¹à¸„à¹ˆ Jan-Dec)
    if 'Season' not in cv_df.columns:
        cv_df['Season'] = cv_df['Date_x'].apply(get_season)

    seasons = sorted(cv_df['Season'].dropna().unique())
    # à¸•à¹‰à¸­à¸‡à¸¡à¸µ training data à¸­à¸¢à¹ˆà¸²à¸‡à¸™à¹‰à¸­à¸¢ 3 seasons
    min_train_seasons = 3
    test_seasons = [s for s in seasons[min_train_seasons:] if not pd.isna(s)]

    if len(test_seasons) == 0:
        print("  âš ï¸  à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸à¸µà¸¢à¸‡à¸à¸­à¸ªà¸³à¸«à¸£à¸±à¸š walk-forward CV")
        return []

    fold_results = []
    if verbose:
        print(f"\n  {'Season':<10} {'Train':>8} {'Test':>7} {'Acc':>8} {'Draw-F1':>9} {'LogLoss':>9}")
        print(f"  {LINE}")

    for test_season in test_seasons:
        train_mask = cv_df['Season'] < test_season
        test_mask  = cv_df['Season'] == test_season

        n_train = train_mask.sum()
        n_test  = test_mask.sum()

        # ğŸ”¥ FIX D v2: à¸¥à¸” MIN_TEST_MATCHES â†’ 80 à¹€à¸à¸·à¹ˆà¸­à¹ƒà¸«à¹‰ season 2024 (87 test) à¸œà¹ˆà¸²à¸™
        #    à¹€à¸à¸´à¹ˆà¸¡ caveat à¹ƒà¸™ output à¸§à¹ˆà¸² fold à¸—à¸µà¹ˆ test < 150 à¸„à¸§à¸£ interpret à¸”à¹‰à¸§à¸¢à¸„à¸§à¸²à¸¡à¸£à¸°à¸¡à¸±à¸”à¸£à¸°à¸§à¸±à¸‡
        MIN_TEST_MATCHES = 80
        if n_train < 200 or n_test < MIN_TEST_MATCHES:
            if n_test > 0 and verbose:
                status = 'train' if n_train < 200 else 'test'
                warn = f"({n_train} train, {n_test} test â€” need 200 train + {MIN_TEST_MATCHES}+ test)"
                print(f"  â­ï¸  Skip {test_season} â€” {status} too small {warn}")
            continue
        small_sample_warn = "âš ï¸ small" if n_test < 150 else ""

        X_tr = cv_df.loc[train_mask, FEATURES].values
        y_tr = cv_df.loc[train_mask, 'Result3'].values
        X_te = cv_df.loc[test_mask,  FEATURES].values
        y_te = cv_df.loc[test_mask,  'Result3'].values

        sc_wf  = StandardScaler()
        X_tr_sc = sc_wf.fit_transform(X_tr)
        X_te_sc = sc_wf.transform(X_te)

        # ğŸ”¥ FIX CONSISTENCY: à¹ƒà¸Šà¹‰ shared params à¹€à¸«à¸¡à¸·à¸­à¸™ main model
        if LGBM_AVAILABLE:
            cv_model = lgb.LGBMClassifier(**get_cv_lgbm_params())
        else:
            cv_model = GradientBoostingClassifier(
                n_estimators=200, max_depth=4, learning_rate=0.05,
                subsample=0.8, random_state=42
            )

        cv_model.fit(X_tr_sc, y_tr)
        y_proba_wf = cv_model.predict_proba(X_te_sc)
        # ğŸ”¥ FIX 1 v7b: Narrow threshold search anchored à¸£à¸­à¸š main model â€” walk-forward
        y_proba_wf = suppress_draw_proba(y_proba_wf, draw_factor=DRAW_SUPPRESS_FACTOR)
        try:
            t_h_wf, t_d_wf, _ = optimize_thresholds(
                y_proba_wf, y_te, n_steps=10,
                t_home_range=(max(0.15, OPT_T_HOME - 0.05), min(0.55, OPT_T_HOME + 0.05)),
                t_draw_range=(max(0.15, OPT_T_DRAW - 0.05), min(0.55, OPT_T_DRAW + 0.05)),
            )
        except (NameError, TypeError):
            t_h_wf, t_d_wf, _ = optimize_thresholds(y_proba_wf, y_te, n_steps=15)
        y_pred_wf  = apply_thresholds(y_proba_wf, t_home=t_h_wf, t_draw=t_d_wf)

        a   = accuracy_score(y_te, y_pred_wf)
        ll  = log_loss(y_te, y_proba_wf)
        rep = classification_report(y_te, y_pred_wf, output_dict=True, zero_division=0)
        draw_f1 = rep.get('1', {}).get('f1-score', 0)

        fold_results.append({
            'year': test_season, 'train_size': n_train,
            'test_size': n_test, 'acc': a,
            'draw_f1': draw_f1, 'logloss': ll
        })
        if verbose:
            print(f"  {str(test_season):<10} {n_train:>8} {n_test:>7} "
                  f"{a:>8.4f} {draw_f1:>9.4f} {ll:>9.4f}  {small_sample_warn}")

    if fold_results and verbose:
        accs = [r['acc'] for r in fold_results]
        drs  = [r['draw_f1'] for r in fold_results]
        lls  = [r['logloss'] for r in fold_results]
        trend = "ğŸ“ˆ à¸”à¸µà¸‚à¸¶à¹‰à¸™" if accs[-1] > accs[0] else ("ğŸ“‰ à¹à¸¢à¹ˆà¸¥à¸‡" if accs[-1] < accs[0] else "â†’ à¸„à¸‡à¸—à¸µà¹ˆ")
        print(f"  {LINE}")
        print(f"  Mean  {' ':>8} {' ':>7} {np.mean(accs):>8.4f} "
              f"{np.mean(drs):>9.4f} {np.mean(lls):>9.4f}")
        print(f"\n  ğŸ“Š Walk-Forward Results:")
        print(f"     Mean Accuracy  : {np.mean(accs):.4f} Â± {np.std(accs):.4f}")
        print(f"     Mean Draw F1   : {np.mean(drs):.4f}")
        print(f"     Best Year      : {fold_results[np.argmax(accs)]['year']}  ({max(accs):.4f})")
        print(f"     Worst Year     : {fold_results[np.argmin(accs)]['year']}  ({min(accs):.4f})")
        print(f"     Trend          : {trend}")
        stab = "âœ… à¹€à¸ªà¸–à¸µà¸¢à¸£à¸‚à¹‰à¸²à¸¡à¸›à¸µ" if np.std(accs) < 0.04 else "âš ï¸  unstable across years"
        print(f"     à¸„à¸§à¸²à¸¡à¹€à¸ªà¸–à¸µà¸¢à¸£    : {stab} (std={np.std(accs):.4f})")

        # ğŸ”¥ FIX 3 (v7): à¸–à¹‰à¸² walk-forward à¸¡à¸µ fold à¸™à¹‰à¸­à¸¢ (<3 folds) à¹ƒà¸«à¹‰à¹à¸ªà¸”à¸‡ pooled estimate
        #    à¹€à¸à¸·à¹ˆà¸­à¹€à¸à¸´à¹ˆà¸¡ statistical reliability à¸‚à¸­à¸‡ estimate
        n_small = sum(1 for r in fold_results if r['test_size'] < 150)
        if n_small > 0:
            all_test_sizes = sum(r['test_size'] for r in fold_results)
            print(f"\n  âš ï¸  Walk-forward reliability warning:")
            print(f"     {n_small}/{len(fold_results)} folds à¸¡à¸µ test < 150 à¸™à¸±à¸” (sample à¹€à¸¥à¹‡à¸)")
            print(f"     Total pooled test size: {all_test_sizes} à¸™à¸±à¸”")
            if all_test_sizes >= 150:
                # à¸„à¸³à¸™à¸§à¸“ pooled weighted accuracy
                weighted_acc = sum(r['acc'] * r['test_size'] for r in fold_results) / all_test_sizes
                weighted_draw_f1 = sum(r['draw_f1'] * r['test_size'] for r in fold_results) / all_test_sizes
                print(f"     ğŸ“Š Pooled weighted accuracy: {weighted_acc:.4f}  (à¸™à¹ˆà¸²à¹€à¸Šà¸·à¹ˆà¸­à¸–à¸·à¸­à¸à¸§à¹ˆà¸² mean of folds)")
                print(f"     ğŸ“Š Pooled weighted Draw F1 : {weighted_draw_f1:.4f}")
            else:
                print(f"     ğŸ’¡ à¹à¸™à¸°à¸™à¸³: à¸£à¸§à¸šà¸£à¸§à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸¢à¹‰à¸­à¸™à¸«à¸¥à¸±à¸‡à¹€à¸à¸´à¹ˆà¸¡à¹€à¸à¸·à¹ˆà¸­ walk-forward à¸—à¸µà¹ˆà¸™à¹ˆà¸²à¹€à¸Šà¸·à¹ˆà¸­à¸–à¸·à¸­à¸à¸§à¹ˆà¸²")
        print(SEP)
    return fold_results


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ NEW: REGIME DETECTION â€” Form Clustering (v3.0)
#    à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š "à¸Šà¹ˆà¸§à¸‡à¸Ÿà¸­à¸£à¹Œà¸¡à¸”à¸µ / à¸Ÿà¸­à¸£à¹Œà¸¡à¸•à¸" à¸‚à¸­à¸‡à¸—à¸µà¸¡
#    à¹ƒà¸Šà¹‰ K-Means clustering à¸šà¸™ rolling form features
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

from sklearn.cluster import KMeans
from sklearn.preprocessing import MinMaxScaler

def detect_team_regimes(team, n_regimes=3, verbose=True):
    """
    à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š form regime à¸‚à¸­à¸‡à¸—à¸µà¸¡à¸”à¹‰à¸§à¸¢ K-Means clustering
    n_regimes=3: Cold Form / Average Form / Hot Form
    """
    SEP  = "=" * 65
    LINE = "â”€" * 65

    team_rows = team_df[team_df['Team'] == team].sort_values('Date').copy()
    team_rows = team_rows.dropna(subset=['GF_last5','GA_last5','Points_last5','GD_std5'])

    if len(team_rows) < n_regimes * 5:
        if verbose: print(f"  âš ï¸  à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹„à¸¡à¹ˆà¸à¸­à¸ªà¸³à¸«à¸£à¸±à¸š {team}")
        return None

    regime_features = ['Points_last5', 'GF_last5', 'GA_last5',
                       'GD_last5', 'GD_ewm5', 'Pts_ewm5']
    rf_avail = [f for f in regime_features if f in team_rows.columns]
    X_reg = team_rows[rf_avail].fillna(0).values  # ğŸ”¥ fillna à¸à¹ˆà¸­à¸™ KMeans

    # Normalize
    mm = MinMaxScaler()
    X_norm = mm.fit_transform(X_reg)

    # K-Means clustering
    km = KMeans(n_clusters=n_regimes, random_state=42, n_init=10)
    labels = km.fit_predict(X_norm)
    team_rows['Regime'] = labels

    # Label clusters by average points (0=Cold, 1=Average, 2=Hot)
    cluster_pts = {c: team_rows[team_rows['Regime']==c]['Points_last5'].mean()
                   for c in range(n_regimes)}
    sorted_clusters = sorted(cluster_pts, key=cluster_pts.get)
    regime_names = {sorted_clusters[0]: 'â„ï¸  Cold Form',
                    sorted_clusters[1]: 'ğŸŸ¡ Average Form',
                    sorted_clusters[2]: 'ğŸ”¥ Hot Form'}
    if n_regimes == 2:
        regime_names = {sorted_clusters[0]: 'â„ï¸  Cold Form',
                        sorted_clusters[1]: 'ğŸ”¥ Hot Form'}
    team_rows['RegimeName'] = team_rows['Regime'].map(regime_names)

    # Current regime
    current_regime = team_rows.iloc[-1]['RegimeName']
    current_pts5   = team_rows.iloc[-1]['Points_last5']

    if verbose:
        print(f"\n{SEP}")
        print(f"  ğŸ§   REGIME DETECTION: {team.upper()}")
        print(SEP)
        print(f"\n  Current Form Regime : {current_regime}")
        print(f"  Points (last 5)     : {current_pts5:.2f}")
        print(f"\n  Regime Statistics:")
        print(f"  {'Regime':<20} {'Matches':>8} {'Avg Pts':>9} {'Avg GF':>8} {'Avg GA':>8}")
        print(f"  {LINE}")
        for cluster in range(n_regimes):
            subset = team_rows[team_rows['Regime'] == cluster]
            r_name = regime_names.get(cluster, f'Cluster {cluster}')
            print(f"  {r_name:<20} {len(subset):>8} "
                  f"{subset['Points_last5'].mean():>9.2f} "
                  f"{subset['GF_last5'].mean():>8.2f} "
                  f"{subset['GA_last5'].mean():>8.2f}")

        # Recent regime timeline (last 10 matches)
        recent = team_rows.tail(10)
        print(f"\n  ğŸ“… Last 10 matches regime timeline:")
        print(f"  ", end="")
        for _, r in recent.iterrows():
            icon = {'â„ï¸  Cold Form': 'â„', 'ğŸŸ¡ Average Form': 'â—', 'ğŸ”¥ Hot Form': 'ğŸ”¥'}.get(r['RegimeName'], '?')
            print(icon, end=" ")
        print(f"\n  {LINE}")
        print(f"  â„ Cold  â— Average  ğŸ”¥ Hot")
        print(SEP)

    return {
        'team': team, 'current_regime': current_regime,
        'current_pts5': current_pts5,
        'regime_stats': {regime_names[c]: {
            'count': int((team_rows['Regime']==c).sum()),
            'avg_pts': float(team_rows[team_rows['Regime']==c]['Points_last5'].mean())
        } for c in range(n_regimes)},
        'all_regimes': team_rows[['Date','RegimeName','Points_last5']].tail(20).to_dict('records')
    }


def analyze_league_regimes(top_n=6):
    """à¸”à¸¹ regime à¸‚à¸­à¸‡ top N à¸—à¸µà¸¡ (à¸•à¸²à¸¡ Elo) à¸à¸£à¹‰à¸­à¸¡à¸à¸±à¸™"""
    SEP = "=" * 65
    print(f"\n{SEP}\n  ğŸ§   LEAGUE-WIDE REGIME SUMMARY\n{SEP}")
    top_teams = sorted(final_elo.items(), key=lambda x: x[1], reverse=True)[:top_n]
    print(f"  {'Team':<22} {'Current Regime':<22} {'Pts/5':>7} {'Elo':>7}")
    print(f"  {'â”€'*60}")
    results = {}
    for team, elo in top_teams:
        r = detect_team_regimes(team, verbose=False)
        if r:
            print(f"  {team:<22} {r['current_regime']:<22} "
                  f"{r['current_pts5']:>7.2f} {elo:>7.0f}")
            results[team] = r
    print(SEP)
    return results


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 27) PHASE 3 (CV + ROI + Calibration + Walk-Forward)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ FIX 5: MARKET ABLATION TEST
#    à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š model à¸—à¸µà¹ˆà¸¡à¸µà¹à¸¥à¸°à¹„à¸¡à¹ˆà¸¡à¸µ market features
#    à¸–à¹‰à¸² accuracy à¸”à¸£à¸­à¸›à¸¡à¸²à¸ â†’ à¹‚à¸¡à¹€à¸”à¸¥à¹à¸„à¹ˆ "à¹€à¸£à¸µà¸¢à¸™ odds"
#    à¸–à¹‰à¸² accuracy à¸”à¸£à¸­à¸›à¸™à¹‰à¸­à¸¢ â†’ à¹‚à¸¡à¹€à¸”à¸¥à¸¡à¸µ football intelligence à¹à¸—à¹‰à¸ˆà¸£à¸´à¸‡
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run_market_ablation_test(verbose=True):
    """
    Ablation test: train 3 versions à¹à¸¥à¸° compare accuracy à¸šà¸™ test set
    1) Full features (with market)
    2) No market features
    3) No xG features

    ğŸ”¥ v8: à¹ƒà¸Šà¹‰ single-stage LightGBM à¹€à¸à¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸à¸±à¸™à¹„à¸”à¹‰à¸¢à¸¸à¸•à¸´à¸˜à¸£à¸£à¸¡
    (main model à¹€à¸›à¹‡à¸™ 2-stage + Poisson hybrid à¸ˆà¸¶à¸‡à¸¡à¸µ accuracy à¸•à¹ˆà¸²à¸‡à¸à¸±à¸™ â€”
    ablation à¸™à¸µà¹‰à¸§à¸±à¸” *relative contribution* à¸‚à¸­à¸‡ feature groups à¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆ absolute accuracy)
    """
    SEP  = "=" * 65
    LINE = "â”€" * 65
    if verbose:
        print(f"\n{SEP}")
        print(f"  ğŸ”¬  MARKET ABLATION TEST (FIX 5)")
        print(f"  à¸—à¸”à¸ªà¸­à¸šà¸§à¹ˆà¸² edge à¸¡à¸²à¸ˆà¸²à¸ Market Odds à¸«à¸£à¸·à¸­ Football Features à¸ˆà¸£à¸´à¸‡")
        print(f"  âš ï¸  à¹ƒà¸Šà¹‰ single-stage LightGBM à¹€à¸à¸·à¹ˆà¸­à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š feature groups à¸­à¸¢à¹ˆà¸²à¸‡à¸¢à¸¸à¸•à¸´à¸˜à¸£à¸£à¸¡")
        print(f"  (à¸•à¸±à¸§à¹€à¸¥à¸‚ accuracy à¸™à¸µà¹‰à¸•à¹ˆà¸³à¸à¸§à¹ˆà¸² main model à¹€à¸à¸£à¸²à¸°à¹„à¸¡à¹ˆà¸¡à¸µ 2-stage + Poisson)")
        print(SEP)

    if not LGBM_AVAILABLE:
        print("  âš ï¸  LightGBM à¹„à¸¡à¹ˆà¸à¸£à¹‰à¸­à¸¡ â€” à¸‚à¹‰à¸²à¸¡ ablation test")
        return None

    MKT_FEATURES = ['Mkt_ImpH', 'Mkt_ImpD', 'Mkt_ImpA',
                     'Mkt_Spread', 'Mkt_DrawPrem', 'Mkt_Overround']
    XG_FEAT_LIST = [f for f in FEATURES if any(k in f for k in
                    ['xGF', 'xGA', 'xGD', 'xG_over', 'xAttack', 'xGF_slope'])]

    features_no_mkt = [f for f in FEATURES if f not in MKT_FEATURES]
    features_no_xg  = [f for f in FEATURES if f not in XG_FEAT_LIST]
    features_base   = [f for f in FEATURES
                       if f not in MKT_FEATURES and f not in XG_FEAT_LIST]

    # ğŸ”¥ FIX CONSISTENCY: à¹ƒà¸Šà¹‰ params à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸š main model
    #    à¹€à¸”à¸´à¸¡à¹ƒà¸Šà¹‰ hardcode default params â†’ accuracy 44.8% vs main 51.24%
    #    à¹à¸à¹‰à¹à¸¥à¹‰à¸§: à¹ƒà¸Šà¹‰ get_cv_lgbm_params() + draw suppression à¹€à¸«à¸¡à¸·à¸­à¸™à¸à¸±à¸™à¸—à¸¸à¸ instance
    ablation_params = get_cv_lgbm_params() if LGBM_AVAILABLE else {}

    results = {}
    configs = [
        ('Full (Market+xG)',     FEATURES),
        ('No Market Features',   features_no_mkt),
        ('No xG Features',       features_no_xg),
        ('Base Only (No Mkt/xG)',features_base),
    ]

    if verbose:
        print(f"\n  {'Config':<28} {'Features':>10} {'Test Acc':>10} {'Draw F1':>9}")
        print(f"  {LINE}")

    for name, feat_list in configs:
        if len(feat_list) < 5:
            if verbose: print(f"  {name:<28} {'skip â€” too few features':>30}")
            continue
        try:
            X_tr_ab = train[feat_list].fillna(0).values
            X_te_ab = test[feat_list].fillna(0).values
            y_tr_ab = train['Result3'].values
            y_te_ab = test['Result3'].values

            sc_ab = StandardScaler()
            X_tr_sc_ab = sc_ab.fit_transform(X_tr_ab)
            X_te_sc_ab = sc_ab.transform(X_te_ab)

            mdl = lgb.LGBMClassifier(**ablation_params)
            mdl.fit(X_tr_sc_ab, y_tr_ab)

            # ğŸ”¥ FIX CONSISTENCY: apply draw suppression + threshold à¸à¹ˆà¸­à¸™ predict
            proba_ab = mdl.predict_proba(X_te_sc_ab)
            proba_ab = suppress_draw_proba(proba_ab, draw_factor=DRAW_SUPPRESS_FACTOR)
            t_h_ab, t_d_ab, _ = optimize_thresholds(proba_ab, y_te_ab, n_steps=20)
            pred_ab  = apply_thresholds(proba_ab, t_home=t_h_ab, t_draw=t_d_ab)

            acc_ab = accuracy_score(y_te_ab, pred_ab)
            rep_ab = classification_report(y_te_ab, pred_ab, output_dict=True, zero_division=0)
            draw_f1_ab = rep_ab.get('1', {}).get('f1-score', 0)

            results[name] = {'acc': acc_ab, 'draw_f1': draw_f1_ab, 'n_features': len(feat_list)}

            marker = ''
            if 'Full' in name: marker = ' â† baseline'
            elif results.get('Full (Market+xG)'):
                drop = results['Full (Market+xG)']['acc'] - acc_ab
                marker = f' (drop {drop:+.1%})'

            if verbose:
                print(f"  {name:<28} {len(feat_list):>10} {acc_ab:>10.1%} {draw_f1_ab:>9.3f}{marker}")

        except Exception as e:
            if verbose: print(f"  {name:<28} Error: {e}")

    if verbose and len(results) >= 2:
        print(f"\n  {LINE}")
        full_acc  = results.get('Full (Market+xG)', {}).get('acc', 0)
        nomkt_acc = results.get('No Market Features', {}).get('acc', 0)
        noxg_acc  = results.get('No xG Features', {}).get('acc', 0)
        base_acc  = results.get('Base Only (No Mkt/xG)', {}).get('acc', 0)

        market_contribution = full_acc - nomkt_acc
        xg_contribution     = full_acc - noxg_acc if noxg_acc else 0

        print(f"\n  ğŸ“Š Feature Contribution Analysis:")
        print(f"     Market features contribution : {market_contribution:+.1%}")
        # ğŸ”¥ v8: xG contribution à¸­à¸²à¸ˆà¹€à¸›à¹‡à¸™ negative à¹ƒà¸™ single-stage ablation
        #    à¹€à¸à¸£à¸²à¸° xG features à¸­à¸­à¸à¹à¸šà¸šà¸¡à¸²à¸ªà¸³à¸«à¸£à¸±à¸š 2-stage model â†’ à¸•à¹‰à¸­à¸‡à¸­à¸˜à¸´à¸šà¸²à¸¢ context
        xg_note = ""
        if xg_contribution < -0.01:
            xg_note = "  â† à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸ˆà¸£à¸´à¸‡à¹ƒà¸™ 2-Stage+Poisson à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™ (à¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆ single-stage)"
        print(f"     xG features contribution     : {xg_contribution:+.1%}{xg_note}")
        print(f"     Base (Elo+Form) accuracy     : {base_acc:.1%}")

        print(f"\n  ğŸ¯ Verdict:")
        if market_contribution > 0.05:
            print(f"     âŒ Edge à¸¡à¸²à¸ˆà¸²à¸ Market Odds à¹€à¸›à¹‡à¸™à¸«à¸¥à¸±à¸ (>{market_contribution:.0%})")
            print(f"        â†’ ROI backtest à¸¡à¸µà¹‚à¸­à¸à¸²à¸ª overestimate à¸–à¹‰à¸²à¹ƒà¸Šà¹‰ closing odds")
            print(f"        â†’ à¸•à¹‰à¸­à¸‡à¸à¸´à¸ªà¸¹à¸ˆà¸™à¹Œà¸”à¹‰à¸§à¸¢ opening odds à¸«à¸£à¸·à¸­ in-play edge")
        elif market_contribution > 0.02:
            print(f"     ğŸŸ¡ Market à¸Šà¹ˆà¸§à¸¢ moderate ({market_contribution:.0%})")
            print(f"        â†’ à¹‚à¸¡à¹€à¸”à¸¥à¸¡à¸µà¸—à¸±à¹‰à¸‡ football + market signal")
        else:
            print(f"     âœ… Model à¸¡à¸µ football intelligence à¹à¸—à¹‰ ({market_contribution:.0%} from market)")
            print(f"        â†’ ROI à¸™à¹ˆà¸²à¹€à¸Šà¸·à¹ˆà¸­à¸–à¸·à¸­à¸¡à¸²à¸à¸‚à¸¶à¹‰à¸™")

        if xg_contribution < -0.01:
            print(f"     ğŸ’¡ xG features: contribution à¸”à¸¹à¹€à¸›à¹‡à¸™ negative à¹ƒà¸™ single-stage ablation")
            print(f"        â†’ à¸™à¸µà¹ˆà¹€à¸›à¹‡à¸™ artifact à¸‚à¸­à¸‡ model architecture à¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆ xG à¹„à¸¡à¹ˆà¸¡à¸µà¸›à¸£à¸°à¹‚à¸¢à¸Šà¸™à¹Œ")
            print(f"        â†’ Main model (2-Stage+Poisson) à¹ƒà¸Šà¹‰ xG à¹„à¸”à¹‰à¸œà¸¥à¸”à¸µà¸à¸§à¹ˆà¸² à¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡: Hybrid gain +2.09%")

        print(SEP)

    return {
        'with_mkt': results.get('Full (Market+xG)', {}).get('acc', 0),
        'no_mkt':   results.get('No Market Features', {}).get('acc', 0),
        'no_xg':    results.get('No xG Features', {}).get('acc', 0),
        'base':     results.get('Base Only (No Mkt/xG)', {}).get('acc', 0),
        'details':  results
    }


def run_phase3(n_simulations=1000):
    print(f"\n{'â–ˆ'*65}")
    print(f"  ğŸ†  PHASE 3 â€” PRODUCTION GRADE v3.0")
    print(f"{'â–ˆ'*65}")

    cv_results  = rolling_window_cv(n_splits=5)
    wf_results  = walk_forward_season_cv()
    # ğŸ”¥ FIX: à¸¥à¸” kelly_fraction 0.25 â†’ 0.15 à¹€à¸à¸·à¹ˆà¸­à¸„à¸§à¸šà¸„à¸¸à¸¡ max drawdown
    #    v6.0 à¸¡à¸µ 106 bets vs 42 bets à¹€à¸”à¸´à¸¡ â†’ drawdown à¹‚à¸­à¸à¸²à¸ªà¸ªà¸¹à¸‡à¸‚à¸¶à¹‰à¸™
    roi_result  = backtest_roi(bankroll=1000.0, min_edge=0.03, kelly_fraction=0.15)

    # ğŸ”¥ FIX 3: Backtest à¹€à¸à¸´à¹ˆà¸¡ conservative + max_odds mode (à¹€à¸‰à¸à¸²à¸°à¹€à¸¡à¸·à¹ˆà¸­à¹ƒà¸Šà¹‰ market)
    if USE_MARKET_FEATURES and ODDS_AVAILABLE:
        print(f"\n{'â”€'*65}")
        print(f"  ğŸ”¬  STRESS TEST: Opening Odds Simulation (FIX 3)")
        print(f"{'â”€'*65}")
        roi_conservative = backtest_roi(
            bankroll=1000.0, min_edge=0.03, kelly_fraction=0.25,
            mode='conservative', odds_shrink=0.05,
            verbose=True
        )
        roi_max = backtest_roi(
            bankroll=1000.0, min_edge=0.03, kelly_fraction=0.25,
            mode='max_odds', verbose=True
        )
        print(f"\n  ğŸ“Š Backtest Comparison (FIX 3):")
        print(f"  {'Mode':<30} {'ROI':>8}  {'WinRate':>9}  {'Bets':>6}")
        print(f"  {'â”€'*56}")
        for tag, r in [
            ("Closing B365 (optimistic)", roi_result),
            ("Conservative -5% (opening)", roi_conservative),
            ("Max odds (worst-case)", roi_max),
        ]:
            if r:
                print(f"  {tag:<30} {r['roi']:>+7.1f}%  {r['win_rate']:>8.1f}%  {r['total_bets']:>6}")
        verdict = ""
        if roi_conservative and roi_conservative['roi'] > 5:
            verdict = "âœ… Edge à¸¢à¸±à¸‡à¸„à¸‡à¸­à¸¢à¸¹à¹ˆà¹à¸¡à¹‰ conservative â†’ edge à¸ˆà¸£à¸´à¸‡"
        elif roi_conservative and roi_conservative['roi'] > 0:
            verdict = "ğŸŸ¡ Edge à¸­à¹ˆà¸­à¸™à¸¥à¸‡à¸¡à¸²à¸ â†’ à¸­à¸²à¸ˆà¸¡à¸²à¸ˆà¸²à¸ closing odds advantage à¸šà¸²à¸‡à¸ªà¹ˆà¸§à¸™"
        elif roi_conservative:
            verdict = "âŒ Edge à¸«à¸²à¸¢à¹„à¸›à¹ƒà¸™ conservative â†’ edge à¸¡à¸²à¸ˆà¸²à¸ closing odds à¹€à¸›à¹‡à¸™à¸«à¸¥à¸±à¸"
        if verdict:
            print(f"\n  ğŸ’¡ {verdict}")

    mc_results  = run_monte_carlo(n_simulations=n_simulations)
    regime_data = analyze_league_regimes(top_n=6)  # ğŸ”¥ NEW: Regime Detection

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ”¥ FIX 5: NO-MARKET ABLATION TEST
    #    train à¹‚à¸¡à¹€à¸”à¸¥à¹ƒà¸«à¸¡à¹ˆà¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸¡à¸µ market features
    #    à¸–à¹‰à¸² accuracy à¸”à¸£à¸­à¸› > 5% â†’ edge à¸¡à¸²à¸ˆà¸²à¸ odds à¹€à¸›à¹‡à¸™à¸«à¸¥à¸±à¸
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    ablation_result = run_market_ablation_test()

    SEP = "=" * 65
    cv_accs = [r['acc'] for r in cv_results]
    cv_drs  = [r['draw_f1'] for r in cv_results]

    print(f"\n{SEP}\n  ğŸ“‹  PHASE 3 â€” SUMMARY v3.0\n{SEP}")

    # ğŸ”¥ v8: walk-forward à¹€à¸›à¹‡à¸™ PRIMARY metric
    if wf_results:
        wf_accs = [r['acc'] for r in wf_results]
        wf_sizes = [r['test_size'] for r in wf_results]
        wf_total = sum(wf_sizes)
        wf_weighted = sum(r['acc'] * r['test_size'] for r in wf_results) / wf_total if wf_total > 0 else 0
        print(f"\n  ğŸ† Walk-Forward CV (PRIMARY â€” season-by-season) ğŸ”¥")
        print(f"     Mean Accuracy   : {np.mean(wf_accs):.4f} Â± {np.std(wf_accs):.4f}")
        print(f"     Weighted Acc    : {wf_weighted:.4f}  (pooled {wf_total} matches)")
        print(f"     Range           : [{min(wf_accs):.4f} â€“ {max(wf_accs):.4f}]")

    print(f"\n  ğŸ”„ Rolling CV (5 folds) â€” reference only, not production estimate")
    print(f"     Mean Accuracy : {np.mean(cv_accs):.4f} Â± {np.std(cv_accs):.4f}")
    print(f"     Mean Draw F1  : {np.mean(cv_drs):.4f}")
    print(f"     âš ï¸  à¸•à¹ˆà¸³à¸à¸§à¹ˆà¸² main model à¹€à¸à¸£à¸²à¸°à¹ƒà¸Šà¹‰ single-stage + data à¸¢à¸¸à¸„ 2020-22")

    if roi_result:
        print(f"\n  ğŸ’° Backtest ROI")
        print(f"     ROI            : {roi_result['roi']:+.1f}%")
        print(f"     Win Rate       : {roi_result['win_rate']:.1f}%")
        print(f"     Max Drawdown   : {roi_result['max_dd']:.1f}%")
        print(f"     Total Bets     : {roi_result['total_bets']:,}")

    if ablation_result:
        print(f"\n  ğŸ”¬ Market Ablation Test (FIX 5)")
        print(f"     With Market    : {ablation_result['with_mkt']:.1%}")
        print(f"     No Market      : {ablation_result['no_mkt']:.1%}")
        drop = ablation_result['with_mkt'] - ablation_result['no_mkt']
        print(f"     Market Contribution: {drop:+.1%}")
        if drop > 0.05:
            print(f"     âš ï¸  Edge à¸¡à¸²à¸ˆà¸²à¸ market odds à¹€à¸›à¹‡à¸™à¸«à¸¥à¸±à¸ (drop > 5%)")
        elif drop > 0.02:
            print(f"     ğŸŸ¡ Market à¸Šà¹ˆà¸§à¸¢ moderate (drop 2-5%)")
        else:
            print(f"     âœ… Model à¸¡à¸µ football intelligence à¹à¸—à¹‰ (drop < 2%)")

    print(f"\n{SEP}\n  âœ…  PHASE 3 COMPLETE\n{SEP}\n")
    return {'cv': cv_results, 'walk_forward': wf_results, 'roi': roi_result, 'mc': mc_results,
            'ablation': ablation_result}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸš€  MAIN EXECUTION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# STEP 1: à¸­à¸±à¸›à¹€à¸”à¸• CSV à¸ˆà¸²à¸ API
update_season_csv_from_api()

# STEP 2: à¸ˆà¸³à¸¥à¸­à¸‡à¸¤à¸”à¸¹à¸à¸²à¸¥
run_season_simulation()

# STEP 3: à¸—à¸³à¸™à¸²à¸¢à¸—à¸µà¸¡à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£ (à¹à¸à¹‰à¸Šà¸·à¹ˆà¸­à¸—à¸µà¸¡à¸•à¸²à¸¡à¸•à¹‰à¸­à¸‡à¸à¸²à¸£)
predict_with_api("Arsenal")
# predict_with_api("Liverpool")
# predict_with_api("Man City")
# predict_with_api("Chelsea")
# predict_with_api("Aston Villa")

# STEP 4: à¸•à¸²à¸£à¸²à¸‡à¹à¸‚à¹ˆà¸‡ PL à¸–à¸±à¸”à¹„à¸›
show_next_pl_fixtures(5)

# STEP 5: Summary Report
print_full_summary()

# STEP 6: Phase 2 â€” Monte Carlo + Draw Calibration + Feature Importance
run_phase2(n_simulations=1000)

# STEP 7: Phase 3 â€” Rolling CV + ROI Backtest
run_phase3()